{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data Cleaning, Reduction & Enrichment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the data scientist jobs data that I scraped from glassdoor.co.uk for analysis, I will:\n",
    "\n",
    "- **Enrich** the data: by expanding/filling-in parts of the advertised job location using an Ordinance Survey API\n",
    "\n",
    "- **Clean** the data: after importing the CSV file into a pandas DataFrame, I'll remove duplicate jobs, and check and clean the data column-by-column\n",
    "\n",
    "- **Reduce** the data: by eliminating invalid jobs and transforming the data types where possible so that they take up less memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and modules\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all columns and rows will be displayed if/when you print the dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# ensure all figures will have a white background in this notebook\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "\n",
    "# ignore filter warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll import the jobs data CSV file, reading it in as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 727 entries, Senior Data Scientist to Researcher/Data Scientist - QMUL\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   salary_estimate         453 non-null    object \n",
      " 1   job_description         724 non-null    object \n",
      " 2   rating                  587 non-null    float64\n",
      " 3   company_name            727 non-null    object \n",
      " 4   location                727 non-null    object \n",
      " 5   size                    629 non-null    object \n",
      " 6   founded                 508 non-null    float64\n",
      " 7   type_of_ownership       629 non-null    object \n",
      " 8   industry                553 non-null    object \n",
      " 9   sector                  555 non-null    object \n",
      " 10  revenue                 629 non-null    object \n",
      " 11  rating_culturevalues    572 non-null    float64\n",
      " 12  rating_worklifebalance  583 non-null    float64\n",
      " 13  rating_diversity        451 non-null    float64\n",
      " 14  rating_seniormgmt       582 non-null    float64\n",
      " 15  rating_compbenefits     583 non-null    float64\n",
      " 16  rating_careerops        583 non-null    float64\n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 102.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# create the path to the scraped and checked glassdoor jobs data\n",
    "path = './data/'\n",
    "\n",
    "# provide glassdoor scrape date\n",
    "scrapedate = '14Dec2020'  # e.g. '14Dec2020'\n",
    "\n",
    "# create the absolute path to the scraped jobs data with parsed locations\n",
    "filename = os.path.join(path, f\"gdjobs_df_{scrapedate}_checked.csv\")\n",
    "\n",
    "# read the data scientist jobs data (CSV file) into a dataframe\n",
    "gdjobs = pd.read_csv(filename, index_col=0)\n",
    "\n",
    "# display dataframe info to check that it's what you expected\n",
    "gdjobs.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment: getting the full job location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When browsing jobs on the glassdoor.co.uk, I had noticed that the level of detail in the job locations very (e.g. 'Greater Manchester' vs 'Farnborough, Hampshire, South East England, England')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alva, Scotland                                     1\n",
       "Bromley, England                                   1\n",
       "Skipton, England                                   1\n",
       "Bristol, England                                   9\n",
       "Swindon, Wiltshire, South West England, England    2\n",
       "Colchester, England                                2\n",
       "Birmingham, England                                5\n",
       "Dundee, Scotland                                   1\n",
       "Bury St Edmunds, England                           1\n",
       "Cambridgeshire                                     1\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a sample of the job locations scraped from glassdoor.co.uk\n",
    "gdjobs['location'].value_counts().sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm interested in being able to look at jobs by region or city, etc. To make this possible, I will enrich the data set using the Ordinance Survey API to parse the location given by each employer, such that all parts of the job location are recorded in the DataFrame. For this purpose I have written the function `get_locations`, which is in the `function_locationapi.py` script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 727/727 [01:30<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 727 entries, 0 to 726\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   job_title               727 non-null    object \n",
      " 1   salary_estimate         453 non-null    object \n",
      " 2   job_description         724 non-null    object \n",
      " 3   rating                  587 non-null    float64\n",
      " 4   company_name            727 non-null    object \n",
      " 5   location                727 non-null    object \n",
      " 6   size                    629 non-null    object \n",
      " 7   founded                 508 non-null    float64\n",
      " 8   type_of_ownership       629 non-null    object \n",
      " 9   industry                553 non-null    object \n",
      " 10  sector                  555 non-null    object \n",
      " 11  revenue                 629 non-null    object \n",
      " 12  rating_culturevalues    572 non-null    float64\n",
      " 13  rating_worklifebalance  583 non-null    float64\n",
      " 14  rating_diversity        451 non-null    float64\n",
      " 15  rating_seniormgmt       582 non-null    float64\n",
      " 16  rating_compbenefits     583 non-null    float64\n",
      " 17  rating_careerops        583 non-null    float64\n",
      " 18  api_citytownvilham      694 non-null    object \n",
      " 19  api_region              694 non-null    object \n",
      " 20  api_country             698 non-null    object \n",
      " 21  uk                      727 non-null    bool   \n",
      " 22  remote                  727 non-null    bool   \n",
      "dtypes: bool(2), float64(8), object(13)\n",
      "memory usage: 120.8+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from function_locationapi import get_locations\n",
    "\n",
    "gdjobs_loc = get_locations(\n",
    "    scrapedate='14Dec2020', \n",
    "    path='./data/')\n",
    "\n",
    "# display dataframe info to check that it's what you expected\n",
    "gdjobs_loc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 new columns have been added by `get_locations()`  after using the Ordinance Survey API to parse the locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>api_citytownvilham</th>\n",
       "      <th>api_region</th>\n",
       "      <th>api_country</th>\n",
       "      <th>uk</th>\n",
       "      <th>remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Staines, England</td>\n",
       "      <td>Staines-upon-Thames</td>\n",
       "      <td>South East</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Greater London</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>London, England</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Stockport, England</td>\n",
       "      <td>Stockport</td>\n",
       "      <td>North West</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Derby, England</td>\n",
       "      <td>Derby</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>London, England</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Newcastle upon Tyne, England</td>\n",
       "      <td>Newcastle upon Tyne</td>\n",
       "      <td>North East</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>London, England</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Cheltenham, England</td>\n",
       "      <td>Cheltenham</td>\n",
       "      <td>South West</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         location   api_citytownvilham     api_region  \\\n",
       "196              Staines, England  Staines-upon-Thames     South East   \n",
       "590                Greater London               London         London   \n",
       "512               London, England               London         London   \n",
       "275            Stockport, England            Stockport     North West   \n",
       "135                Derby, England                Derby  East Midlands   \n",
       "627               London, England               London         London   \n",
       "503  Newcastle upon Tyne, England  Newcastle upon Tyne     North East   \n",
       "181               London, England               London         London   \n",
       "198           Cheltenham, England           Cheltenham     South West   \n",
       "54                 United Kingdom                  NaN            NaN   \n",
       "\n",
       "    api_country     uk  remote  \n",
       "196     England  False   False  \n",
       "590     England  False   False  \n",
       "512     England  False   False  \n",
       "275     England  False   False  \n",
       "135     England  False   False  \n",
       "627     England  False   False  \n",
       "503     England  False   False  \n",
       "181     England  False   False  \n",
       "198     England  False   False  \n",
       "54          NaN   True   False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdjobs_loc[['location', 'api_citytownvilham', 'api_region', 'api_country', 'uk', 'remote']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning: checking and cleaning each column as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll look at the values in each column to decide and implement any necessary cleaning of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist (KTP Associate)                              1\n",
      "NGS Product Integration Scientist                           1\n",
      "Data Scientist / Operational Researcher                     2\n",
      "Senior Data Scientist - Product                             1\n",
      "Principal Applied Scientist                                 1\n",
      "Lead Data Scientist, Performance Marketing (Belfast, UK)    2\n",
      "Senior Data Scientist - Crop Modeller R&D                   1\n",
      "Commercial Data Analyst                                     1\n",
      "Customer Data Scientist                                     1\n",
      "Data Scientist - Reinforcement Learning                     1\n",
      "Data Scientist Python PhD                                   1\n",
      "Data Science Manager                                        6\n",
      "Artificial Intelligence – Data Scientist                    1\n",
      "Chemical Development Scientist                              1\n",
      "Data Science Communicator                                   1\n",
      "Data Scientist - Defence                                    1\n",
      "Analytical Scientist 1                                      1\n",
      "Data Scientist - NLP                                        2\n",
      "Data Scientist | Python | NLP | London | Contract           1\n",
      "Customer-Facing Data Scientists                             1\n",
      "Name: job_title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check what the job titles look like\n",
    "print(gdjobs_loc['job_title'].value_counts().sample(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job titles seem to have been scraped appropriately; there are no cleaning requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£24K-£44K (Glassdoor Est.)     1\n",
      "£39K-£44K (Glassdoor Est.)     1\n",
      "£24K-£32K (Glassdoor Est.)     1\n",
      "£40K-£52K (Glassdoor Est.)    46\n",
      "£66K-£92K (Glassdoor Est.)     2\n",
      "£33K-£51K (Glassdoor Est.)     2\n",
      "£35K-£64K (Glassdoor Est.)     1\n",
      "£26K-£32K (Glassdoor Est.)     2\n",
      "£43K-£70K (Glassdoor Est.)     1\n",
      "£48K-£60K (Glassdoor Est.)     1\n",
      "Name: salary_estimate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check what the salary estimates look like\n",
    "print(gdjobs_loc['salary_estimate'].value_counts().sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to analyse the salary estimates I will need to isolate the numbers.\n",
    "\n",
    "It looks like all scraped salary estimates:\n",
    "- are given as ranges\n",
    "- are in GBP ('£'),\n",
    "- are per annum salaries (implied by the use of 'K' to denote thousands), and \n",
    "- end with '(Glassdoor Est.)'\n",
    "\n",
    "Before I go ahead with the cleaning, I will check whether my assumptions (above) are true to spot and address any exceptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All salaries are given as a range; no exceptions to deal with\n"
     ]
    }
   ],
   "source": [
    "# check if all salaries include a '-' (hyphen) indicating a range \n",
    "if (gdjobs_loc['salary_estimate'].dropna().str.contains('-').all()):\n",
    "    print('All salaries are given as a range; no exceptions to deal with')\n",
    "else:\n",
    "    # calculate what proportion of salary estimates are not given as a range\n",
    "    ppn_range = gdjobs_loc['salary_estimate'].dropna().str.contains('-').mean().round(2)\n",
    "    print(f\"The vast majority of Glassdoor salary estimates ({(100-ppn_range)*100}%) are given as a range\")\n",
    "    print(\"Salaries given as a single value will be used for the salary estimate midpoint directly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not all salaries are in GBP:\n",
      "\n",
      "227     $86K-$142K (Glassdoor Est.)\n",
      "471    $120K-$253K (Glassdoor Est.)\n",
      "Name: salary_estimate, dtype: object\n",
      "\n",
      "Jobs with non-GBP salary estimates removed\n"
     ]
    }
   ],
   "source": [
    "# check if all salaries are in GBP (£)\n",
    "all_gbp = gdjobs_loc['salary_estimate'].dropna().str.contains('\\£').all()\n",
    "\n",
    "if not all_gbp:\n",
    "    nongbp_se = gdjobs_loc[gdjobs_loc[\"salary_estimate\"].str.contains('\\£') == False]['salary_estimate']\n",
    "    print(f\"Not all salaries are in GBP:\\n\\n{nongbp_se}\\n\")\n",
    "    gdjobs_loc = gdjobs_loc.drop(labels=nongbp_se.index, axis='index')\n",
    "    print(\"Jobs with non-GBP salary estimates removed\")\n",
    "else:\n",
    "    print(\"All salaries are in GBP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All salaries are in thousands, denoted with a 'K'\n"
     ]
    }
   ],
   "source": [
    "# check if all salaries are in thousands (K) \n",
    "all_k = gdjobs_loc['salary_estimate'].dropna().astype(str).str.contains('K').all()\n",
    "\n",
    "if not all_k:\n",
    "    nonk_se = gdjobs_loc[gdjobs_loc[\"salary_estimate\"].astype(str).str.contains('K') == False]['salary_estimate']\n",
    "    print(f\"Not all salaries are in thousands (K; indicating annual salary):\\n\\n{nonk_se}\\n\")\n",
    "    gdjobs_loc.loc[nonk_se.index, \"salary_estimate\"] = np.nan\n",
    "    print(\"These have been converted to 'np.nan'\")\n",
    "else:\n",
    "    print(\"All salaries are in thousands, denoted with a 'K'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All salary estimates end in \"(Glassdoor Est.)\"\n"
     ]
    }
   ],
   "source": [
    "# check if all salaries end in \"(Glassdoor Est.)\"\n",
    "all_gdest = gdjobs_loc['salary_estimate'].dropna().astype(str).str.contains('(Glassdoor Est.)').all()\n",
    "\n",
    "if all_gdest:\n",
    "    print('All salary estimates end in \"(Glassdoor Est.)\"')\n",
    "else:\n",
    "    nongdest_se = gdjobs_loc[gdjobs_loc[\"salary_estimate\"].str.contains('(Glassdoor Est.)') == False]['salary_estimate']\n",
    "    print(f'Not all salaries end in \"(Glassdoor Est.)\":\\n\\n{nongdest_se}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to analyse the salary estimates more easily, I will:\n",
    "- remove all instances of \"£\", \"K\" and \"(Glassdoor Est.)\", \n",
    "- split salary ranges into min and max salary, and convert these data to numerical values\n",
    "- calculate the midpoint of the salary range by taking the mean of the min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "0     54-69\n",
      "1     58-80\n",
      "2     26-27\n",
      "10    35-40\n",
      "11    26-32\n",
      "13    46-51\n",
      "14    58-77\n",
      "15    29-38\n",
      "16    61-69\n",
      "17    51-70\n",
      "Name: salary_estimate, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# remove \"£\" and \"K\" from the salary_estimate column\n",
    "gdjobs_loc['salary_estimate'] = gdjobs_loc['salary_estimate'].str.replace('[K£]', '')\n",
    "\n",
    "# remove \"(Glassdoor Est.)\" by splitting string on \"(\" and keeping only the first part\n",
    "gdjobs_loc[\"salary_estimate\"] = gdjobs_loc[\"salary_estimate\"].apply(\n",
    "    lambda x: x if pd.isna(x) else x.split(\" (\")[0])\n",
    "\n",
    "# check if any instances of \"£\", \"K\", or \"(Glassdoor Est.)\" remain\n",
    "print(gdjobs_loc['salary_estimate'].str.contains('\\£').any())\n",
    "print(gdjobs_loc['salary_estimate'].str.contains('K').any())\n",
    "print(gdjobs_loc['salary_estimate'].str.contains('(Glassdoor Est.)').any())\n",
    "\n",
    "# check how the values look now\n",
    "print(gdjobs_loc['salary_estimate'].dropna().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    salary_estimate salary_min salary_max  salary_mid\n",
      "633           47-67         47         67        57.0\n",
      "15            29-38         29         38        33.5\n",
      "182           61-91         61         91        76.0\n",
      "16            61-69         61         69        65.0\n",
      "526           39-56         39         56        47.5\n",
      "552           45-62         45         62        53.5\n",
      "89            34-45         34         45        39.5\n",
      "275           37-50         37         50        43.5\n",
      "378           36-47         36         47        41.5\n",
      "616           42-52         42         52        47.0\n"
     ]
    }
   ],
   "source": [
    "# extract the min, max and mid-point of the salary estimate, where a range is given\n",
    "# split string on \"-\" and take first part\n",
    "gdjobs_loc[\"salary_min\"] = gdjobs_loc[\"salary_estimate\"].apply(\n",
    "    lambda x: x if (pd.isna(x) or (\"-\" not in x)) else x.split(\"-\")[0]\n",
    ")\n",
    "\n",
    "# max; split string on \"-\" and take second part\n",
    "gdjobs_loc[\"salary_max\"] = gdjobs_loc[\"salary_estimate\"].apply(\n",
    "    lambda x: x if (pd.isna(x) or (\"-\" not in x)) else x.split(\"-\")[1]\n",
    ")\n",
    "\n",
    "# convert the min and max to numerical values and get the midpoint\n",
    "gdjobs_loc[\"salary_mid\"] = gdjobs_loc.apply(\n",
    "    lambda x: x[\"salary_estimate\"] if pd.isna(x[\"salary_estimate\"]) else np.mean(\n",
    "        pd.to_numeric([x[\"salary_min\"], x[\"salary_max\"]])\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# check for the expected output\n",
    "print(gdjobs_loc[[\n",
    "    \"salary_estimate\", \n",
    "    \"salary_min\", \n",
    "    \"salary_max\", \n",
    "    \"salary_mid\"]].dropna().sample(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the questions I am interested in, I need all job ads in my data set to have a description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    722\n",
       "True       3\n",
       "Name: job_description, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for jobs that lack a description\n",
    "gdjobs_loc['job_description'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove jobs that don't have a description\n",
    "gdjobs_loc = gdjobs_loc[gdjobs_loc['job_description'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305                       infarm\\n4.1\n",
      "717                   G-Research\\n4.7\n",
      "297     British American Tobacco\\n4.0\n",
      "42                         Logic Plum\n",
      "211                   Kelkoo LTD\\n4.4\n",
      "436                        Abcam\\n4.8\n",
      "99     Amida Recruitment Limited\\n4.4\n",
      "281       Next Phase Recruitment\\n4.0\n",
      "384                    Taylorollinson\n",
      "386                    causaLens\\n4.5\n",
      "Name: company_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check what the scraped company names look like\n",
    "print(gdjobs_loc[\"company_name\"].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a company has a Glassdoor rating, it appears with the company's name on the website. My scraping tool has captured both the company's name and rating together, separated by a new line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the company rating has already been scraped separately and recorded in it's own column (`rating`), I'll simply remove it from the `company_name` column. I'll check each job for a rating, and when there is one, the last 4 characters of the company name will be excluded to remove the rating and new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91              GlaxoSmithKline\n",
      "409                 esure Group\n",
      "445                   CitizenMe\n",
      "348                   Sartorius\n",
      "695                       Tesco\n",
      "2                   BioGrad Ltd\n",
      "342                       Ipsos\n",
      "310      Novation Solutions Ltd\n",
      "115                 AstraZeneca\n",
      "260    Public Sector Resourcing\n",
      "Name: company_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# remove the company rating from the company name\n",
    "gdjobs_loc[\"company_name\"] = gdjobs_loc.apply(\n",
    "    lambda x: x[\"company_name\"] if pd.isna(x[\"rating\"]) else x[\"company_name\"][:-4], axis=1\n",
    ")\n",
    "print(gdjobs_loc[\"company_name\"].sample(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 to 50 Employees          118\n",
      "10000+ Employees           157\n",
      "1001 to 5000 Employees      92\n",
      "201 to 500 Employees        54\n",
      "5001 to 10000 Employees     21\n",
      "501 to 1000 Employees       34\n",
      "51 to 200 Employees        124\n",
      "Unknown                     25\n",
      "NaN                         97\n",
      "Name: size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check what the company sizes look like\n",
    "print(gdjobs_loc[\"size\"].value_counts(dropna=False).sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 issues with the `size` column:\n",
    "- Each size bracket ends with the word \"Employees\", which isn't necessary: this should be removed\n",
    "- The size values are intervals/bins of number of employees, which are essentially ordered categories, but the data type of the column is pandas object (or python string), which take up more memory than categories: I'll change the data type from object to category, specifying the order, so that the data are plotted appropriately\n",
    "- Some companies have a size called \"Unknown\": I'll convert these to NaN values so that they are excluded from analyses and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55855"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check memory usage before changing to categorical data type\n",
    "gdjobs_loc[\"size\"].memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn \"Unknown\" entries to nan values and remove \" Employees\" (10 chars) from the end\n",
    "gdjobs_loc[\"size\"] = gdjobs_loc[\"size\"].apply(\n",
    "    lambda x: np.nan if (x == \"Unknown\" or pd.isna(x)) else x[:-10]\n",
    ")\n",
    "\n",
    "# create an ordered categorical data type to apply to the 'size' column\n",
    "size_cat_type = CategoricalDtype( # CategoricalDtype allows ordering\n",
    "    categories=[\n",
    "        '1 to 50',\n",
    "        '51 to 200',\n",
    "        '201 to 500',\n",
    "        '501 to 1000',\n",
    "        '1001 to 5000',\n",
    "        '5001 to 10000',\n",
    "        '10000+'\n",
    "    ],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# change the data type to size_cat_type\n",
    "gdjobs_loc[\"size\"] = gdjobs_loc[\"size\"].astype(size_cat_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7265"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check memory usage after changing to categorical data type\n",
    "gdjobs_loc[\"size\"].memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are now in the appropriate format and using much less memory, which will make the analyses run more quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Founded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348    1870.0\n",
      "14        NaN\n",
      "504    1987.0\n",
      "668       NaN\n",
      "107    1993.0\n",
      "696    2017.0\n",
      "217    1991.0\n",
      "238    2017.0\n",
      "497    2015.0\n",
      "242    2007.0\n",
      "Name: founded, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check what the founded year values look like\n",
    "print(gdjobs_loc[\"founded\"].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year in which each company was founded are in floating point number format; I'll convert these to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     2007\n",
      "517    <NA>\n",
      "223    1987\n",
      "410    <NA>\n",
      "684    2005\n",
      "592    <NA>\n",
      "425    1992\n",
      "569    2010\n",
      "327    <NA>\n",
      "266    <NA>\n",
      "Name: founded, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# change the data type of the founded column\n",
    "gdjobs_loc[\"founded\"] = gdjobs_loc[\"founded\"].astype('Int64')\n",
    "print(gdjobs_loc[\"founded\"].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "College / University               15\n",
      "Company - Private                 385\n",
      "Company - Public                  174\n",
      "Contract                            1\n",
      "Government                          8\n",
      "Hospital                            2\n",
      "Nonprofit Organization              8\n",
      "Other Organization                  2\n",
      "Private Practice / Firm             1\n",
      "Subsidiary or Business Segment     25\n",
      "Unknown                             4\n",
      "NaN                                97\n",
      "Name: type_of_ownership, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check what the type of ownership values look like\n",
    "print(gdjobs_loc[\"type_of_ownership\"].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will take the valid values found in the jobs data set scraped on 14 Dec 2020 to create a categorical data type using CategoricalDtype; this will remove np.nan values and turn anything not listed in the CategoricalDtype into np.nan values as well. Changing the data type of the `type_of_ownership` column from pandas object/python string to categorical will also reduce memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company - Private                 385\n",
       "Company - Public                  174\n",
       "NaN                               103\n",
       "Subsidiary or Business Segment     25\n",
       "College / University               15\n",
       "Government                          8\n",
       "Nonprofit Organization              8\n",
       "Hospital                            2\n",
       "Contract                            1\n",
       "Private Practice / Firm             1\n",
       "Name: type_of_ownership, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an categorical data type to apply to the 'type_of_ownership' column\n",
    "too_cat_type = CategoricalDtype( \n",
    "    categories=[\n",
    "        'Company - Private',\n",
    "        'Company - Public',\n",
    "        'Subsidiary or Business Segment',\n",
    "        'College / University',\n",
    "        'Government',\n",
    "        'Nonprofit Organization',\n",
    "        'Hospital',\n",
    "        'Contract',\n",
    "        'Private Practice / Firm',\n",
    "    ],\n",
    "    ordered=False\n",
    ")\n",
    "\n",
    "# change the data type of gdjobs_loc[\"type_of_ownership\"] to too_cat_type\n",
    "gdjobs_loc[\"type_of_ownership\"] = gdjobs_loc[\"type_of_ownership\"].astype(too_cat_type)\n",
    "gdjobs_loc[\"type_of_ownership\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Unknown' and 'Other Organization' values, not included in the categories of the `too_cat_type` CategoricalDtype, were automatically converted to NaN values, when `too_cat_type` was applied to `gdjobs[\"type_of_ownership\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounting                                     7\n",
      "Advertising & Marketing                        7\n",
      "Aerospace & Defense                            8\n",
      "Airlines                                       1\n",
      "Architectural & Engineering Services           7\n",
      "Banks & Credit Unions                         15\n",
      "Beauty & Personal Accessories Stores           1\n",
      "Biotech & Pharmaceuticals                     68\n",
      "Brokerage Services                             3\n",
      "Cable, Internet & Telephone Providers          2\n",
      "Camping & RV Parks                             1\n",
      "Chemical Manufacturing                         1\n",
      "Colleges & Universities                       15\n",
      "Commercial Equipment Repair & Maintenance      1\n",
      "Computer Hardware & Software                  20\n",
      "Construction                                   1\n",
      "Consulting                                    33\n",
      "Consumer Products Manufacturing                4\n",
      "Department, Clothing, & Shoe Stores           10\n",
      "Drug & Health Stores                           3\n",
      "Education Training Services                    5\n",
      "Electrical & Electronic Manufacturing          1\n",
      "Energy                                         4\n",
      "Enterprise Software & Network Solutions       39\n",
      "Federal Agencies                               6\n",
      "Financial Analytics & Research                 3\n",
      "Financial Transaction Processing               9\n",
      "Food & Beverage Stores                         5\n",
      "Food Production                                1\n",
      "Grocery Stores & Supermarkets                  3\n",
      "Health Care Products Manufacturing             2\n",
      "Health Care Services & Hospitals               9\n",
      "Health Fundraising Organizations               1\n",
      "Home Furniture & Housewares Stores             1\n",
      "Hotels, Motels, & Resorts                      1\n",
      "IT Services                                   24\n",
      "Industrial Manufacturing                       3\n",
      "Insurance Agencies & Brokerages                2\n",
      "Insurance Carriers                            15\n",
      "Internet                                      43\n",
      "Investment Banking & Asset Management         10\n",
      "Lending                                       10\n",
      "Logistics & Supply Chain                       3\n",
      "Mining                                         1\n",
      "Motion Picture Production & Distribution       1\n",
      "Oil & Gas Services                             2\n",
      "Other Retail Stores                            2\n",
      "Publishing                                     4\n",
      "Real Estate                                    1\n",
      "Research & Development                        10\n",
      "Social Assistance                              1\n",
      "Sports & Recreation                            2\n",
      "Staffing & Outsourcing                       101\n",
      "TV Broadcast & Cable Networks                  7\n",
      "Talent & Modeling Agencies                     3\n",
      "Telecommunications Services                    3\n",
      "Transportation Equipment Manufacturing         1\n",
      "Utilities                                      1\n",
      "Video Games                                    1\n",
      "NaN                                          173\n",
      "Name: industry, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check what the industry values look like\n",
    "print(gdjobs_loc[\"industry\"].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll switch the data type from pandas object to 'category' to reduce the memory usage when working with this column going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if there are any 'Unknown' industries, convert these to np.nan\n",
    "# gdjobs_loc[\"industry\"] = gdjobs_loc.apply(lambda x: np.nan if (x[\"industry\"] == \"Unknown\") else x[\"industry\"], axis=1)\n",
    "\n",
    "# change the industry column's data type from object to category\n",
    "gdjobs_loc[\"industry\"] = gdjobs_loc[\"industry\"].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounting & Legal                      7\n",
      "Aerospace & Defense                     8\n",
      "Agriculture & Forestry                  1\n",
      "Arts, Entertainment & Recreation        5\n",
      "Biotech & Pharmaceuticals              68\n",
      "Business Services                     158\n",
      "Construction, Repair & Maintenance      2\n",
      "Education                              20\n",
      "Finance                                50\n",
      "Government                              6\n",
      "Health Care                             9\n",
      "Information Technology                126\n",
      "Insurance                              17\n",
      "Manufacturing                          12\n",
      "Media                                  13\n",
      "Mining & Metals                         1\n",
      "Non-Profit                              2\n",
      "Oil, Gas, Energy & Utilities            7\n",
      "Real Estate                             1\n",
      "Retail                                 27\n",
      "Telecommunications                      5\n",
      "Transportation & Logistics              3\n",
      "Travel & Tourism                        3\n",
      "NaN                                   171\n",
      "Name: sector, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check what the sector values look like\n",
    "print(gdjobs_loc[\"sector\"].value_counts(dropna=False).sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll switch the data type from pandas object to 'category' to reduce the memory usage when working with this column going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if there are any 'Unknown' sectors, convert these to np.nan\n",
    "# gdjobs_loc[\"sector\"] = gdjobs_loc.apply(lambda x: np.nan if (x[\"sector\"] == \"Unknown\") else x[\"sector\"], axis=1)\n",
    "\n",
    "# change the sector column's data type from object to category\n",
    "gdjobs_loc[\"sector\"] = gdjobs_loc[\"sector\"].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown / Non-Applicable            218\n",
      "NaN                                  97\n",
      "Less than $1 million (USD)           92\n",
      "$10+ billion (USD)                   80\n",
      "$100 to $500 million (USD)           48\n",
      "$5 to $10 billion (USD)              36\n",
      "$25 to $50 million (USD)             27\n",
      "$10 to $25 million (USD)             25\n",
      "$2 to $5 billion (USD)               25\n",
      "$50 to $100 million (USD)            21\n",
      "$500 million to $1 billion (USD)     21\n",
      "$1 to $5 million (USD)               19\n",
      "$1 to $2 billion (USD)                7\n",
      "$5 to $10 million (USD)               6\n",
      "Name: revenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check what the revenue values look like\n",
    "print(gdjobs_loc[\"revenue\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Unknown / Non-Applicable' values need to be converted to NaN values. I'll convert the `revenue` values from string objects to CategoricalDtype with an ordered list of valid values, so everything else (in this case, 'Unknown / Non-Applicable') is changed to a NaN value. Changing the data type of the `revenue` column from pandas object/python string to CategoricalDtype will also reduce memory usage and make plotting the data more straightforward, since the categories will be correctly ordered in any plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Less than $1 million (USD)           92\n",
       "$1 to $5 million (USD)               19\n",
       "$5 to $10 million (USD)               6\n",
       "$10 to $25 million (USD)             25\n",
       "$25 to $50 million (USD)             27\n",
       "$50 to $100 million (USD)            21\n",
       "$100 to $500 million (USD)           48\n",
       "$500 million to $1 billion (USD)     21\n",
       "$1 to $2 billion (USD)                7\n",
       "$2 to $5 billion (USD)               25\n",
       "$5 to $10 billion (USD)              36\n",
       "$10+ billion (USD)                   80\n",
       "NaN                                 315\n",
       "Name: revenue, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if there are any \"Unknown / Non-Applicable\" revenues, convert these to np.nan\n",
    "gdjobs_loc[\"revenue\"] = gdjobs_loc.apply(lambda x: np.nan if (x[\"revenue\"] == \"Unknown / Non-Applicable\") else x[\"revenue\"], axis=1)\n",
    "\n",
    "revenue_cat_type = CategoricalDtype(\n",
    "    categories=[\n",
    "        'Less than $1 million (USD)',\n",
    "        '$1 to $5 million (USD)',\n",
    "        '$5 to $10 million (USD)',\n",
    "        '$10 to $25 million (USD)',\n",
    "        '$25 to $50 million (USD)',\n",
    "        '$50 to $100 million (USD)',\n",
    "        '$100 to $500 million (USD)',\n",
    "        '$500 million to $1 billion (USD)',\n",
    "        '$1 to $2 billion (USD)',\n",
    "        '$2 to $5 billion (USD)',\n",
    "        '$5 to $10 billion (USD)',\n",
    "        '$10+ billion (USD)',\n",
    "    ],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "gdjobs_loc[\"revenue\"] = gdjobs_loc[\"revenue\"].astype(revenue_cat_type)\n",
    "gdjobs_loc[\"revenue\"].value_counts(dropna=False).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The former 'Unknown / Non-Applicable' are now correctly included with the np.nan ('NaN') values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were up to 6 different subratings for each company when the Glassdoor website was scraped (14 Dec 2020). There is a column for each in the gdjobs DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the subrating column headers\n",
    "subratings = [\n",
    "    \"rating_culturevalues\",\n",
    "    \"rating_worklifebalance\",\n",
    "    \"rating_diversity\",\n",
    "    \"rating_seniormgmt\",\n",
    "    \"rating_compbenefits\",\n",
    "    \"rating_careerops\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 722 entries, 0 to 726\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   rating_culturevalues    567 non-null    float64\n",
      " 1   rating_worklifebalance  578 non-null    float64\n",
      " 2   rating_diversity        446 non-null    float64\n",
      " 3   rating_seniormgmt       577 non-null    float64\n",
      " 4   rating_compbenefits     578 non-null    float64\n",
      " 5   rating_careerops        578 non-null    float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 39.5 KB\n"
     ]
    }
   ],
   "source": [
    "# get info on the subrating columns in the jobs dataset dataframe\n",
    "gdjobs_loc[subratings].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_culturevalues</th>\n",
       "      <th>rating_worklifebalance</th>\n",
       "      <th>rating_diversity</th>\n",
       "      <th>rating_seniormgmt</th>\n",
       "      <th>rating_compbenefits</th>\n",
       "      <th>rating_careerops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_culturevalues  rating_worklifebalance  rating_diversity  \\\n",
       "0                   4.0                     3.9               NaN   \n",
       "1                   4.7                     4.6               4.5   \n",
       "2                   NaN                     NaN               NaN   \n",
       "3                   2.9                     2.6               3.4   \n",
       "4                   3.2                     3.1               3.4   \n",
       "\n",
       "   rating_seniormgmt  rating_compbenefits  rating_careerops  \n",
       "0                3.7                  3.8               4.1  \n",
       "1                4.4                  4.4               4.3  \n",
       "2                NaN                  NaN               NaN  \n",
       "3                2.7                  3.6               3.5  \n",
       "4                2.8                  3.3               2.9  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what the subratings values look like\n",
    "gdjobs_loc[subratings].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check that all subratings are either NaN or a value between 0 and 5 with 1 d.p.\n",
    "for i in subratings:\n",
    "    print(\n",
    "        np.all(\n",
    "            gdjobs_loc[i].apply(\n",
    "                lambda x: pd.isna(x) or ((x*10 == np.floor(x*10)) and (x<=5 and x>0))\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data type for every subrating column is float64, and the values are either numbers between 0 and 5 rounded to 1 d.p. or NaN, no cleaning is necessary in order to analyse and plot these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsed job location columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_loc_cols = [\n",
    "    'api_citytownvilham', \n",
    "    'api_region', \n",
    "    'api_country', \n",
    "    'uk', \n",
    "    'remote'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 722 entries, 0 to 726\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   api_citytownvilham  689 non-null    object\n",
      " 1   api_region          689 non-null    object\n",
      " 2   api_country         693 non-null    object\n",
      " 3   uk                  722 non-null    bool  \n",
      " 4   remote              722 non-null    bool  \n",
      "dtypes: bool(2), object(3)\n",
      "memory usage: 24.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# get info on the parsed_loc_cols columns in the jobs dataset dataframe\n",
    "gdjobs_loc[parsed_loc_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London        375\n",
      "Cambridge      47\n",
      "Manchester     22\n",
      "Edinburgh      17\n",
      "Reading        13\n",
      "Name: api_citytownvilham, dtype: int64 \n",
      "\n",
      "London             386\n",
      "East of England     80\n",
      "South East          56\n",
      "North West          40\n",
      "Scotland            30\n",
      "Name: api_region, dtype: int64 \n",
      "\n",
      "England             641\n",
      "Scotland             30\n",
      "Northern Ireland     12\n",
      "Wales                10\n",
      "Name: api_country, dtype: int64 \n",
      "\n",
      "False    708\n",
      "True      14\n",
      "Name: uk, dtype: int64 \n",
      "\n",
      "False    710\n",
      "True      12\n",
      "Name: remote, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check what the values in each location column looks like\n",
    "for i in parsed_loc_cols:\n",
    "    print(gdjobs_loc[i].value_counts().head(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value counts of the columns created from parsing the scraped locations using the Ordinance Survery API look as we'd expect. However, I'll turn the `api_region` and `api_country` columns into categorical data to reduce their memory usage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 722 entries, 0 to 726\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   api_citytownvilham  689 non-null    object  \n",
      " 1   api_region          689 non-null    category\n",
      " 2   api_country         693 non-null    category\n",
      " 3   uk                  722 non-null    bool    \n",
      " 4   remote              722 non-null    bool    \n",
      "dtypes: bool(2), category(2), object(1)\n",
      "memory usage: 14.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# change the sector api_region and api_country columns data type to category\n",
    "gdjobs_loc[\"api_region\"] = gdjobs_loc[\"api_region\"].astype(\"category\")\n",
    "gdjobs_loc[\"api_country\"] = gdjobs_loc[\"api_country\"].astype(\"category\")\n",
    "\n",
    "# get info on the parsed_loc_cols columns in the jobs dataset dataframe\n",
    "gdjobs_loc[parsed_loc_cols].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove irrelevant jobs based on job titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin our exploratory data analysis, we want to make sure we're analysing only data scientist roles. \n",
    "\n",
    "When you search glassdoor.co.uk for a \"data scientist\" roles, jobs with wide-ranging titles are returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561                                            Data Scientist\n",
      "338       Associate Laboratory Scientist - Clinical Pathology\n",
      "351                                             Data Engineer\n",
      "190          Data Scientist Degree Apprenticeship, Ware, 2021\n",
      "456                                      Head of Data Science\n",
      "559                                            Data Scientist\n",
      "186    Transport Data Scientist, real world logistic analysis\n",
      "544                                            Data Scientist\n",
      "104                Senior Data Scientist - R&D Remote Sensing\n",
      "208                       Senior Data Scientist (Forecasting)\n",
      "556                                            Data Scientist\n",
      "240                                     Senior Data Scientist\n",
      "19                 Enzymology & Protein Engineering Scientist\n",
      "95                                               Data Analyst\n",
      "267                    Senior Data Scientist - Bioinformatics\n",
      "680                                   Curious Data Scientists\n",
      "371                     Data Scientist - Energy-Tech Start-Up\n",
      "47                                             Data Scientist\n",
      "52                                             Data Scientist\n",
      "578              Cardiovascular Renal and Metabolic Scientist\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# run the code below as many times as you like \n",
    "# to get an impression of the wide-ranging job titles\n",
    "\n",
    "# print 20 random job titles from the glassdoor data set\n",
    "print(gdjobs_loc[\"job_title\"].sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having scanned the job titles (above), I have identified 6 categories of job titles returned by GlassDoor when searching for a \"data scientist\":\n",
    "\n",
    "1. Data Scientist\n",
    "2. Data Analyst\n",
    "3. Data Engineer\n",
    "4. Machine Learning/AI Engineer or Specialist\n",
    "5. Researcher\n",
    "6. Intern/Apprentice\n",
    "\n",
    "While there is overlap between all of these roles, I want to focus my analysis on jobs that best match what is commonly considered to be the role of a data scientist: an inter-disciplinary role to extract knowledge and insights from many structural and unstructured data using scientific methods, processes, and algorithms (often involving data mining, machine learning and big data).\n",
    "\n",
    "I will use regular expressions to identify whether each job title in the dataset matches any of the 6 title categories identified above, and create boolean columns to record the match results for each so that they can be used as masks to filter the data. I will use the boolean masking to select and scan the descriptions of jobs in each of the title categories (listed above) to see if they reflect a distinct job role, and whether they fit the core data scientist role that I am interested in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_description(jobsdf, col=None):\n",
    "    \"\"\"Print the description of a randomly selected job\n",
    "    \n",
    "    :param jobsdf: jobs data with job descriptions\n",
    "    :type jobsdf: pandas.core.frame.DataFrame\n",
    "    :param col: label of boolean column within jobsdf if you want a sample \n",
    "    job description from a subset of jobs (default None)\n",
    "    :type col: str\n",
    "    \"\"\"\n",
    "    # produce a random integer for the sample function\n",
    "    seed = random.randint(0, 100)\n",
    "    \n",
    "    if col is not None:  # take a sample from jobs that are True in that column\n",
    "        print(f\"\\nDescription of randomly selected job with title, '\",\n",
    "        f\"{jobsdf[jobsdf[col]]['job_title'].sample(random_state=seed).iloc[0]}':\\n\")\n",
    "        print(jobsdf[jobsdf[col]]['job_description'].sample(random_state=seed).iloc[0])\n",
    "    else:  # otherwise take a sample from all jobs\n",
    "        print(f\"\\nDescription of randomly selected job with title, '\",\n",
    "        f\"{jobsdf['job_title'].sample(random_state=seed).iloc[0]}':\\n\")\n",
    "        print(jobsdf['job_description'].sample(random_state=seed).iloc[0])\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474 (66%) job titles indicate 'data scientist' role\n"
     ]
    }
   ],
   "source": [
    "# use a regular expression to identfy \"data scientist\" job titles and \n",
    "# create a boolean mask for this category\n",
    "gdjobs_loc[\"title_datascientist\"] = gdjobs_loc[\"job_title\"].str.contains(\n",
    "    r\"data scientist\", regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# how many job titles indicate \"data scientist\" role? (\"True\" count)\n",
    "print(\n",
    "    f\"{sum(gdjobs_loc.title_datascientist)} ({round((np.mean(gdjobs_loc.title_datascientist))*100)}%)\",\n",
    "    \"job titles indicate 'data scientist' role\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149                                              Senior Data Scientist\n",
       "75     Data Scientist | Python | Tensorflow | Deep Learning | Contract\n",
       "656                                                     Data Scientist\n",
       "190                   Data Scientist Degree Apprenticeship, Ware, 2021\n",
       "659                                            Data Scientist, Digital\n",
       "601                Power, Transmission and Distribution Data Scientist\n",
       "130                                              Senior Data Scientist\n",
       "718          Research Data Scientist, Intern - Infrastructure Strategy\n",
       "421                                           Principal Data Scientist\n",
       "600                                 Data Scientist - Marketing Science\n",
       "196                                              Senior Data Scientist\n",
       "266                                            Data Scientist (Senior)\n",
       "156                                              Senior Data Scientist\n",
       "455                   Senior Data Scientist - Electrical Power Systems\n",
       "170                                       Data Scientist - Consultancy\n",
       "108                     Data Scientist/Engineer - Medical Devices Unit\n",
       "37                                      Junior Data Scientist - London\n",
       "139                       Data Scientist - Remote - £60,000 to £80,000\n",
       "136                                  Data Scientist – Causality Expert\n",
       "696                                            Data Scientist - Remote\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display a random sample of job titles that include the string, \"data scientist\"\n",
    "gdjobs_loc.loc[gdjobs_loc['title_datascientist'],'job_title'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan job descriptions; keep running this cell until you've reviewed enough samples\n",
    "sample_description(jobsdf=gdjobs_loc, col=\"title_datascientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at many random samples of job titles that include \"data scientist\", it often seems to be included as a general title in addition to specialisms, e.g. \"Data Scientist/Engineer\" indicating a Data Engineer role, and \"Remote Data Scientist / Machine Learning Engineer\" specifying a machine learning engineer role, \"AI Ops Data Scientist\" suggesting a DevOps role specialising in AI, and \"Data Scientist / Software Developer\", which would require someone with significant software development skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 (9%) job titles indicate a 'data analyst' role\n"
     ]
    }
   ],
   "source": [
    "# use a regular expression to identfy \"data analyst\" job titles and \n",
    "# create a boolean mask for this category\n",
    "gdjobs_loc[\"title_dataanalyst\"] = gdjobs_loc[\"job_title\"].str.contains(\n",
    "    r\"analy\", regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# how many job titles indicate \"data analyst\" role? (\"True\" count)\n",
    "print(\n",
    "    f\"{sum(gdjobs_loc.title_dataanalyst)} ({round((np.mean(gdjobs_loc.title_dataanalyst))*100)}%)\",\n",
    "    \"job titles indicate a 'data analyst' role\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55                                                     Data Analyst\n",
      "504                                Analytical Outsourcing Scientist\n",
      "128                                                    DATA ANALYST\n",
      "466                         Data Analytics apprenticeship programme\n",
      "407          Senior Data Scientist - Innovation, Advanced Analytics\n",
      "627                               Data Scientist, Product Analytics\n",
      "48         Data Scientist, Data Analyst, Data Visualisation, Python\n",
      "497                                     Risk & Control Data Analyst\n",
      "95                                                     Data Analyst\n",
      "13                    Finance Data Analyst - Growth and Forecasting\n",
      "375                                         Business Analyst (Data)\n",
      "462                             Data & Analytics Consultant (m/f/d)\n",
      "573                        Data Science Lead, Reliability Analytics\n",
      "328              Scientific Data Analyst - Machine Learning, Python\n",
      "429                          eCommerce Data Analyst - Book Retailer\n",
      "325                                   Data Analyst, Financial Crime\n",
      "102                                   Senior Data Analyst/Scientist\n",
      "674                             Data Scientist – Customer Analytics\n",
      "285                                  Analytical Chemistry Scientist\n",
      "61     Data Scientist (Video Content Analysis)(KTP Associate), CSEE\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display the job titles that fit the \"data analyst\" category\n",
    "print(gdjobs_loc.loc[gdjobs_loc[\"title_dataanalyst\"],'job_title'].sample(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan job descriptions; keep running this cell until you've reviewed enough samples\n",
    "sample_description(jobsdf=gdjobs_loc, col=\"title_dataanalyst\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having scanned the job descriptions of the data analyst roles that were returned in this search of \"data scientist\" jobs on glass door, there is considerable overlap with the \"data scientist\" roles. However, they don't seem to mention machine learning as often as 'data scientist' roles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 (8%) job titles indicate a 'data engineer' role\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a regular expression to identfy \"data engineer\" job titles and \n",
    "# create a boolean column to record whether or not each job title fits this category\n",
    "gdjobs_loc[\"title_dataengineer\"] = gdjobs_loc[\"job_title\"].str.contains(\n",
    "    r\"data engineer|devops\", regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# how many job titles indicate \"data engineer\" role? (\"True\" count)\n",
    "print(\n",
    "    f\"{sum(gdjobs_loc.title_dataengineer)} ({round((np.mean(gdjobs_loc.title_dataengineer))*100)}%)\",\n",
    "    \"job titles indicate a 'data engineer' role\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288                       Data Engineer\n",
      "284                       Data Engineer\n",
      "365                       Data Engineer\n",
      "478        Data Engineer - Test Analyst\n",
      "393    Data Engineer (Machine Learning)\n",
      "398                       DATA ENGINEER\n",
      "183                 Cloud Data Engineer\n",
      "364                       Data Engineer\n",
      "333                       Data Engineer\n",
      "499                       Data Engineer\n",
      "276                       Data Engineer\n",
      "418     Big Data Engineer (Python Team)\n",
      "270                       Data Engineer\n",
      "436        Data Engineer (12 month FTC)\n",
      "498                       Data Engineer\n",
      "388                Senior Data Engineer\n",
      "287                       Data Engineer\n",
      "339                       Data Engineer\n",
      "440                       Data Engineer\n",
      "275                       Data Engineer\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display the job titles that fit the \"data engineer\" category\n",
    "print(gdjobs_loc.loc[gdjobs_loc[\"title_dataengineer\"],'job_title'].sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan job descriptions; keep running this cell until you've reviewed enough samples\n",
    "sample_description(jobsdf=gdjobs_loc, col=\"title_dataengineer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scanning the description of the \"Data Engineer\" jobs indicates that this role is distinct from a data scientist job; data engineers know how to build an effective data architecture, streamline data processing, and maintain large-scale data systems. In addition to working with Python or R, they likely also work with other languages to create data engineering pipelines, automate common file system tasks, and build high-performance databases. They also need to know how to use cloud and big data tools such as AWS Boto, PySpark, Spark SQL, and MongoDB, to create and query databases, wrangle data, and configure schedules to run pipelines. They need database, scripting, and process skills. We will exclude these positions from our analysis of data science jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Machine Learning/AI Specialist or Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 (6%) job titles indicate a 'machine learning/AI specialist/engineer' role\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a regular expression to identfy \"machine learning/AI specialist/engineer\" job titles and \n",
    "# create a boolean column to record whether or not each job title fits this category\n",
    "gdjobs_loc[\"title_mlai\"] = gdjobs_loc[\"job_title\"].str.contains(\n",
    "    r\"machine learning engineer|ml engineer|machine learning scientist|machine learning|\\bai\\b|artificial intelligence\", \n",
    "    regex=True, \n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "# how many job titles indicate \"machine learning/AI specialist/engineer\" role? (\"True\" count)\n",
    "print(\n",
    "    f\"{sum(gdjobs_loc.title_mlai)} ({round((np.mean(gdjobs_loc.title_mlai))*100)}%)\",\n",
    "    \"job titles indicate a 'machine learning/AI specialist/engineer' role\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412                                               Data and ML Engineer\n",
      "40                                  Applied Machine Learning Scientist\n",
      "403                                Machine Learning Scientist (London)\n",
      "268                  Senior Data Scientist/ Machine Learning Developer\n",
      "254                                      Visiting Scientist, AI (EMEA)\n",
      "368               Applied Scientist in Machine Learning for Simulation\n",
      "481                         AI Scientist - Natural Language Processing\n",
      "7       Senior Data Scientist- (Machine Learning & Advanced Analytics)\n",
      "225    Outside IR35 | Data Scientist | AI | Python | Contract | London\n",
      "228                     Data Scientist - Machine Learning (Python/SQL)\n",
      "419                           Data Science - Machine Learning Research\n",
      "515                     Principal Research Scientist: Machine Learning\n",
      "328                 Scientific Data Analyst - Machine Learning, Python\n",
      "39                                   Data Scientist - Machine Learning\n",
      "618                           Artificial Intelligence – Data Scientist\n",
      "396                                             Visiting Scientist, AI\n",
      "688                                  Data Scientist – Machine Learning\n",
      "257          Applied Machine Learning Scientist (Remote, London-Based)\n",
      "361              Data Scientist - Innovative Applications of Causal AI\n",
      "94                                    Data Engineer (Machine Learning)\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display the job titles that fit the \"machine learning/AI specialist/engineer\" category\n",
    "print(gdjobs_loc.loc[gdjobs_loc[\"title_mlai\"], 'job_title'].sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan job descriptions; keep running this cell until you've reviewed enough samples\n",
    "sample_description(jobsdf=gdjobs_loc, col=\"title_mlai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptions of jobs with titles that include 'machine learning' and 'artificial intelligence', sometimes with term 'engineer', tend to involve researching, designing, building, testing and optimizing machine learning/AI algorithms/models and systems that can learn and be used to make predictions. However, since our glassdoor search was for UK 'data scientist' jobs, the jobs that fall into this category almost always overlap with the general data scientist roles that don't mention ML/AI in the title, many of which still mention machine learning knowledge and skills. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Science or Machine Learning Research Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 (3%) job titles indicate a 'data science or ML research scientist' role\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a regular expression to identfy \"data science or ML research scientist\" job titles \n",
    "# and create a boolean column to record whether or not each job title fits this category\n",
    "gdjobs_loc[\"title_research\"] = gdjobs_loc[\"job_title\"].str.contains(\n",
    "    r\"research\", regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# how many job titles indicate \"data science or ML research scientist\" role? (\"True\" count)\n",
    "print(\n",
    "    f\"{sum(gdjobs_loc.title_research)} ({round((np.mean(gdjobs_loc.title_research))*100)}%)\",\n",
    "    \"job titles indicate a 'data science or ML research scientist' role\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73                                                                  Research Officer and Data Scientist\n",
      "493                                                                         Engineer Research Scientist\n",
      "41                                                              Data Scientist / Operational Researcher\n",
      "410                                                      Senior Data Scientist / Operational Researcher\n",
      "726                                                                    Researcher/Data Scientist - QMUL\n",
      "447    Research Associate III/Senior Research Associate Data Collection Peri- and Post Approval Studies\n",
      "465                                                            Research Scientist Video Compression R&D\n",
      "25                                                                Research Scientist Evidence Synthesis\n",
      "419                                                            Data Science - Machine Learning Research\n",
      "477                                         Imaging Research Scientist (Machine Learning/Deep Learning)\n",
      "642                                                                   Data Scientist - Applied Research\n",
      "695                                                             Data Scientist / Operational Researcher\n",
      "581                                                               Research Scientist – Causality Expert\n",
      "509                                                             919-LO-33499143-EXT -Research Scientist\n",
      "483                                            Research Scientist Peri-and-Post Approval Studies (PPAS)\n",
      "168                                                                             Research Data Scientist\n",
      "22                                                        Senior Research Associate/Associate Scientist\n",
      "522                                           Machine Learning Researcher (NLP, Python, Data Scientist)\n",
      "505                                                              Research Scientist - Protein Scientist\n",
      "583                                                           Quantitative Research Director - Big Data\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display the job titles that fit the \"data science or ML research scientist\" category\n",
    "print(gdjobs_loc.loc[gdjobs_loc[\"title_research\"],\"job_title\"].sample(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan job descriptions; keep running this cell until you've reviewed enough samples\n",
    "sample_description(jobsdf=gdjobs_loc, col=\"title_research\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jobs that include 'research' in the title tend to be more specialised and technical, often require the candidate to have a PhD, and involve researching and coming up with novel solutions/algorithms to address difficult machine learning/deep learning/AI problems. Within this category are jobs that require indepth knowledge/experience within a particular domain, e.g. operations research, biomedical data. Some are University positions, others are within interdisciplinary data science teams within businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data Science Intern/Apprentice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 (2%) job titles indicate a 'data science intern/apprentice' role\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a regular expression to identfy \"data science intern/apprentice\" job titles and create a boolean column to record whether or not each job title fits this category\n",
    "gdjobs_loc[\"title_internapprentice\"] = gdjobs_loc[\"job_title\"].str.contains(\n",
    "    r\"\\binternship|\\bintern\\b|\\bapprentic\", regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# how many job titles indicate \"data science intern/apprentice\" role? (\"True\" count)\n",
    "print(\n",
    "    f\"{sum(gdjobs_loc.title_internapprentice)} ({round((np.mean(gdjobs_loc.title_internapprentice))*100)}%)\",\n",
    "    f\"job titles indicate a 'data science intern/apprentice' role\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43                                              Internship- Data Science\n",
      "159           Data Scientist Degree Apprenticeship, Barnard Castle, 2021\n",
      "179                Data Scientist Degree Apprenticeship, Stevenage, 2021\n",
      "188    Data Scientist Degree Apprenticeship, GSK House (Brentford), 2021\n",
      "190                     Data Scientist Degree Apprenticeship, Ware, 2021\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display the job titles that fit the \"data science intern/apprentice\" category\n",
    "print(gdjobs_loc.loc[gdjobs_loc[\"title_internapprentice\"],'job_title'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan job descriptions; keep running this cell until you've reviewed enough samples\n",
    "sample_description(jobsdf=gdjobs_loc, col=\"title_internapprentice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data science internships and apprenticeships that come up in our search for data science jobs fall into 3 types of roles:\n",
    "- essentially a full data scientist role for new graduates, likely so the company can trial the graduate before hiring\n",
    "- mid-degree industry placement roles\n",
    "- apprenticeships for people leaving school with science a-levels (including a company sponsored data science degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having scanned many of the job descriptions in the GlassDoor \"data scientist\" jobs data set, I believe the Data Scientist role to be best represented by the job titles falling into the following categories *only*:\n",
    "\n",
    "- Data Scientist\n",
    "- Data Analyst\n",
    "- Machine Learning/AI Specialist or Engineer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not those that fall under the following:\n",
    "\n",
    "- Data Engineer\n",
    "- Researcher\n",
    "- Intern/Apprentice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 (71%) job titles indicate a data scientist role (data scientists, analysts and ML/AI specialists/engineers)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a boolean mask for jobs that have titles that fall into the following categories: \n",
    "# \"data scientist\", \"data analyst\", \"machine learning/ai specialist or engineer\"\n",
    "gdjobs_loc[\"datascience_role\"] = (\n",
    "    ((gdjobs_loc[\"title_datascientist\"] == True) | (gdjobs_loc[\"title_mlai\"] == True) | (gdjobs_loc[\"title_dataanalyst\"] == True))\n",
    ") & (\n",
    "    (gdjobs_loc[\"title_internapprentice\"] == False) & (gdjobs_loc[\"title_dataengineer\"] == False) & (gdjobs_loc[\"title_research\"] == False)\n",
    ")\n",
    "\n",
    "# how many job titles indicate a data scientist role? (\"True\" count)\n",
    "print(\n",
    "    f\"{sum(gdjobs_loc.datascience_role)} ({round((np.mean(gdjobs_loc.datascience_role))*100)}%)\",\n",
    "    f\"job titles indicate a data scientist role (data scientists, analysts and ML/AI specialists/engineers)\\n\"\n",
    ")\n",
    "\n",
    "# create a dataframe of data science roles only\n",
    "dsjobs = gdjobs_loc[gdjobs_loc[\"datascience_role\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 511 entries, 0 to 725\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   job_title               511 non-null    object  \n",
      " 1   salary_estimate         322 non-null    object  \n",
      " 2   job_description         511 non-null    object  \n",
      " 3   rating                  399 non-null    float64 \n",
      " 4   company_name            511 non-null    object  \n",
      " 5   location                511 non-null    object  \n",
      " 6   size                    415 non-null    category\n",
      " 7   founded                 348 non-null    Int64   \n",
      " 8   type_of_ownership       428 non-null    category\n",
      " 9   industry                381 non-null    category\n",
      " 10  sector                  383 non-null    category\n",
      " 11  revenue                 271 non-null    category\n",
      " 12  rating_culturevalues    389 non-null    float64 \n",
      " 13  rating_worklifebalance  394 non-null    float64 \n",
      " 14  rating_diversity        296 non-null    float64 \n",
      " 15  rating_seniormgmt       394 non-null    float64 \n",
      " 16  rating_compbenefits     394 non-null    float64 \n",
      " 17  rating_careerops        394 non-null    float64 \n",
      " 18  api_citytownvilham      488 non-null    object  \n",
      " 19  api_region              488 non-null    category\n",
      " 20  api_country             491 non-null    category\n",
      " 21  uk                      511 non-null    bool    \n",
      " 22  remote                  511 non-null    bool    \n",
      " 23  salary_min              322 non-null    object  \n",
      " 24  salary_max              322 non-null    object  \n",
      " 25  salary_mid              322 non-null    float64 \n",
      " 26  title_datascientist     511 non-null    bool    \n",
      " 27  title_dataanalyst       511 non-null    bool    \n",
      " 28  title_dataengineer      511 non-null    bool    \n",
      " 29  title_mlai              511 non-null    bool    \n",
      " 30  title_research          511 non-null    bool    \n",
      " 31  title_internapprentice  511 non-null    bool    \n",
      " 32  datascience_role        511 non-null    bool    \n",
      "dtypes: Int64(1), bool(9), category(7), float64(8), object(8)\n",
      "memory usage: 85.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dsjobs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data have been cleaned, they are ready for feature engineering and analysing! Since some jobs were removed from the data set during the cleaning process, the DataFrame needs to be reindexed before it is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index; 'drop' stops old index being inserted as a column\n",
    "dsjobs.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned dataframe \n",
    "# as a .csv file\n",
    "dsjobs.to_csv(os.path.join(path, f'dsjobs_df_{scrapedate}_postclean.csv'), encoding='utf-8')\n",
    "# as a .pkl file which preserves data types (better for processing steps)\n",
    "dsjobs.to_pickle(os.path.join(path, f'dsjobs_df_{scrapedate}_postclean.pkl'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('eda-proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "ecf77a1a389081cd4a2e68fe826e74ff3c59ede00e7da793e7feb1b74b90842f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
