{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Glassdoor data scientist jobs data set that I enriched, cleaned and reduced in Part 2, I will now extract features from the job titles and \"raw\" job descriptions, to prepare the data for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all columns and rows will be displayed if/when you print the dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# ensure all figures will have a white background in this notebook\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 511 entries, 0 to 510\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   job_title               511 non-null    object  \n",
      " 1   salary_estimate         322 non-null    object  \n",
      " 2   job_description         511 non-null    object  \n",
      " 3   rating                  399 non-null    float64 \n",
      " 4   company_name            511 non-null    object  \n",
      " 5   location                511 non-null    object  \n",
      " 6   size                    415 non-null    category\n",
      " 7   founded                 348 non-null    Int64   \n",
      " 8   type_of_ownership       428 non-null    category\n",
      " 9   industry                381 non-null    category\n",
      " 10  sector                  383 non-null    category\n",
      " 11  revenue                 271 non-null    category\n",
      " 12  rating_culturevalues    389 non-null    float64 \n",
      " 13  rating_worklifebalance  394 non-null    float64 \n",
      " 14  rating_diversity        296 non-null    float64 \n",
      " 15  rating_seniormgmt       394 non-null    float64 \n",
      " 16  rating_compbenefits     394 non-null    float64 \n",
      " 17  rating_careerops        394 non-null    float64 \n",
      " 18  api_citytownvilham      488 non-null    object  \n",
      " 19  api_region              488 non-null    category\n",
      " 20  api_country             491 non-null    category\n",
      " 21  uk                      511 non-null    bool    \n",
      " 22  remote                  511 non-null    bool    \n",
      " 23  salary_min              322 non-null    object  \n",
      " 24  salary_max              322 non-null    object  \n",
      " 25  salary_mid              322 non-null    float64 \n",
      " 26  title_datascientist     511 non-null    bool    \n",
      " 27  title_dataanalyst       511 non-null    bool    \n",
      " 28  title_dataengineer      511 non-null    bool    \n",
      " 29  title_mlai              511 non-null    bool    \n",
      " 30  title_research          511 non-null    bool    \n",
      " 31  title_internapprentice  511 non-null    bool    \n",
      " 32  datascience_role        511 non-null    bool    \n",
      "dtypes: Int64(1), bool(9), category(7), float64(8), object(8)\n",
      "memory usage: 77.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# provide the path to the location of the cleaned scraped glassdoor job data\n",
    "path = './data/'\n",
    "\n",
    "# provide glassdoor scrape date\n",
    "scrapedate = '14Dec2020'  # e.g. '14Dec2020', '16Feb2021'\n",
    "\n",
    "# create the absolute path to the cleaned glassdoor job data\n",
    "filename = os.path.join(path, f\"dsjobs_df_{scrapedate}_postclean.pkl\")\n",
    "\n",
    "# read the cleaned data scientist jobs data (.pkl file) into a dataframe\n",
    "dsjobs = pd.read_pickle(filename)\n",
    "\n",
    "# display dataframe info to check that it's what you expected\n",
    "dsjobs.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seniority of position: Identify seniority from the job title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am interested in being able to differentiate between junior and senior positions, so I'll now use the job titles to mark - using Boolean masks - those that mention seniority for the purpose of splitting and comparing these jobs later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True      11\n",
       "False    500\n",
       "Name: seniority_junior, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a regular expression to identify junior positions from the job titles\n",
    "dsjobs[\"seniority_junior\"] = dsjobs[\"job_title\"].str.contains(\n",
    "    r\"\\bjunior\\b|\\bjr.?\\b|\\bentry level\\b|\\bgraduate\\b\", flags=re.IGNORECASE, regex=True)\n",
    "dsjobs[\"seniority_junior\"].value_counts().sort_index(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few job titles indicating a \"junior role\", so I will not analyse this group of jobs separately. I will remove the \"seniority_junior\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the \"seniority_junior\" column\n",
    "dsjobs.drop(columns=\"seniority_junior\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     140\n",
       "False    371\n",
       "Name: seniority_senior, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a regular expression to identify senior positions from the job titles\n",
    "dsjobs[\"seniority_senior\"] = dsjobs[\"job_title\"].str.contains(\n",
    "    r\"\\bsenior\\b|\\bsr.?\\b|\\bexperienced\\b|\\blead\\b|\\bprinciple\\b|\\bchief\\b|\\bmanager\\b|\\bhead\\b\", flags=re.IGNORECASE, regex=True)\n",
    "dsjobs[\"seniority_senior\"].value_counts().sort_index(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large proportion of the job titles in the dataset indicate being of a \"senior\" position, so this Boolean mask (or, new \"feature\") will be useful for analysing these roles separately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skills, experience & education: Job description text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know which skills, experience/knowledge, and education employers are most often looking for in data scientist candidates, but you cannot look through hundreds or thousands of jobs to figure this out, and looking through a small sample might give you the impression that a certain skill/tool/degree is more desireable than it really is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, I'll check the job descriptions in my data set for mentions of various data science skills, tools, and degrees, and record the results for each one within the data science jobs DataFrame (`dsjobs`). This feature engineering and analysis of the results will allow me to identify the most desireable traits employers are looking for in candidates, and which skills/experiences tend to be mentioned together (possibly indicating a relationship). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills: search for mentions of data science skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the role of a data scientist is, and which skills they should have, will vary depending on who you ask, because:\n",
    "- data scientists working in different sectors and industries will have different roles\n",
    "- the label \"data scientist\" has now also been applied to jobs that were previously called something else, e.g. statisticians, data analysts, computer scientists, and \n",
    "- there is a growing demand for specialists with certain combinations of data science skills\n",
    "\n",
    " To learn which skills are most commonly mentioned (and found together) in data science job advertisements, I will create and use a dictionary of regular expressions to search for a wide range of skills within the job description text, and add the results to `dsjobs`. \n",
    " \n",
    " The data science skills I have decided to look for are based on my own knowledge of the data scientist role, scanning many of the job descriptions in the data set, and additional web searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below will be used to develop and optimise the regular expressions \n",
    "# for searching the the job descriptions text for mentions of skills, tools, etc\n",
    "\n",
    "def check_re(jobsdf, regex):\n",
    "    \"\"\" Scans through a random sample of 100 job descriptions from the jobs DataFrame, /\n",
    "    looking for a match to the regular expression(s), and prints up to 20 match objects /\n",
    "    plus the surrounding text (for context)\n",
    "\n",
    "    :param jobsdf: jobs data with job descriptions\n",
    "    :type jobsdf: pandas.core.frame.DataFrame\n",
    "    :param regex: regular expression(s)\n",
    "    :type regex: str | dict\n",
    "    \n",
    "    \"\"\"    \n",
    "    print(f\"*** Pattern = '{regex}' ***\\n\")\n",
    "\n",
    "    # produce a random integer for the sample function\n",
    "    seed = random.randint(0, 100)\n",
    "\n",
    "    if (type(regex) is str):\n",
    "        sample_counter = 1\n",
    "        print_counter = 0\n",
    "        for i in (jobsdf.job_description.sample(n=100, random_state=seed)):\n",
    "            if print_counter >= 20:\n",
    "                break\n",
    "            result = re.search(regex, i, re.IGNORECASE)  # returns 1st occurrence only\n",
    "            if result:\n",
    "                start = result.span()[0]\n",
    "                stop = result.span()[1]\n",
    "                string = i[start-50:stop+50]\n",
    "                print(f\"[{sample_counter}] {string}\\n\")\n",
    "                print_counter += 1\n",
    "            sample_counter += 1\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"regex must be a string\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expression that will be used to search for \n",
    "# data science skills in each job description; the labels will later be used for plots\n",
    "dict_skills = {\n",
    "    \"shell_or_bash\": {\n",
    "        # placing a 'r' before a string literal creates a raw-string literal\n",
    "        # raw strings do not process escape sequences (\\n, \\b, etc.) \n",
    "        're': r\"\\bshell\\b|\\bbash\\b\",  \n",
    "        'label': \"Shell/Bash\"\n",
    "    },\n",
    "    \"version_control\": {\n",
    "        're': \"version control\",\n",
    "        'label': \"Version Control\"\n",
    "    },\n",
    "    \"distributed_data\": {\n",
    "        're': \"distributed data\",\n",
    "        'label': \"Distributed Data\"\n",
    "    },\n",
    "    \"big_unstructured_data\": {\n",
    "        're': \"big data|NoSQL|data lake|unstructured data\",\n",
    "        'label': \"Big Data/Unstructured Data/NoSQL\"\n",
    "    },\n",
    "    \"data_management\": {\n",
    "        're': r\"data\\w* management\",\n",
    "        'label': \"Data Management\"\n",
    "    },\n",
    "    \"data_transformation\": {\n",
    "        're': r\"data transform\\w*|\\betl\\b\",\n",
    "        'label': \"Data Transformation\"\n",
    "    },\n",
    "    \"data_mining\": {\n",
    "        're': r\"\\bmine\\b|\\bmining\\b\",\n",
    "        'label': \"Data Mining\"\n",
    "    },\n",
    "    \"data_streaming\": {\n",
    "        're': r\"\\bdata stream\\w*\",\n",
    "        'label': \"Data Streaming\"\n",
    "    },\n",
    "    \"data_analytics\": {\n",
    "        're': r\"data analy|analy[sz]e data\\w*\",\n",
    "        'label': \"Data Analytics\"\n",
    "    },\n",
    "    \"querying\": {\n",
    "        're': r\"\\bquer\\w*\",\n",
    "        'label': \"Querying\"\n",
    "    },\n",
    "    \"data_cleaning\": {\n",
    "        're': r\"\\bcleaning\\w*|\\bwrangl\\w*|\\bmung\\w*\",\n",
    "        'label': \"Data Cleaning\"\n",
    "    },\n",
    "    \"geospatial\": {\n",
    "        're': \"geospatial\",\n",
    "        'label': \"Geospatial Data\"\n",
    "    },\n",
    "    \"time_series\": {\n",
    "        're': \"time series|time-series\",\n",
    "        'label': \"Time Series Data\"\n",
    "    },\n",
    "    \"web_scraping\": {\n",
    "        're': \"web scraping|scrape\",\n",
    "        'label': \"Web Scraping\"\n",
    "    },\n",
    "    \"data_visualisation\": {\n",
    "        're': r\"data visuali\\w*\",\n",
    "        'label': \"Data Visualisation\"\n",
    "    },\n",
    "    \"dashboard\": {\n",
    "        're': \"dashboard\",\n",
    "        'label': \"Building Dashboards\"\n",
    "    },\n",
    "    \"statistical_modelling\": {\n",
    "        're': r\"predictive analy\\w*|predictive model\\w*|statistical model\\w*\",\n",
    "        'label': \"Statistical Modelling\"\n",
    "    },\n",
    "    \"regression\": {\n",
    "        're': \"regression\",\n",
    "        'label': \"Regression\"\n",
    "    },\n",
    "    \"clustering\": {\n",
    "        're': \"cluster|clustering\",\n",
    "        'label': \"Clustering\"\n",
    "    },\n",
    "    \"classification\": {\n",
    "        're': r\"classif\\w*|decision tree|random forest|svm|support vector machine\",\n",
    "        'label': \"Classification\"\n",
    "    },\n",
    "    \"supervised_learning\": {\n",
    "        're': r\"\\bsupervised\",\n",
    "        'label': \"Supervised Learning\"\n",
    "    },\n",
    "    \"unsupervised_learning\": {\n",
    "        're': \"unsupervised\",\n",
    "        'label': \"Unsupervised Learning\"\n",
    "    },\n",
    "    \"machine_learning\": {\n",
    "        're': r\"machine learning|\\bml\\b\",\n",
    "        'label': \"Machine Learning\"\n",
    "    },\n",
    "    \"deep_learning\": {\n",
    "        're': \"deep learning|neural network\",\n",
    "        'label': \"Deep Learning\"\n",
    "    },\n",
    "    \"dimensionality_reduction\": {\n",
    "        're': r\"dimensionality reduction|principle component analysis|PCA|t-SNE\",\n",
    "        'label': \"Dimensionality Reduction\"\n",
    "    },\n",
    "    \"sequence_modelling\": {\n",
    "        're': r\"sequence model\\w*|rnn\",\n",
    "        'label': \"Sequence Modelling\"\n",
    "    },\n",
    "    \"computer_vision\": {\n",
    "        're': r\"computer vision|machine vision|image classif\\w*\",\n",
    "        'label': \"Computer Vision\"\n",
    "    },\n",
    "    \"NLP\": {\n",
    "        're': \"natural language processing|NLP\",\n",
    "        'label': \"Natural Language Processing\"\n",
    "    },\n",
    "    \"ai\": {\n",
    "        're': r\"artificial intelligence|\\bai\\b\",\n",
    "        'label': \"Artifical Intelligence\"\n",
    "    },\n",
    "    \"hypothesis_testing\": {\n",
    "        're': r\"\\ba\\/b\\b|hypothesis testing\",\n",
    "        'label': \"Hypothesis Testing\"\n",
    "    },\n",
    "    \"cloud_computing\": {\n",
    "        're': \"cloud|cloud computing\",\n",
    "        'label': \"Cloud Computing\"\n",
    "    },\n",
    "    \"software_development\": {\n",
    "        're': \"software development|software engineering\",\n",
    "        'label': \"Software Development/Engineering\"\n",
    "    },\n",
    "    \"agile_working\": {\n",
    "        're': \"agile working|agile develop|agile method|scrum\",\n",
    "        'label': \"Agile Working\"\n",
    "    },\n",
    "    \"pipelines\": {\n",
    "        're': \"pipeline\",\n",
    "        'label': \"Working with/Developing Pipelines\"\n",
    "    },\n",
    "    \"devops\": {\n",
    "        're': r\"\\bci\\b|\\bcd\\b|devops\",\n",
    "        'label': \"DevOps\"\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        're': r\"deploy\\w*\",\n",
    "        'label': \"Deploying Models/Products\"\n",
    "    },\n",
    "    \"containerization\": {\n",
    "        're': r\"container\\w*\",\n",
    "        'label': \"Containerisation\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use check_re to test the regex dictionary that will be used to search for skills\n",
    "for key, val in dict_skills.items():\n",
    "    print(f\"{key.upper()}\\n\")\n",
    "    check_re(jobsdf=dsjobs, regex=val[\"re\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda function below throws a SettingWithCopyWarning but I have checked that\n",
    "# I am not making a change to a copy so this warning will be suppressed\n",
    "from warnings import simplefilter\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each skill in the dict_skills, create a column in the dataframe with the 'label',\n",
    "# with a lambda function, search for the skill in each job's description text using \n",
    "# the regular expression ('re'), entering the boolean result in the column, 'label'\n",
    "for key, val in dict_skills.items():\n",
    "    dsjobs[key] = dsjobs[\"job_description\"].apply(\n",
    "        lambda x: bool(re.search(val['re'], x, re.IGNORECASE)))\n",
    "    # # if you want to see the results for debugging, uncomment below\n",
    "    # print(f\"{val['label']} : {round(np.mean(dsjobs[key])*100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools: search for mentions of data science tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job descriptions will almost always name programming languages and other data science tools that the company uses or the employer expects candidates to know/have experience with. I want to know which tools are most popular among employers/companies, so I will create and test a dictionary of regular expressions to search for a wide range of tools within the description text of each job, and add the results to `dsjobs`. The data science tools I have decided to look for are based on my own knowledge of the data scientist role, scanning many of the job descriptions in the data set, and additional web searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expression that will be used to search for \n",
    "# data science tools in each job description; the labels will later be used for plots\n",
    "dict_tools = {\n",
    "    \"python\": {\n",
    "        # programming language\n",
    "        're': r\"\\bpython\\b\",\n",
    "        'label': \"Python\"\n",
    "    },\n",
    "    \"r\": {\n",
    "        # programming language\n",
    "        're': r\"\\br(?!&)\\b|\\brstudio\\b\",\n",
    "        'label': \"R\"\n",
    "    },\n",
    "    \"scala\": {\n",
    "        # programming language\n",
    "        're': r\"\\bscala\\b\",\n",
    "        'label': \"Scala\"\n",
    "    },\n",
    "    \"matlab\": {\n",
    "        # desktop environment tuned for iterative analysis and design processes with a \n",
    "        # programming language that expresses matrix and array mathematics directly\n",
    "        're': r\"\\bmatlab\\b\",\n",
    "        'label': \"MATLAB\"\n",
    "    },\n",
    "    \"sas\": {\n",
    "        # statistical software suite\n",
    "        're': r\"\\bsas\\b\",\n",
    "        'label': \"SAS\"\n",
    "    },\n",
    "    \"spss\": {\n",
    "        # software package used for interactive, or batched, statistical analysis\n",
    "        're': r\"\\bspss\\b\",\n",
    "        'label': \"SPSS\"\n",
    "    },\n",
    "    \"stata\": {\n",
    "        # statistical software package\n",
    "        're': r\"\\bstata\\b\",\n",
    "        'label': \"Stata\"\n",
    "    },\n",
    "    \"perl\": {\n",
    "        # programming language\n",
    "        're': r\"\\bperl\\b\",\n",
    "        'label': \"Perl\"\n",
    "    },\n",
    "    \"unix\": {\n",
    "        # Operating system\n",
    "        're': r\"\\bunix\\b\",\n",
    "        'label': \"Unix\"\n",
    "    },\n",
    "    \"linux\": {\n",
    "        # Unix-like operating system\n",
    "        're': r\"\\blinux\\b\",\n",
    "        'label': \"Linux\"\n",
    "    },\n",
    "    \"git_github\": {\n",
    "        # Git is a version control system that lets you manage and keep track of your source code history;\n",
    "        # GitHub is a cloud-based hosting service that lets you manage Git repositories.\n",
    "        're': r\"\\bgit|github\\b\",\n",
    "        'label': \"Git/GitHub\"\n",
    "    },\n",
    "    \"anaconda\": {\n",
    "        # Anaconda is a distribution of the Python and R programming languages for scientific computing\n",
    "        # (data science, machine learning applications, large-scale data processing, predictive analytics, etc.),\n",
    "        # that aims to simplify package management and deployment.\n",
    "        're': r\"\\banaconda\\b\",\n",
    "        'label': \"Anaconda\"\n",
    "    },\n",
    "    \"d3js\": {\n",
    "        # a JavaScript library for visualizing data with HTML, SVG, and CSS\n",
    "        're': r\"\\bd3\\.?js\\b\",\n",
    "        'label': \"D3.js\"\n",
    "    },\n",
    "    \"jira\": {\n",
    "        # software used for bug tracking, issue tracking, and project management\n",
    "        're': r\"\\bjira\\b\",\n",
    "        'label': \"Jira\"\n",
    "    },\n",
    "    \"java\": {\n",
    "        # programming language\n",
    "        're': r\"\\bjava\\b\",\n",
    "        'label': \"Java\"\n",
    "    },\n",
    "    \"javascript\": {\n",
    "        # programming language\n",
    "        're': r\"\\bjavascript\\b\",\n",
    "        'label': \"JavaScript\"\n",
    "    },\n",
    "    \"nodejs\": {\n",
    "        # cross-platform, back-end JavaScript runtime environment that executes JavaScript code outside a web browser.\n",
    "        're': r\"\\bnode\\.js\\b\",\n",
    "        'label': \"Node.js\"\n",
    "    },\n",
    "    \"c++_c#\": {\n",
    "        # programming languages\n",
    "        're': r\"\\bc\\b|\\bc\\+{2}\\b|\\bc\\#\\b\",\n",
    "        'label': \"C++/C#\"\n",
    "    },\n",
    "    \"docker\": {\n",
    "        # Docker is a set of products that use OS-level virtualization to deliver software in packages called containers,\n",
    "        # removing the issue of dependencies\n",
    "        're': r\"\\bdocker\\w*?\\b\",\n",
    "        'label': \"Docker\"\n",
    "    },\n",
    "    \"kubernetes\": {\n",
    "        # Container-orchestration system for automating computer application deployment, scaling, and management\n",
    "        're': r\"\\bkubernetes\\b\",\n",
    "        'label': \"Kubernetes\"\n",
    "    },\n",
    "    \"google_cloud\": {\n",
    "        # a suite of cloud computing services\n",
    "        're': r\"\\bgoogle cloud\\b|\\bgcp\\b\",\n",
    "        'label': \"Google Cloud Platform (GCP)\"\n",
    "    },\n",
    "    \"aws\": {\n",
    "        # a suite of cloud computing services\n",
    "        're': r\"\\baws\\b\",\n",
    "        'label': \"Amazon Web Services (AWS)\"\n",
    "    },\n",
    "    \"azure\": {\n",
    "        # a suite of cloud computing services\n",
    "        're': r\"\\bazure\\b\",\n",
    "        'label': \"Microsoft Azure\"\n",
    "    },\n",
    "    \"kafka\": {\n",
    "        # a stream-processing software platform for handling real-time data feeds, which can connect to external systems (for data import/export)\n",
    "        're': r\"\\bkafka\\b\",\n",
    "        'label': \"Kafka\"\n",
    "    },\n",
    "    \"kinesis\": {\n",
    "        # a cloud-based service that allows real-time processing of data streaming large amount of data\n",
    "        're': r\"\\bkinesis\\b\",\n",
    "        'label': \"Kinesis\"\n",
    "    },\n",
    "    \"spark\": {\n",
    "        # general-purpose cluster-computing framework\n",
    "        're': r\"\\bspark\\b\",\n",
    "        'label': \"Spark\"\n",
    "    },\n",
    "    \"elasticsearch\": {\n",
    "        # Elasticsearch takes unstructured data from different locations, stores and indexes it according to user-specified mapping\n",
    "        # (or automatically from data) and makes it searchable.\n",
    "        're': r\"\\belasticsearch\\b\",\n",
    "        'label': \"Elasticsearch\"\n",
    "    },\n",
    "    \"sql\": {\n",
    "        # a domain-specific language used in programming and designed for managing data held in a relational database management system\n",
    "        're': r\"\\bsql\\b\",\n",
    "        'label': \"Structured Query Language (SQL)\"\n",
    "    },\n",
    "    \"redshift\": {\n",
    "        #  a cloud-based, big data warehouse product; can be used for real-time analytics\n",
    "        're': r\"\\bredshift\\b\",\n",
    "        'label': \"Redshift\"\n",
    "    },\n",
    "    \"looker\": {\n",
    "        # a browser-based data analytics platform for collection, visualization and analysis\n",
    "        're': r\"\\blooker\\b\",\n",
    "        'label': \"Looker\"\n",
    "    },\n",
    "    \"bigquery\": {\n",
    "        # A serverless cloud storage platform for large data sets,\n",
    "        # which allows you to run complex analytical SQL-based queries under large sets of data\n",
    "        're': r\"\\bbigquery\\b\",\n",
    "        'label': \"BigQuery\"\n",
    "    },\n",
    "    \"hive\": {\n",
    "        # A data warehouse software that allows users to read, write, and manage petabytes of data using SQL.\n",
    "        # Hive is built on top of Hadoop\n",
    "        're': r\"\\bhive\\b\",\n",
    "        'label': \"Apache Hive\"\n",
    "    },\n",
    "    \"excel\": {\n",
    "        # A program that allows users to organize, format and calculate data with formulas using a spreadsheet system\n",
    "        're': r\"\\bexcel\\b\",\n",
    "        'label': \"Excel\"\n",
    "    },\n",
    "    \"power_bi\": {\n",
    "        # Power BI is a business analytics service by Microsoft for interactive visualizations and business intelligence\n",
    "        # capabilities with an interface simple enough for end users to create their own reports and dashboards.\n",
    "        're': r\"\\bpower bi\\b\",\n",
    "        'label': \"Power BI\"\n",
    "    },\n",
    "    \"snowflake\": {\n",
    "        # Snowflake is a full SQL data warehouse built for the cloud (on top of the AWS or Azure)\n",
    "        're': r\"\\bsnowflake\\b\",\n",
    "        'label': \"Snowflake\"\n",
    "    },\n",
    "    \"tableau\": {\n",
    "        # an interactive data visualization software\n",
    "        're': r\"\\btableau\\b\",\n",
    "        'label': \"Tableau\"\n",
    "    },\n",
    "    \"vertica\": {\n",
    "        # a data analytics platform\n",
    "        're': r\"\\bvertica\\b\",\n",
    "        'label': \"Vertica\"\n",
    "    },\n",
    "    \"grafana\": {\n",
    "        # a multi-platform open source analytics and interactive visualization web application.\n",
    "        're': r\"\\bgrafana\\b\",\n",
    "        'label': \"Grafana\"\n",
    "    },\n",
    "    \"lubridate\": {\n",
    "        # R library used for data wrangling, good for date-time data\n",
    "        're': r\"\\blubridate\\b\",\n",
    "        'label': \"Lubridate\"\n",
    "    },\n",
    "    \"tidyverse\": {\n",
    "        # R data science packages\n",
    "        're': r\"\\btidyverse\\b\",\n",
    "        'label': \"Tidyverse\"\n",
    "    },\n",
    "    \"dplyr\": {\n",
    "        # R package to manipulate, clean and summarize unstructured data\n",
    "        're': r\"\\bdplyr\\b\",\n",
    "        'label': \"dplyr\"\n",
    "    },\n",
    "    \"ggplot2\": {\n",
    "        # library for data visualization in R\n",
    "        're': r\"\\bggplot2\\b\",\n",
    "        'label': \"ggplot2\"\n",
    "    },\n",
    "    \"esquisse\": {\n",
    "        # R ggplot2 addin that allows you to interactively explore your data by visualizing it with the ggplot2 package,\n",
    "        # then export the graph or retrieve the code generating the graph\n",
    "        're': r\"\\besquisse\\b\",\n",
    "        'label': \"esquisse\"\n",
    "    },\n",
    "    \"shiny\": {\n",
    "        # R package  to build interactive web apps\n",
    "        're': r\"\\bshiny\\b\",\n",
    "        'label': \"Shiny\"\n",
    "    },\n",
    "    \"bioconductor\": {\n",
    "        # software for bioinformatics\n",
    "        're': r\"\\bbioconductor\\b\",\n",
    "        'label': \"Bioconductor\"\n",
    "    },\n",
    "    \"knitr\": {\n",
    "        # R package for dynamic report generation\n",
    "        're': r\"\\bknitr\\b\",\n",
    "        'label': \"knitr\"\n",
    "    },\n",
    "    \"rmarkdown\": {\n",
    "        # R package for dynamic report generation\n",
    "        're': r\"\\brmarkdown\\b\",\n",
    "        'label': \"RMarkdown\"\n",
    "    },\n",
    "    \"quanteda\": {\n",
    "        # R package for managing and analyzing text\n",
    "        're': r\"\\bquanteda\\b\",\n",
    "        'label': \"quanteda\"\n",
    "    },\n",
    "    \"rcrawler\": {\n",
    "        # R package for domain-based web crawling and content scraping\n",
    "        're': r\"\\brcrawler\\b\",\n",
    "        'label': \"RCrawler\"\n",
    "    },\n",
    "    \"caret\": {\n",
    "        # R package for model building and evaluation, e.g. data splitting, pre-processing, feature selection, variable importance estimation etc.\n",
    "        're': r\"\\bcaret\\b\",\n",
    "        'label': \"Caret\"\n",
    "    },\n",
    "    \"mlr\": {\n",
    "        # R package and framework for ML\n",
    "        're': r\"\\bmlr\\b\",\n",
    "        'label': \"mlr\"\n",
    "    },\n",
    "    \"oracle\": {\n",
    "        # cloud computing infrastructure\n",
    "        're': r\"\\boracle\\b\",\n",
    "        'label': \"Oracle\"\n",
    "    },\n",
    "    \"numpy\": {\n",
    "        # python library adding support for large, multi-dimensional arrays and matrices,\n",
    "        # along with a large collection of high-level mathematical functions to operate on them\n",
    "        're': r\"\\bnumpy\\b\",\n",
    "        'label': \"NumPy\"\n",
    "    },\n",
    "    \"scipy\": {\n",
    "        # python library used for scientific computing and technical computing, with modules for optimization,\n",
    "        # linear algebra, integration, interpolation, special functions, FFT, signal and image processing,\n",
    "        # ODE solvers and other tasks common in science and engineering.\n",
    "        're': r\"\\bscipy\\b\",\n",
    "        'label': \"SciPy\"\n",
    "    },\n",
    "    \"pandas\": {\n",
    "        # python library for data manipulation and analysis in python, offering data structures and operations\n",
    "        # for manipulating numerical tables and time series.\n",
    "        're': r\"\\bpandas\\b\",\n",
    "        'label': \"pandas\"\n",
    "    },\n",
    "    \"matplotlib\": {\n",
    "        # python ibrary for creating static, animated, and interactive visualizations in Python, based on NumPy\n",
    "        're': r\"\\bmatplotlib\\b\",\n",
    "        'label': \"matplotlib\"\n",
    "    },\n",
    "    \"bokeh\": {\n",
    "        # python library used to make interactive plots, dashboards, and data applications for modern web browsers/notebooks\n",
    "        're': r\"\\bbokeh\\b\",\n",
    "        'label': \"Bokeh\"\n",
    "    },\n",
    "    \"sklearn\": {\n",
    "        # python ML library, used for classification, regression clustering, SVM, random forests,\n",
    "        # gradient boosting, k-means and DBSCAN; designed to work with NumPy and SciPy.\n",
    "        're': r\"\\bscikit\\-learn\\b|\\bsklearn\\b\",\n",
    "        'label': \"scikit-learn\"\n",
    "    },\n",
    "    \"pytorch\": {\n",
    "        # python ML library based on the Torch library, uses include computer vision and NLP\n",
    "        're': r\"\\bpytorch\\b\",\n",
    "        'label': \"PyTorch\"\n",
    "    },\n",
    "    \"pyspark\": {\n",
    "        # python API written to support Apache Spark\n",
    "        're': r\"\\bpyspark\\b\",\n",
    "        'label': \"PySpark\"\n",
    "    },\n",
    "    \"sparkml\": {\n",
    "        # Spark MLlib is a distributed ML framework on top of Spark Core\n",
    "        're': r\"\\bspark[\\.\\s]?ml\",\n",
    "        'label': \"Spark ML\"\n",
    "    },\n",
    "    \"tensorflow\": {\n",
    "        # library for ML with a particular focus on training and interference of deep neural networks\n",
    "        're': r\"\\btensorflow\\b\",\n",
    "        'label': \"TensorFlow\"\n",
    "    },\n",
    "    \"spacy\": {\n",
    "        # Library for advanced NLP\n",
    "        're': r\"\\bspacy\\b\",\n",
    "        'label': \"spaCy\"\n",
    "    },\n",
    "    \"keras\": {\n",
    "        # Library providing Python interface for artificial neural networks.\n",
    "        're': r\"\\bkeras\\b\",\n",
    "        'label': \"Keras\"\n",
    "    },\n",
    "    \"databricks\": {\n",
    "        # Data analytics/ data lake platform optimized for Azure\n",
    "        're': r\"\\bdatabricks\\b\",\n",
    "        'label': \"Databricks\"\n",
    "    },\n",
    "    \"mongodb\": {\n",
    "        # Cross-platform document-oriented NoSQL database program.\n",
    "        're': r\"\\bmongodb\\b\",\n",
    "        'label': \"MongoDB\"\n",
    "    },\n",
    "    \"hadoop\": {\n",
    "        # A software framework for distributed storage and processing of big data\n",
    "        're': r\"\\bhadoop\\b\",\n",
    "        'label': \"Hadoop\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use check_re to test the regular expressions that will be used to search for tools\n",
    "for key, val in dict_tools.items():\n",
    "    print(f\"{key.upper()}\\n\")\n",
    "    check_re(jobsdf=dsjobs, regex=val[\"re\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression looking for mentions of the C, C++ or C# programming languages matches mentions of \"C\" with respect to grades, e.g. GCSE grades or NHS/other salary bands, so I will check for this and correct the results where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (and correct, if needed) the results of the regex used to identify mentions of \n",
    "# C, C++ or C# programming languages\n",
    "for index, row in dsjobs.iterrows():\n",
    "    # return an iterator over all matches with the regular expression\n",
    "    result = re.finditer(\n",
    "        dict_tools[\"c++_c#\"]['re'], row[\"job_description\"], re.IGNORECASE)\n",
    "    if result:  # if there are any matches:\n",
    "        for v in result:\n",
    "            start = v.span()[0]\n",
    "            stop = v.span()[1]\n",
    "            # isolate the text surrounding the match result (string)\n",
    "            string = row['job_description'][start-50:stop+50]\n",
    "            counter = 0\n",
    "            # search this string for reference to grades, GCSEs and Bands (e.g. NHS salary bands)\n",
    "            if re.search(r\"\\bgcse\\b|\\bband\\b|\\bgrade\\b\", string, re.IGNORECASE):\n",
    "                # correct these \"false positives\"\n",
    "                print(string+\"\\n\")\n",
    "                dsjobs.loc[index, \"c++_c#\"] = False\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search each job description for each skill using the regular expressions in dict_tools,\n",
    "# entering the boolean result in a new column for each tool\n",
    "for key, val in dict_tools.items():\n",
    "    dsjobs[key] = dsjobs[\"job_description\"].apply(\n",
    "        lambda x: bool(re.search(val['re'], x, re.IGNORECASE)))\n",
    "    # print(f\"{val['label']}: {(np.mean(dsjobs[key])*100).round(2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education: search for mentions of academic qualifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A quick scan of a few data science roles will tell you that employers believe a very strong educational background is required to develop the depth of knowledge necessary to be a data scientist.\n",
    " \n",
    " To find out what proportion of data science jobs require a degree, and which qualifications and subjects are most often mentioned by employers in job descriptions, I will create dictionaries of regular expressions to search for these within the job descriptions, and add the results (boolean masks) to `dsjobs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expressions and labels for degree qualifications,\n",
    "# which will be used to search for these in the job descriptions\n",
    "# the labels will later be used for plots\n",
    "dict_qualifications = {\n",
    "    \"bachelors\": {\n",
    "        're': r\"\\bbachelor\\'?|\\bhonours\\b|\\bbsc\\b|\\bbs\\b|\\bba\\b\",\n",
    "        'label': \"Bachelor's\"\n",
    "    },\n",
    "    \"masters\": {\n",
    "        're': r\"\\bmaster\\'?s\\b|\\bmsc\\b|\\bma\\b\",\n",
    "        'label': \"Master's\"\n",
    "    },\n",
    "    \"phd\": {\n",
    "        're': r\"\\bphd\\b|\\bdphil\\b|\\bdoctorate\\b\",\n",
    "        'label': \"PhD\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use check_re to test the regular expressions that will be used for searching qualifications\n",
    "for key, val in dict_qualifications.items():\n",
    "    print(f\"{key.upper()}\\n\")\n",
    "    check_re(jobsdf=dsjobs, regex=val[\"re\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bachelor's: 0.19\n",
      "Master's: 0.24\n",
      "PhD: 0.28\n"
     ]
    }
   ],
   "source": [
    "# search each job description for each qualification using the regular expressions in \n",
    "# dict_qualifications, entering the boolean result in a new column for each one\n",
    "for key, val in dict_qualifications.items():\n",
    "    dsjobs[key] = dsjobs[\"job_description\"].apply(\n",
    "        lambda x: bool(re.search(val['re'], x, re.IGNORECASE)))\n",
    "    # for debugging: if any job mentions a qualification, column mean should be non-zero\n",
    "    print(f\"{val['label']}: {(np.mean(dsjobs[key])).round(2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find mentions of degree subjects in the job descriptions, searching for just the name of the subject in the job description will not do, since words like \"statistics\" and \"engineering\" are also mentioned in other contexts, e.g. in the company overview, or in the description of responsibilities, so I'll look for instances where the subject name and reference to a degree are in the same sentence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the job description text into sentences using new lines\n",
    "dsjobs['job_description_sent'] = dsjobs[\"job_description\"].apply(\n",
    "    lambda x: x.split(\"\\n\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expressions for degree subjects, which will\n",
    "# be used to search for the subjects in the text surrounding the mention of \n",
    "# a qualification; the labels will be used for analysis plots later\n",
    "dict_degsubjects = {\n",
    "    \"degree_statistics\": {\n",
    "        're': r\"\\bstatistics\\b\",\n",
    "        'label': \"Statistics\"\n",
    "    },\n",
    "    \"degree_compsci\": {\n",
    "        're': r\"\\bcomputer science\\b\",\n",
    "        'label': \"Computer Science\"\n",
    "    },\n",
    "    \"degree_software_engineering\": {\n",
    "        're': r\"\\bsoftware engineering\\b\",\n",
    "        'label': \"Software Engineering\"\n",
    "    },\n",
    "    \"degree_economics\": {\n",
    "        're': r\"\\beconomics\\b\",\n",
    "        'label': \"Economics\"\n",
    "    },\n",
    "    \"degree_maths\": {\n",
    "        're': r\"\\bmaths\\b|\\bmathematics\\b\",\n",
    "        'label': \"Maths\"\n",
    "    },\n",
    "    \"degree_physics\": {\n",
    "        're': r\"\\bphysics\\b\",\n",
    "        'label': \"Physics\"\n",
    "    },\n",
    "    \"degree_engineering\": {\n",
    "        're': r\"\\bengineering\\b\",\n",
    "        'label': \"Engineering\"\n",
    "    },\n",
    "    \"degree_biology\": {\n",
    "        're': r\"\\bbiolog\\b|\\bbioinformatics\\b\",\n",
    "        'label': \"Biology\"\n",
    "    },\n",
    "    \"degree_chemistry\": {\n",
    "        're': r\"\\bchemistry\\b\",\n",
    "        'label': \"Chemistry\"\n",
    "    },\n",
    "    \"degree_datasci\": {\n",
    "        're': r\"\\bdata science\\b\",\n",
    "        'label': \"Data Science\"\n",
    "    },\n",
    "    \"degree_ml_ai\": {\n",
    "        're': r\"machine learning|\\bml\\b|artificial intelligence|\\bai\\b\",\n",
    "        'label': \"ML or AI\"\n",
    "    },\n",
    "    \"degree_stem_quantfield\": {\n",
    "        're': r\"\\bstem\\b|\\bquantitative field\\b\",\n",
    "        'label': \"'STEM' or 'Quantitative Field'\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics: 0.26\n",
      "Computer Science: 0.29\n",
      "Software Engineering: 0.01\n",
      "Economics: 0.06\n",
      "Maths: 0.29\n",
      "Physics: 0.12\n",
      "Engineering: 0.17\n",
      "Biology: 0.02\n",
      "Chemistry: 0.02\n",
      "Data Science: 0.13\n",
      "ML or AI: 0.1\n",
      "'STEM' or 'Quantitative Field': 0.11\n"
     ]
    }
   ],
   "source": [
    "# line by line, check each job description for the subject + mention of a 'degree'/qualification\n",
    "for key, val in dict_degsubjects.items():\n",
    "    # create a column for the degree subject in ds with default values set to False\n",
    "    dsjobs[key] = False\n",
    "    for index, row in dsjobs.iterrows():\n",
    "        for sentence in row['job_description_sent']:\n",
    "            # if the subject is in the sentence\n",
    "            if (re.search(val['re'], sentence, re.IGNORECASE)):\n",
    "                # if \"degree\" is in the same sentence, positive result\n",
    "                if (re.search(r\"degree\", sentence, re.IGNORECASE)):\n",
    "                    dsjobs.loc[index, key] = True\n",
    "                    break   # no need to look for a specific degree type\n",
    "                # else look for a specific qualification, e.g. \"PhD\"\n",
    "                else:\n",
    "                    for k, v in dict_qualifications.items():\n",
    "                        # if the qualification is in the same sentence\n",
    "                        if (re.search(v['re'], sentence, re.IGNORECASE)):  \n",
    "                            dsjobs.loc[index, key] = True\n",
    "                            break   # no need to keep looking for a qualification\n",
    "    # for debugging: if any mentions of a degree in the subject, column mean should be non-zero\n",
    "    print(f\"{val['label']}: {round((dsjobs[key].mean()),2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boolean mask to mark jobs that mention any type of degree\n",
    "degree_any = dsjobs.loc[:,\"degree_statistics\":\"degree_stem_quantfield\"].any(axis='columns')\n",
    "dsjobs[\"degree_any\"] = degree_any\n",
    "\n",
    "# add mention of \"any degree\" to the qualifcations dictionary for analysis and visualisation\n",
    "dict_qualifications[\"degree_any\"] = {'label': \"Any Degree\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of the dictionaries so we can use them later\n",
    "dsjobs_dicts = {\n",
    "    'dict_skills' : dict_skills,\n",
    "    'dict_tools' : dict_tools,\n",
    "    'dict_degsubjects' : dict_degsubjects,\n",
    "    'dict_qualifications' : dict_qualifications,\n",
    "}\n",
    "\n",
    "# save the list of dictionaries as a .pkl file\n",
    "with open('dsjobs_dicts.pkl', 'wb') as f:\n",
    "    pickle.dump(dsjobs_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fully wrangled dsjobs dataframe \n",
    "# as a .csv file\n",
    "dsjobs.to_csv(\n",
    "    os.path.join(path, f'dsjobs_df_{scrapedate}_wrangled.csv'), \n",
    "    encoding='utf-8'\n",
    ")\n",
    "# as a .pkl file which preserves data types (better for processing steps)\n",
    "dsjobs.to_pickle(os.path.join(path, f'dsjobs_df_{scrapedate}_wrangled.pkl'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf77a1a389081cd4a2e68fe826e74ff3c59ede00e7da793e7feb1b74b90842f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('eda-proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
