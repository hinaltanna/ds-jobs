{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Glassdoor data scientist jobs data set that I enriched, cleaned and reduced in Part 2, I will now extract features from the job titles and \"raw\" job descriptions, to prepare the data for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all columns and rows will be displayed if/when you print the dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# ensure all figures will have a white background in this notebook\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 511 entries, 0 to 510\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   job_title               511 non-null    object  \n",
      " 1   salary_estimate         322 non-null    object  \n",
      " 2   job_description         511 non-null    object  \n",
      " 3   rating                  399 non-null    float64 \n",
      " 4   company_name            511 non-null    object  \n",
      " 5   location                511 non-null    object  \n",
      " 6   size                    415 non-null    category\n",
      " 7   founded                 348 non-null    Int64   \n",
      " 8   type_of_ownership       428 non-null    category\n",
      " 9   industry                381 non-null    category\n",
      " 10  sector                  383 non-null    category\n",
      " 11  revenue                 271 non-null    category\n",
      " 12  rating_culturevalues    389 non-null    float64 \n",
      " 13  rating_worklifebalance  394 non-null    float64 \n",
      " 14  rating_diversity        296 non-null    float64 \n",
      " 15  rating_seniormgmt       394 non-null    float64 \n",
      " 16  rating_compbenefits     394 non-null    float64 \n",
      " 17  rating_careerops        394 non-null    float64 \n",
      " 18  api_citytownvilham      488 non-null    object  \n",
      " 19  api_region              488 non-null    category\n",
      " 20  api_country             491 non-null    category\n",
      " 21  uk                      511 non-null    bool    \n",
      " 22  remote                  511 non-null    bool    \n",
      " 23  salary_min              322 non-null    object  \n",
      " 24  salary_max              322 non-null    object  \n",
      " 25  salary_mid              322 non-null    float64 \n",
      " 26  title_datascientist     511 non-null    bool    \n",
      " 27  title_dataanalyst       511 non-null    bool    \n",
      " 28  title_dataengineer      511 non-null    bool    \n",
      " 29  title_mlai              511 non-null    bool    \n",
      " 30  title_research          511 non-null    bool    \n",
      " 31  title_internapprentice  511 non-null    bool    \n",
      " 32  datascience_role        511 non-null    bool    \n",
      "dtypes: Int64(1), bool(9), category(7), float64(8), object(8)\n",
      "memory usage: 77.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# provide the path to the location of the cleaned scraped glassdoor job data\n",
    "path = './data/'\n",
    "\n",
    "# provide glassdoor scrape date\n",
    "scrapedate = '14Dec2020'  # e.g. '14Dec2020', '16Feb2021'\n",
    "\n",
    "# create the absolute path to the cleaned glassdoor job data\n",
    "filename = os.path.join(path, f\"dsjobs_df_{scrapedate}_postclean.pkl\")\n",
    "\n",
    "# read the cleaned data scientist jobs data (.pkl file) into a dataframe\n",
    "dsjobs = pd.read_pickle(filename)\n",
    "\n",
    "# display dataframe info to check that it's what you expected\n",
    "dsjobs.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seniority of position: Identify seniority from the job title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am interested in being able to differentiate between junior and senior positions, so I'll now use the job titles to mark - using Boolean masks - those that mention seniority for the purpose of splitting and comparing these jobs later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True      11\n",
       "False    500\n",
       "Name: seniority_junior, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a regular expression to identify junior positions from the job titles\n",
    "dsjobs[\"seniority_junior\"] = dsjobs[\"job_title\"].str.contains(\n",
    "    r\"\\bjunior\\b|\\bjr.?\\b|\\bentry level\\b|\\bgraduate\\b\", flags=re.IGNORECASE, regex=True)\n",
    "dsjobs[\"seniority_junior\"].value_counts().sort_index(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few job titles indicating a \"junior role\", so I will not analyse this group of jobs separately. I will remove the \"seniority_junior\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the \"seniority_junior\" column\n",
    "dsjobs.drop(columns=\"seniority_junior\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     140\n",
       "False    371\n",
       "Name: seniority_senior, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a regular expression to identify senior positions from the job titles\n",
    "dsjobs[\"seniority_senior\"] = dsjobs[\"job_title\"].str.contains(\n",
    "    r\"\\bsenior\\b|\\bsr.?\\b|\\bexperienced\\b|\\blead\\b|\\bprinciple\\b|\\bchief\\b|\\bmanager\\b|\\bhead\\b\", flags=re.IGNORECASE, regex=True)\n",
    "dsjobs[\"seniority_senior\"].value_counts().sort_index(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large proportion of the job titles in the dataset indicate being of a \"senior\" position, so this Boolean mask (or, new \"feature\") will be useful for analysing these roles separately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skills, experience & education: Job description text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know which skills, experience/knowledge, and education employers are most often looking for in data scientist candidates, but you cannot look through hundreds or thousands of jobs to figure this out, and looking through a small sample might give you the impression that a certain skill/tool/degree is more desireable than it really is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, I'll check the job descriptions in my data set for mentions of various data science skills, tools, and degrees, and record the results for each one within the data science jobs DataFrame (`dsjobs`). This feature engineering and analysis of the results will allow me to identify the most desireable traits employers are looking for in candidates, and which skills/experiences tend to be mentioned together (possibly indicating a relationship). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills: search for mentions of data science skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the role of a data scientist is, and which skills they should have, will vary depending on who you ask, because:\n",
    "- data scientists working in different sectors and industries will have different roles\n",
    "- the label \"data scientist\" has now also been applied to jobs that were previously called something else, e.g. statisticians, data analysts, computer scientists, and \n",
    "- there is a growing demand for specialists with certain combinations of data science skills\n",
    "\n",
    " To learn which skills are most commonly mentioned (and found together) in data science job advertisements, I will create and use a dictionary of regular expressions to search for a wide range of skills within the job description text, and add the results to `dsjobs`. \n",
    " \n",
    " The data science skills I have decided to look for are based on my own knowledge of the data scientist role, scanning many of the job descriptions in the data set, and additional web searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below will be used to develop and optimise the regular expressions \n",
    "# for searching the the job descriptions text for mentions of skills, tools, etc\n",
    "\n",
    "def check_re(jobsdf, regex):\n",
    "    \"\"\" Scans through a random sample of 100 job descriptions from the jobs DataFrame, /\n",
    "    looking for a match to the regular expression(s), and prints up to 20 match objects /\n",
    "    plus the surrounding text (for context)\n",
    "\n",
    "    :param jobsdf: jobs data with job descriptions\n",
    "    :type jobsdf: pandas.core.frame.DataFrame\n",
    "    :param regex: regular expression(s)\n",
    "    :type regex: str | dict\n",
    "    \n",
    "    \"\"\"    \n",
    "    print(f\"*** Pattern = '{regex}' ***\\n\")\n",
    "\n",
    "    # produce a random integer for the sample function\n",
    "    seed = random.randint(0, 100)\n",
    "\n",
    "    if (type(regex) is str):\n",
    "        sample_counter = 1\n",
    "        print_counter = 0\n",
    "        for i in (jobsdf.job_description.sample(n=100, random_state=seed)):\n",
    "            if print_counter >= 20:\n",
    "                break\n",
    "            result = re.search(regex, i, re.IGNORECASE)  # returns 1st occurrence only\n",
    "            if result:\n",
    "                start = result.span()[0]\n",
    "                stop = result.span()[1]\n",
    "                string = i[start-50:stop+50]\n",
    "                print(f\"[{sample_counter}] {string}\\n\")\n",
    "                print_counter += 1\n",
    "            sample_counter += 1\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"regex must be a string\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expression that will be used to search for \n",
    "# data science skills in each job description; the labels will later be used for plots\n",
    "dict_skills = {\n",
    "    \"shell_or_bash\": {\n",
    "        # placing a 'r' before a string literal creates a raw-string literal\n",
    "        # raw strings do not process escape sequences (\\n, \\b, etc.) \n",
    "        're': r\"\\bshell\\b|\\bbash\\b\",  \n",
    "        'label': \"Shell/Bash\"\n",
    "    },\n",
    "    \"version_control\": {\n",
    "        're': \"version control\",\n",
    "        'label': \"Version Control\"\n",
    "    },\n",
    "    \"distributed_data\": {\n",
    "        're': \"distributed data\",\n",
    "        'label': \"Distributed Data\"\n",
    "    },\n",
    "    \"big_unstructured_data\": {\n",
    "        're': \"big data|NoSQL|data lake|unstructured data\",\n",
    "        'label': \"Big Data/Unstructured Data/NoSQL\"\n",
    "    },\n",
    "    \"data_management\": {\n",
    "        're': r\"data\\w* management\",\n",
    "        'label': \"Data Management\"\n",
    "    },\n",
    "    \"data_transformation\": {\n",
    "        're': r\"data transform\\w*|\\betl\\b\",\n",
    "        'label': \"Data Transformation\"\n",
    "    },\n",
    "    \"data_mining\": {\n",
    "        're': r\"\\bmine\\b|\\bmining\\b\",\n",
    "        'label': \"Data Mining\"\n",
    "    },\n",
    "    \"data_streaming\": {\n",
    "        're': r\"\\bdata stream\\w*\",\n",
    "        'label': \"Data Streaming\"\n",
    "    },\n",
    "    \"data_analytics\": {\n",
    "        're': r\"data analy|analy[sz]e data\\w*\",\n",
    "        'label': \"Data Analytics\"\n",
    "    },\n",
    "    \"querying\": {\n",
    "        're': r\"\\bquer\\w*\",\n",
    "        'label': \"Querying\"\n",
    "    },\n",
    "    \"data_cleaning\": {\n",
    "        're': r\"\\bcleaning\\w*|\\bwrangl\\w*|\\bmung\\w*\",\n",
    "        'label': \"Data Cleaning\"\n",
    "    },\n",
    "    \"geospatial\": {\n",
    "        're': \"geospatial\",\n",
    "        'label': \"Geospatial Data\"\n",
    "    },\n",
    "    \"time_series\": {\n",
    "        're': \"time series|time-series\",\n",
    "        'label': \"Time Series Data\"\n",
    "    },\n",
    "    \"web_scraping\": {\n",
    "        're': \"web scraping|scrape\",\n",
    "        'label': \"Web Scraping\"\n",
    "    },\n",
    "    \"data_visualisation\": {\n",
    "        're': r\"data visuali\\w*\",\n",
    "        'label': \"Data Visualisation\"\n",
    "    },\n",
    "    \"dashboard\": {\n",
    "        're': \"dashboard\",\n",
    "        'label': \"Building Dashboards\"\n",
    "    },\n",
    "    \"statistical_modelling\": {\n",
    "        're': r\"predictive analy\\w*|predictive model\\w*|statistical model\\w*\",\n",
    "        'label': \"Statistical Modelling\"\n",
    "    },\n",
    "    \"regression\": {\n",
    "        're': \"regression\",\n",
    "        'label': \"Regression\"\n",
    "    },\n",
    "    \"clustering\": {\n",
    "        're': \"cluster|clustering\",\n",
    "        'label': \"Clustering\"\n",
    "    },\n",
    "    \"classification\": {\n",
    "        're': r\"classif\\w*|decision tree|random forest|svm|support vector machine\",\n",
    "        'label': \"Classification\"\n",
    "    },\n",
    "    \"supervised_learning\": {\n",
    "        're': r\"\\bsupervised\",\n",
    "        'label': \"Supervised Learning\"\n",
    "    },\n",
    "    \"unsupervised_learning\": {\n",
    "        're': \"unsupervised\",\n",
    "        'label': \"Unsupervised Learning\"\n",
    "    },\n",
    "    \"machine_learning\": {\n",
    "        're': r\"machine learning|\\bml\\b\",\n",
    "        'label': \"Machine Learning\"\n",
    "    },\n",
    "    \"deep_learning\": {\n",
    "        're': \"deep learning|neural network\",\n",
    "        'label': \"Deep Learning\"\n",
    "    },\n",
    "    \"dimensionality_reduction\": {\n",
    "        're': r\"dimensionality reduction|principle component analysis|PCA|t-SNE\",\n",
    "        'label': \"Dimensionality Reduction\"\n",
    "    },\n",
    "    \"sequence_modelling\": {\n",
    "        're': r\"sequence model\\w*|rnn\",\n",
    "        'label': \"Sequence Modelling\"\n",
    "    },\n",
    "    \"computer_vision\": {\n",
    "        're': r\"computer vision|machine vision|image classif\\w*\",\n",
    "        'label': \"Computer Vision\"\n",
    "    },\n",
    "    \"NLP\": {\n",
    "        're': \"natural language processing|NLP\",\n",
    "        'label': \"Natural Language Processing\"\n",
    "    },\n",
    "    \"ai\": {\n",
    "        're': r\"artificial intelligence|\\bai\\b\",\n",
    "        'label': \"Artifical Intelligence\"\n",
    "    },\n",
    "    \"hypothesis_testing\": {\n",
    "        're': r\"\\ba\\/b\\b|hypothesis testing\",\n",
    "        'label': \"Hypothesis Testing\"\n",
    "    },\n",
    "    \"cloud_computing\": {\n",
    "        're': \"cloud|cloud computing\",\n",
    "        'label': \"Cloud Computing\"\n",
    "    },\n",
    "    \"software_development\": {\n",
    "        're': \"software development|software engineering\",\n",
    "        'label': \"Software Development/Engineering\"\n",
    "    },\n",
    "    \"agile_working\": {\n",
    "        're': \"agile working|agile develop|agile method|scrum\",\n",
    "        'label': \"Agile Working\"\n",
    "    },\n",
    "    \"pipelines\": {\n",
    "        're': \"pipeline\",\n",
    "        'label': \"Working with/Developing Pipelines\"\n",
    "    },\n",
    "    \"devops\": {\n",
    "        're': r\"\\bci\\b|\\bcd\\b|devops\",\n",
    "        'label': \"DevOps\"\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        're': r\"deploy\\w*\",\n",
    "        'label': \"Deploying Models/Products\"\n",
    "    },\n",
    "    \"containerization\": {\n",
    "        're': r\"container\\w*\",\n",
    "        'label': \"Containerisation\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHELL_OR_BASH\n",
      "\n",
      "*** Pattern = '\\bshell\\b|\\bbash\\b' ***\n",
      "\n",
      "VERSION_CONTROL\n",
      "\n",
      "*** Pattern = 'version control' ***\n",
      "\n",
      "[28] s\n",
      "Understand software engineering best practices (version control, unit tests, code reviews, CI/CD) and how they ap\n",
      "\n",
      "[39]  practices (coding practices to DS, unit testing, version control, code review)\n",
      "Hadoop (especially the Cloudera and\n",
      "\n",
      "[40] L databases\n",
      "Experience with Jupyter Notebooks and version control (eg. Git)\n",
      "Expert in mining large and complex data\n",
      "\n",
      "[52] g quality assurance, automated testing and modern version control software (ideally Github).\n",
      "Experience in using AW\n",
      "\n",
      "[63]  study\n",
      "Familiarity with data management tools and version control systems like Git\n",
      "You have a highly analytical, de\n",
      "\n",
      "[68] lib\n",
      "Experience with Agile technologies (JIRA) and version control software (Git / Subversion)\n",
      "Familiarity with big \n",
      "\n",
      "[71] te robust and high standard code; experience with version control (preferably Git)\n",
      "Experience working with database\n",
      "\n",
      "[84] mulations.\n",
      "Experience with code collaboration and version control, e.g. Bitbucket, Github etc.\n",
      "Strong verbal and wr\n",
      "\n",
      "[87] asticsearch\n",
      "Web services | Cloud computing | APIs\n",
      "Version control | Git | Continuous integration\n",
      "*\n",
      "Contract length:\n",
      "\n",
      "[100] Spark and \"Big-Data\" is desirable\n",
      "Experience with Version Control such as git\n",
      "Comfortable working in a Linux/Mac de\n",
      "\n",
      "DISTRIBUTED_DATA\n",
      "\n",
      "*** Pattern = 'distributed data' ***\n",
      "\n",
      "BIG_UNSTRUCTURED_DATA\n",
      "\n",
      "*** Pattern = 'big data|NoSQL|data lake|unstructured data' ***\n",
      "\n",
      "[3] istical modelling, machine learning, data mining, unstructured data analytics, natural language processing.\n",
      "Proficien\n",
      "\n",
      "[4] t road maps that enable clients to maximize their big data potential.\n",
      "Supervise, Mentor and manage a team of\n",
      "\n",
      "[9] ocesses\n",
      "Undertake preprocessing of structured and unstructured data\n",
      "Analyse large amounts of information to discover \n",
      "\n",
      "[11] xpectations,\n",
      "dunnhumby exists to defy them. Using big data, deep expertise\n",
      "and AI-driven platforms to decode\n",
      "\n",
      "[14] deep learning techniques combining structured and unstructured data.\n",
      "Experience in data engineering, data modelling f\n",
      "\n",
      "[16] d develop scalable, high-performance solutions to big data problems using state-of-the art technologies, lan\n",
      "\n",
      "[17] ng and innovation in areas from machine vision to big data processing using cloud services and beyond.\n",
      "\n",
      "We c\n",
      "\n",
      "[22] and Hadoop/Hive, working with both structured and unstructured data sets\n",
      "Often, our hands-on Data Scientists work as \n",
      "\n",
      "[23]  a talented team of machine learning researchers, big data scientists, computer vision experts, and software\n",
      "\n",
      "[30] nce algorithms on large and small, structured and unstructured data sets, to guide decision-making on Wefarm’s operat\n",
      "\n",
      "[31] owledge and understanding of machine learning and big data technologies to create solutions for customers' c\n",
      "\n",
      "[32]  Python &/or R\n",
      "Experience with Hadoop and related Big Data Technologies\n",
      "Exceptional communication & customer\n",
      "\n",
      "[42] ou’ll be implementing prototypes and working in a Big Data environment\n",
      "Essential skills of the ML Engineer/ \n",
      "\n",
      "[53] tion: use of structured data tools (e.g., SQL), & unstructured data tools and platforms (e.g., Hadoop, Spark, NoSQL)\n",
      "\n",
      "\n",
      "[54] d proactive data analysis of large structured and unstructured datasets, from a variety of data sources\n",
      "Use a wide ra\n",
      "\n",
      "[55] d generate recommendations in a quickly expanding Big Data reality. Using data to drive business decisions a\n",
      "\n",
      "[61] le complex data structures from multiple sources (Big Data, conventional DBs) and different areas (digital, \n",
      "\n",
      "[63] ills:\n",
      "\n",
      "2 years plus experience using Python, SQL, NoSQL and data science toolkits\n",
      "Provide expert insight \n",
      "\n",
      "[66] stics and machine learning\n",
      "Analyse structured and unstructured datasets for insight and improved decision making\n",
      "Work\n",
      "\n",
      "[71] tial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, id\n",
      "\n",
      "DATA_MANAGEMENT\n",
      "\n",
      "*** Pattern = 'data\\w* management' ***\n",
      "\n",
      "[2] pecializing in providing statistics, programming, data management and data science services through the provision o\n",
      "\n",
      "[46] undering/Counter Terrorist Financing and Customer Data Management. We are a fast-growing division of the RELX Group\n",
      "\n",
      "[66] e data access for stakeholders, leading to higher data management maturity and more opportunities for automation an\n",
      "\n",
      "[81] rsity degree\n",
      "Experience using Power BI or similar data management system/software is vital\n",
      "Strong to advanced Excel\n",
      "\n",
      "DATA_TRANSFORMATION\n",
      "\n",
      "*** Pattern = 'data transform\\w*|\\betl\\b' ***\n",
      "\n",
      "[4] ure, or DataBricks\n",
      "Experience with data cleaning, ETL, and Analytic Development\n",
      "Experience with creatin\n",
      "\n",
      "[70] ization\n",
      "Proficiency in SQL and experience in data ETL in large database systems\n",
      "Experience in running a\n",
      "\n",
      "DATA_MINING\n",
      "\n",
      "*** Pattern = '\\bmine\\b|\\bmining\\b' ***\n",
      "\n",
      "[2] ply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the n\n",
      "\n",
      "[15] , AWS cloud services (Redshift)\n",
      "Knowledge of data mining and segmentation techniques.\n",
      "Familiarity with pro\n",
      "\n",
      "[20] experiences in advanced machine learning and data mining strongly preferred\n",
      "Demonstrated ability to conduc\n",
      "\n",
      "[47] em to run in production\n",
      "Utilise algorithmic, data mining, artificial intelligence, machine learning, and s\n",
      "\n",
      "[48] ilities\n",
      "Experience in quantitative analysis, data mining, and presentation of data to see how users intera\n",
      "\n",
      "[50]  and using it to perform continual analysis, data mining and trend spotting to improve our product offerin\n",
      "\n",
      "[77] MI as it can be connected to Salesforce\n",
      "•Use data mining techniques to clean claims data and messages and \n",
      "\n",
      "[82] algorithms would be beneficial\n",
      "Experience in data mining\n",
      "Understanding of machine-learning and operations \n",
      "\n",
      "[90] tructured and unstructured, using a range of data mining techniques such as anomaly detection, clustering,\n",
      "\n",
      "[93] , etc) and software development skills.\n",
      "Expert in mining large & complex data sets - both structured and u\n",
      "\n",
      "[96] st have strong experience using a variety of data mining/data analysis methods & tools, building and imple\n",
      "\n",
      "DATA_STREAMING\n",
      "\n",
      "*** Pattern = '\\bdata stream\\w*' ***\n",
      "\n",
      "DATA_ANALYTICS\n",
      "\n",
      "*** Pattern = 'data analy|analy[sz]e data\\w*' ***\n",
      "\n",
      "[2] ccessful Applicant\n",
      "A track record of working with data analysis and handling sensitive data\n",
      "A track record of \n",
      "\n",
      "[6] ch teams\n",
      "Production experience of data modelling, data analytics, data processing, data visualisation, and sci\n",
      "\n",
      "[7] or our enterprise customers. Your experience with data analysis, statistical modeling, and machine learning wi\n",
      "\n",
      "[14] \n",
      "\n",
      "[16] urrent customers, as well as for Market Research, Data Analysis, and development of optimization models to ena\n",
      "\n",
      "[17] en insights\n",
      "Develop proprietary algorithms, using data analytical methodologies\n",
      "Develop studies to create the \n",
      "\n",
      "[18] ation, cross-device association)\n",
      "Perform hands-on data analysis and modeling with very large data sets to deve\n",
      "\n",
      "[27] Data Scientist to provide operational support and data analytics.\n",
      "\n",
      "What You'll Do\n",
      "Working cross-functionally t\n",
      "\n",
      "[34] machine learning techniques, deep learning, graph data analytics, statistical analysis, time series, geospatia\n",
      "\n",
      "[35] nce in data science.\n",
      "Experience with data basing, data analysis, statistics, and data visualizations.\n",
      "Strong p\n",
      "\n",
      "[36] rgy, saving carbon, saving the environment.\n",
      "\n",
      "As a Data Analyst at OVO Energy you'll play a key role in achievi\n",
      "\n",
      "[41] ea, Vodafone and L’Oreal.\n",
      "\n",
      "We’re looking to add a Data Analyst to our Machine Learning team, working alongside\n",
      "\n",
      "[44] portunities/gaps\n",
      "Proven ability to conduct and/or analyze data and performance results related to digital busine\n",
      "\n",
      "[47] in just a few taps. We are doctors, designers and data analysts. Software developers, managers and marketers. \n",
      "\n",
      "[51] skills development to create new capabilities for data analytics.\n",
      "Implement metrics/scorecards/dashboards to t\n",
      "\n",
      "[52]  - Hertfordshire - Ware\n",
      "Posted Date: Dec 14 2020\n",
      "\n",
      "Data Analyst\n",
      "\n",
      "GlaxoSmithKline is a world leading research-ba\n",
      "\n",
      "[53] ers as needed\n",
      "Requirements\n",
      "Experience in applying data analytics/machine learning solutions to solve business \n",
      "\n",
      "[60] n Business Consulting\n",
      "Take responsibility\n",
      "Conduct data analysis, identify insights and implications and make r\n",
      "\n",
      "[62] ob type:\n",
      "Permanent\n",
      "Job functions:\n",
      "Data Scientist, Data Analyst\n",
      "Salary:\n",
      "£60000 - £65000 per annum + Bonus packa\n",
      "\n",
      "[66] riven approach to drug discovery. We are hiring a Data Analyst to join our Data Content team to help identify,\n",
      "\n",
      "QUERYING\n",
      "\n",
      "*** Pattern = '\\bquer\\w*' ***\n",
      "\n",
      "[21] and collaborative.\n",
      "You've are proficient building queries with SQL.\n",
      "You have experience with AWS or other c\n",
      "\n",
      "[22] u’re an expert who is one of the go-to people for queries from across the business. Working closely with th\n",
      "\n",
      "[40] ;\n",
      "Have some experience with running Elasticsearch queries.\n",
      "What you’ll get from us\n",
      "\n",
      "dentsu international is\n",
      "\n",
      "[44]  Data Lake and to increase speed to ebable easier queries from end users.\n",
      "Requirements for the Data Scienti\n",
      "\n",
      "[47] include:\n",
      "\n",
      "\n",
      "· Data manipulation: Be comfortable in querying large datasets, with the ability to help manipula\n",
      "\n",
      "[51] able skills and experience\n",
      "Familiar with database query language (e.g. SQL)\n",
      "Strong Microsoft Excel skills\n",
      "\n",
      "[62] telligent advertising.\n",
      "\n",
      "Handling over 600 billion queries per day (more than 100X the query volume of searc\n",
      "\n",
      "[77] on the ‘Apply Now’ button below.\n",
      "\n",
      "If you have any queries regarding the vacancy or application process, ple\n",
      "\n",
      "[81]  will be the go-to person for AI and data science queries where you will be expected to lead their presence\n",
      "\n",
      "[93] mmon data science language (ideally python) and a query language\n",
      "You will have experience manipulating la\n",
      "\n",
      "[96] e and optimise a system that handles thousands of queries a week? What product improvements can we make? Ho\n",
      "\n",
      "[97] ence building and leading teams\n",
      "Strong command of querying and programming languages (SQL, Python, R), and v\n",
      "\n",
      "DATA_CLEANING\n",
      "\n",
      "*** Pattern = '\\bcleaning\\w*|\\bwrangl\\w*|\\bmung\\w*' ***\n",
      "\n",
      "[9] ysts to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analy\n",
      "\n",
      "[43] ith hard problems\n",
      "You like all things about data, cleaning it, analysing it, and finding interesting pattern\n",
      "\n",
      "[44] al environment\n",
      "Skills in or familiarity with data cleaning, natural language processing, machine learning, a\n",
      "\n",
      "[70]  engineering – Understanding of data manipulation/wrangling techniques\n",
      "Visualisations – Delivering insights u\n",
      "\n",
      "[78] al environment\n",
      "Skills in or familiarity with data cleaning, natural language processing, machine learning, a\n",
      "\n",
      "[88] nsible for end-to-end analysis of data, from data cleaning to extracting insights\n",
      "Need to be both organised \n",
      "\n",
      "[98] nities for innovation across the company. Mining, cleaning, understanding, explaining, and modelling data fr\n",
      "\n",
      "GEOSPATIAL\n",
      "\n",
      "*** Pattern = 'geospatial' ***\n",
      "\n",
      "[66]  advantageous\n",
      "Startup experience and working with geospatial & financial data is a bonus\n",
      "Additional Informatio\n",
      "\n",
      "[79] ata analytics, statistical analysis, time series, geospatial, NLP, sentiment analysis, pattern detection, etc.\n",
      "\n",
      "[97] ata analytics, statistical analysis, time series, geospatial, NLP, sentiment analysis, pattern detection, etc.\n",
      "\n",
      "TIME_SERIES\n",
      "\n",
      "*** Pattern = 'time series|time-series' ***\n",
      "\n",
      "[2] a science skills\n",
      "Experience in dealing with short time series and limited data availabilityExperience in using \n",
      "\n",
      "[15] g data visualisation tools if necessary\n",
      "Desirable\n",
      "Time-series forecasting (e.g. auto-regressive models)\n",
      "Probabi\n",
      "\n",
      "[33] ding machine learning, model cross validation and time-series analysis. You’ll have experience in using a range\n",
      "\n",
      "[39] ning, graph data analytics, statistical analysis, time series, geospatial, NLP, sentiment analysis, pattern det\n",
      "\n",
      "[71]  or more of: NLP, Probabilistic Graphical Models, Time Series modelling, Deep Learning\n",
      "Experience with visualiz\n",
      "\n",
      "WEB_SCRAPING\n",
      "\n",
      "*** Pattern = 'web scraping|scrape' ***\n",
      "\n",
      "[10] of person who loves unstructured data, preferably scraped from the Web or a streaming social media platfor\n",
      "\n",
      "DATA_VISUALISATION\n",
      "\n",
      "*** Pattern = 'data visuali\\w*' ***\n",
      "\n",
      "[6]  data modelling, data analytics, data processing, data visualisation, and scientific research methods\n",
      "Experience drawi\n",
      "\n",
      "[14] s and numpy would be advantageous\n",
      "Experience with data visualisation tools Qlikview, Tableau, matplotlib\n",
      "Experience wi\n",
      "\n",
      "[16] omer engagement, LTV and retention.\n",
      "Work with our Data Visualization Experts to develop dashboards that visualize the \n",
      "\n",
      "[17] s of our products and digital ecosystem\n",
      "Establish data visualisation toolkit to enable clear communication of techniqu\n",
      "\n",
      "[19] QL and experienced in R or Python\n",
      "Experience with data visualisation tools and data migration\n",
      "Experience of working wi\n",
      "\n",
      "[23] es (e.g. Networkx, Gephi, Neo4j).\n",
      "Experience with data visualization and dashboard tools (e.g. Matplotlib, D3.js, R Sh\n",
      "\n",
      "[35] ng systems and dashboards\n",
      "Support the creation of data visualization tools and Statistical Analysis Plans.\n",
      "Collaborate\n",
      "\n",
      "[36] ills\n",
      "Can confidently build and present meaningful data visualisations, in Excel/Sheets and ideally a dashboarding platf\n",
      "\n",
      "[41] as, and use of Jupyter notebooks.\n",
      "Experience with data visualisation is beneficial but it’s not a requirement of the r\n",
      "\n",
      "[50] guage and create a compelling storyline from it\n",
      "· Data visualization: Work with others to design, deploy and maintain \n",
      "\n",
      "[51]  lead for data mining and analytics, interpreting data visualization, and facilitating the reporting of large integrat\n",
      "\n",
      "[54]  team and regularly communicate the results using data visualisation tools if necessary\n",
      "Desirable\n",
      "Time-series forecast\n",
      "\n",
      "[56] using behavioural analytics, machine learning and data visualization. Our product encompasses leading-edge AI technolo\n",
      "\n",
      "[64]  team and regularly communicate the results using data visualisation tools if necessary\n",
      "Desirable\n",
      "Time-series forecast\n",
      "\n",
      "[74] e Processing, Hierarchical/Multilevel Regression, Data Visualization, Deep Learning, Social Network Analysis, etc.\n",
      "Why\n",
      "\n",
      "[79] \n",
      "Knowledge of or exposure to machine learning and data visualisation techniques (clustering, regression, classificatio\n",
      "\n",
      "[86] sive measurement technologies, complex modelling, data visualisation, data integration and calibration methodologies.\n",
      "\n",
      "\n",
      "DASHBOARD\n",
      "\n",
      "*** Pattern = 'dashboard' ***\n",
      "\n",
      "[10]  Reporting and Monitoring: Developing reports and dashboards to monitor both the training and prediction perf\n",
      "\n",
      "[13] s accounts including properties, user management, dashboards, and reporting\n",
      "Plan, design and implement data a\n",
      "\n",
      "[20] dels, reporting systems, data automation systems, dashboards and performance metrics\n",
      "Maintain reporting syste\n",
      "\n",
      "[23] tions, shared modules, and visualisations\n",
      "Deliver dashboard products to a range of stakeholders\n",
      "Support the a\n",
      "\n",
      "[28] data in various ways, and feed through to PowerBI dashboards or other client facing outputs. They are intende\n",
      "\n",
      "[33] strategic and operational decisions.\n",
      "Build tools, dashboards, reports to simplify day to day work of the prod\n",
      "\n",
      "[35] stood and well-utilised\n",
      "Create analyses, reports, dashboards and tools to track expected quality and summary \n",
      "\n",
      "[41] o understand ways, either through visualisations, dashboards or written reports.\n",
      "\n",
      "Team\n",
      "\n",
      "Reporting to the Seni\n",
      "\n",
      "[63] P or Azure platforms\n",
      "Exposure to and knowledge of dashboarding technology such as PowerBI, Data Studio, Looke\n",
      "\n",
      "[64] ow of accurate data\n",
      "Producing complex and bespoke dashboards, board packs and reports to the wider business t\n",
      "\n",
      "[91] ifetime value, segmentation…)\n",
      "Experience building dashboard or self-serve tools, with preference for Tableau\n",
      "\n",
      "\n",
      "[95] ifetime value, segmentation…)\n",
      "Experience building dashboard or self-serve tools, with preference for Tableau\n",
      "\n",
      "\n",
      "STATISTICAL_MODELLING\n",
      "\n",
      "*** Pattern = 'predictive analy\\w*|predictive model\\w*|statistical model\\w*' ***\n",
      "\n",
      "[4]  (e.g., speech, images, text, clickstream etc) in predictive analysis\n",
      "Experience required:\n",
      "·2-5 large scale Machine Lea\n",
      "\n",
      "[5] Data Science, leading the team in the delivery of predictive models to improve the insurers competitiveness and profi\n",
      "\n",
      "[9] tasets, and to use a variety of methods including statistical modelling, physical modelling, machine learning and optimis\n",
      "\n",
      "[20] t in Python\n",
      "Genomics transcription data, building predictive models of drug response\n",
      "If you feel you have the relevan\n",
      "\n",
      "[21] you will be responsible for developing end to end predictive models\n",
      "Role and Responsibilities:\n",
      "Develop machine learni\n",
      "\n",
      "[22] of experience manipulating data sets and building statistical models. The candidate should have experience/knowledge o\n",
      "\n",
      "[23] ive field and with a proven record of using data, statistical modelling, machine learning and deep learning techniques to\n",
      "\n",
      "[34] for modelling.\n",
      "\n",
      "Use SAS Enterprise Miner to build predictive models and segmentations.\n",
      "\n",
      "Work with the marketing team \n",
      "\n",
      "[35] ied across a number of areas; segmentations, NLP, predictive modelling, recommendation systems,… . Experience using both\n",
      "\n",
      "[38] ndas, Scikit-learn, TensorFlow)\n",
      "Prior exposure to statistical modelling, machine learning and natural language processing\n",
      "\n",
      "[42] nt of the role. The more experience you have with statistical modelling techniques such as regressions, CHAID, and Bayesi\n",
      "\n",
      "[44] Data Scientist or a strong Data Analyst with some statistical modelling / machine learning experience.\n",
      "\n",
      "As Data Analyst, \n",
      "\n",
      "[45] strategic lens. I’m afraid to say experience with predictive modelling and segmentation builds is not enough here, we ne\n",
      "\n",
      "[55] w data sources and data gathering techniques.\n",
      "Use predictive modeling to increase and optimize customer experiences, re\n",
      "\n",
      "[58] nd their data in relation to machine learning and predictive modelling\n",
      "Development of statistical models and algorithms;\n",
      "\n",
      "[59] pervised learning), Data Mining, Prescriptive and Predictive Analytics to improve business capability in warship sustain\n",
      "\n",
      "[60]  of the following areas is required: Forecasting, Predictive Modelling, Optimisation, Unsupervised Learning or NLP and h\n",
      "\n",
      "[61] twork strategies, BI & visualisation and advanced predictive modelling.\n",
      "We work closely with our clients to ensure we un\n",
      "\n",
      "[62] m discovery to production of Machine Learning and predictive models\n",
      "Fluent French language skills\n",
      "Strong skills in va\n",
      "\n",
      "[73] ls (e.g. C#, VB.net, Java, Python);\n",
      "Statistical / predictive modelling techniques and machine learning algorithms (e.g. \n",
      "\n",
      "REGRESSION\n",
      "\n",
      "*** Pattern = 'regression' ***\n",
      "\n",
      "[1]  a variety of machine learning techniques such as regression, classification, cluster analysis and deep learni\n",
      "\n",
      "[3] ou will use your knowledge of linear and logistic regression, variance and forecasting. It is likely that you \n",
      "\n",
      "[26] nchmarking (KPIs etc), trends/forecasts, logistic regression, statisticalanalysis, data mining and anomaly det\n",
      "\n",
      "[30] ills, such as distributions, statistical testing, regression, etc.\n",
      "Solid understanding of databases & SQL\n",
      "Expe\n",
      "\n",
      "[39] ural Language Processing, Hierarchical/Multilevel Regression, Data Visualization, Deep Learning, Social Networ\n",
      "\n",
      "[47]  of the following algorithms:\n",
      "Linear and logistic regression\n",
      "LDA\n",
      "SVM\n",
      "K-nearest neighbors\n",
      "K-means clustering\n",
      "Cl\n",
      "\n",
      "[49] tanding of most commonly used algorithms – Linear Regressions, Random Forests, SVMs, KNN, K-means, etc?\n",
      "Can yo\n",
      "\n",
      "[52] ience topics, models, and methods (from logisitic regression to advanced neural networks)\n",
      "Preferred Education\n",
      "\n",
      "\n",
      "[54] ng these to solving real world classification and regression problems.\n",
      "Work with transparency and good documen\n",
      "\n",
      "[68] d machine learning algorithms for classification, regression and clustering\n",
      "- Familiarity with Big Data framew\n",
      "\n",
      "[74] dictive analytics, classification, clustering and regression.\n",
      "Clean, manage, and structure data from disparate\n",
      "\n",
      "[77] e learning algorithms in a B2B setting, including regression, random forest, naïve Bayes, K-nearest neighbour,\n",
      "\n",
      "[78] Understanding of data science techniques covering regression, classification and segmentation problems.\n",
      "Strong\n",
      "\n",
      "[91] achine learning techniques for classification and regression problems\n",
      "Collaborating with business stakeholders\n",
      "\n",
      "CLUSTERING\n",
      "\n",
      "*** Pattern = 'cluster|clustering' ***\n",
      "\n",
      "[13] ing key behaviours/triggers, creating behavioural clusters or developing propensity models. You will be wor\n",
      "\n",
      "[21]  in data science techniques (e.g. Decision Trees, Clustering, Regression, Nearest Neighbour, Classification\n",
      "\n",
      "[34] e learning methods (e.g., neural network, k-means clustering).\n",
      "Direct experience using structured programmi\n",
      "\n",
      "[63] ised machine learning algorithms for forecasting, clustering, optimisation etc.\n",
      "Interpret statistical model\n",
      "\n",
      "[67] it modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).\n",
      "\n",
      "Provide the vital inf\n",
      "\n",
      "[69] or the job - simple regression, machine learning, clustering, etc.\n",
      "\n",
      "What we're looking for from you\n",
      "Build o\n",
      "\n",
      "[80] nalytics: NLP, Forecasting, Predictive Modelling, Clustering etc\n",
      "Experience developing and deploying cloud \n",
      "\n",
      "[84] methods for predictive analytics, classification, clustering and regression.\n",
      "Clean, manage, and structure d\n",
      "\n",
      "[100] ) and unsupervised machine learning methods (e.g. clustering, k-nearest-neighbours).\n",
      "Advanced competency an\n",
      "\n",
      "CLASSIFICATION\n",
      "\n",
      "*** Pattern = 'classif\\w*|decision tree|random forest|svm|support vector machine' ***\n",
      "\n",
      "[17] scale production deployment; from forecasting and decision trees to the latest developments in deep learning.\n",
      "As \n",
      "\n",
      "[21] ble:\n",
      "Experienced in data science techniques (e.g. Decision Trees, Clustering, Regression, Nearest Neighbour, Clas\n",
      "\n",
      "[28] to ingest partially structured data and organise, classify and categorise into a usable data set\n",
      "Ability to \n",
      "\n",
      "[36] scale production deployment; from forecasting and decision trees to the latest developments in deep learning.\n",
      "As \n",
      "\n",
      "[41] ing and applying analytical solutions, preferably Random Forest, Logistic Regression and XGBoost\n",
      "Advanced SQL kno\n",
      "\n",
      "[46] ious Machine Learning techniques i.e. regression, classification, random forests, decision trees, Bayserian etc (N\n",
      "\n",
      "[58] ing and machine learning techniques e.g. k-means, decision trees, neural networks and ensemble learning is advant\n",
      "\n",
      "[61] d statistical modeling tools and techniques (e.g. random forests, gradient-boosted regression, LASSO, logistic re\n",
      "\n",
      "[75]  applying machine learning techniques (Regression,Random Forest, Gradient Boosting, and Neural Networks) to model\n",
      "\n",
      "[77] g of data science techniques covering regression, classification and segmentation problems.\n",
      "Strong SAS and SQL ski\n",
      "\n",
      "[84] tistical and ML methods for predictive analytics, classification, clustering and regression.\n",
      "Clean, manage, and st\n",
      "\n",
      "[91] direct impact on the business\n",
      "Development of text classification, segmentation and predictive models\n",
      "Unit testing \n",
      "\n",
      "[94] s (indicative list)\n",
      "·Machine Learning Techniques (SVM, Naive Bayes, kNN, K-Means, Random Forest, Dimens\n",
      "\n",
      "[100] luding supervised (e.g. linear regression, LASSO, random forest, support vector machine) and unsupervised machine\n",
      "\n",
      "SUPERVISED_LEARNING\n",
      "\n",
      "*** Pattern = '\\bsupervised' ***\n",
      "\n",
      "[5] tic or linear regression, gradient boosted trees, supervised techniques such as classification\n",
      "PLUS at least o\n",
      "\n",
      "[17] machine-learning models\n",
      "Demonstrate experience of supervised learning, unsupervised learning is desirable\n",
      "Good\n",
      "\n",
      "[23] llent knowledge of data science methods including supervised (e.g. linear regression, LASSO, random forest, su\n",
      "\n",
      "[34] ailed knowledge on a range of AI techniques (e.g. supervised and un-supervised machine learning techniques, de\n",
      "\n",
      "[56] ng, and evaluation approaches for a wide range of supervised and unsupervised problems.\n",
      "Work closely with Lega\n",
      "\n",
      "[59] sis, Anomaly Detection, Dimensionality Reduction, Supervised and Unsupervised Learning techniques)\n",
      "Demonstrabl\n",
      "\n",
      "[75] ata.\n",
      "Capabilities in a range of AI techniques (eg supervised and unsupervised machine learning techniques, dee\n",
      "\n",
      "[80] dge of different modelling techniques across both supervised and unsupervised learning methods with demonstrab\n",
      "\n",
      "[92]  etc.).\n",
      "Demonstrable machine learning experience (supervised/unsupervised) such as developing and deploying de\n",
      "\n",
      "[100] \n",
      "Develop predictive statistical models using both supervised and unsupervised machine learning algorithms for \n",
      "\n",
      "UNSUPERVISED_LEARNING\n",
      "\n",
      "*** Pattern = 'unsupervised' ***\n",
      "\n",
      "[49] xperience with deep learning, graph analytics and unsupervised learning methods\n",
      "Experience in healthcare\n",
      "Experie\n",
      "\n",
      "[64] ed subjects\n",
      "Project experience in Generative AI & Unsupervised models (VAEs, GANs, Transformers etc.)\n",
      "2+ years s\n",
      "\n",
      "[75]  and SQL\n",
      "Proficient in R or Python\n",
      "Supervised and unsupervised machine learning\n",
      "Statistics\n",
      "Beneficial experience\n",
      "\n",
      "[93] nowledge of and experience with latest supervised/unsupervised machine learning techniques and algorithms eg GBM\n",
      "\n",
      "[100] We have a unique approach combining best in class unsupervised and supervised techniques to solve hard problems \n",
      "\n",
      "MACHINE_LEARNING\n",
      "\n",
      "*** Pattern = 'machine learning|\\bml\\b' ***\n",
      "\n",
      "[1]  Science, Programming languages/visualising data, machine learning, AI or deep neutral net technologies.\n",
      "Security Cl\n",
      "\n",
      "[2] ta visualisation, scientific research methods and machine learning.\n",
      "Communicating and Influencing – Level 3\n",
      "Working \n",
      "\n",
      "[3] developing high quality solutions that use AI and ML technologies to delight our customers and impact \n",
      "\n",
      "[4] dictive models\n",
      "Role and Responsibilities:\n",
      "Develop machine learning and AI models that are scaled across multiple mar\n",
      "\n",
      "[5] oduction ready data solutions which can vary from machine learning, data pipelines to advanced visualisation tools.\n",
      "\n",
      "\n",
      "[6] the most effective techniques in data science and machine learning.\n",
      "Build out Statistical and Machine Learning model\n",
      "\n",
      "[7] oducts\n",
      "Explore and apply predictive modelling and machine learning techniques to internal and new datasets to advanc\n",
      "\n",
      "[8] nce with data analysis, statistical modeling, and machine learning will lead to immediate real-world impact in the f\n",
      "\n",
      "[10] hion industry.\n",
      "The Role:\n",
      "Design, train and deploy machine learning solutions focusing on customer behaviour modellin\n",
      "\n",
      "[11] Income, using financial modelling, statistics and machine learning\n",
      "Analyse structured and unstructured datasets for \n",
      "\n",
      "[13] vast data sets to improve and create a variety of machine learning models\n",
      "Responsibilities:\n",
      "Experiment, train and de\n",
      "\n",
      "[15] Dariush Hessami\n",
      "JobsLondonTechnology\n",
      "11 Dec, 2020\n",
      "Machine Learning Scientist (London)\n",
      "Dariush Hessami\n",
      "Business Consu\n",
      "\n",
      "[16] formance within the portfolio\n",
      "Building end-to-end machine learning solutions, as well as driving key strategic insig\n",
      "\n",
      "[17] the data science team, you will be using advanced machine learning and optimisation techniques to build tools that w\n",
      "\n",
      "[18] g the right tool for the job - simple regression, machine learning, clustering, etc.\n",
      "\n",
      "What we're looking for from yo\n",
      "\n",
      "[19] llaboratingwith a larger team of data scientists, machine learning scientists and dataengineers.\n",
      "\n",
      "= Remainingup to d\n",
      "\n",
      "[20] d platforms\n",
      "You have an in-depth understanding of Machine Learning algorithms\n",
      "You have basic understanding of powers\n",
      "\n",
      "[22] with robust impact estimates; building production machine learning and optimisation models; and upskilling the entir\n",
      "\n",
      "[23] h solid experience in programming (R, Python) and machine learning/AI methodologies.\n",
      "Job Overview\n",
      "\n",
      "COMPANY BACKGROUN\n",
      "\n",
      "[25] au, etc\n",
      "Expertise and experience in data science, machine learning and statistics\n",
      "Interest and endurance in taking o\n",
      "\n",
      "DEEP_LEARNING\n",
      "\n",
      "*** Pattern = 'deep learning|neural network' ***\n",
      "\n",
      "[1] ve a practical understanding of machine learning, Deep Learning and natural language understanding/processing or \n",
      "\n",
      "[3] nk, Docker, Kubernetes, NoSQL DB)\n",
      "Experience with deep learning, graph analytics and unsupervised learning method\n",
      "\n",
      "[8] in ethical behaviour of global organisations\n",
      "Used deep learning to uncover optimal settings to make a pharmaceuti\n",
      "\n",
      "[11] junior team members or graduates\n",
      "Using R\n",
      "Applying deep learning techniques\n",
      "Statistical/probabilistic knowledge of\n",
      "\n",
      "[15] bilistic Graphical Models, Time Series modelling, Deep Learning\n",
      "Experience with visualization and attribution tec\n",
      "\n",
      "[22] \n",
      "Experience with Data science toolkits for ML and deep learning (scikit-learn, SparkML, Tensorflow, Keras)\n",
      "Experi\n",
      "\n",
      "[23] ust have excellent Python skills, experience with Deep Learning is beneficial.\n",
      "Interviews will be via Telephone/Z\n",
      "\n",
      "[30] nd machine learning\n",
      "Delivering solutions based on deep learning\n",
      "Delivering solutions based on NLP\n",
      "Deploying machi\n",
      "\n",
      "[37]  all things AI, whether that be machine learning, deep learning, computer vision and so on, combined with great s\n",
      "\n",
      "[43] icularly strong interest in using ML, and ideally deep learning, with natural language. It is an applied ML role,\n",
      "\n",
      "[45] ne of the modern distributed Machine Learning and Deep Learning frameworks such as TensorFlow, PyTorch, MxNet Caf\n",
      "\n",
      "[53] l Intelligence ( AI ) , Machine Learning ( ML ) , Deep Learning ( DL ) , and statistics.\n",
      "Skills and experience (a\n",
      "\n",
      "[56] cluding advanced statistical and machine learning/deep learning methods.\n",
      "Experience of operating in a HPC Unix en\n",
      "\n",
      "[60] s (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks\n",
      "\n",
      "[73] /Java/Scala.\n",
      "Experience with reinforcement and/or deep learning.\n",
      "Application of GPU computing platforms/architect\n",
      "\n",
      "[75] Keras | Tensorflow | PyTorch | NumPy\n",
      "Regression | Neural networks | Decision Trees | Clustering\n",
      "Simulation | model\n",
      "\n",
      "[78] sed and unsupervised machine learning techniques, deep learning, graph data analytics, statistical analysis, time\n",
      "\n",
      "[87] arfetch customers.\n",
      "\n",
      "You will design and implement deep learning models (e.g., graph embeddings) to fit various us\n",
      "\n",
      "[90] , such as clustering, regression, classification, deep learning.\n",
      "Must have experience in developing production-re\n",
      "\n",
      "[91] language processing (NLP), Machine learning (ML), Deep learning (DL) and Neural Networks.\n",
      "You will be hands on wi\n",
      "\n",
      "DIMENSIONALITY_REDUCTION\n",
      "\n",
      "*** Pattern = 'dimensionality reduction|principle component analysis|PCA|t-SNE' ***\n",
      "\n",
      "[4] s (SVM, Naive Bayes, kNN, K-Means, Random Forest, Dimensionality Reduction Algorithms, and Gradient Boosting etc.)\n",
      "· Deep Le\n",
      "\n",
      "[81] gence, Feed-forward nets, and smart agent systems\n",
      "Dimensionality reduction and manifold learning, and clustering methods\n",
      "LSH\n",
      "\n",
      "SEQUENCE_MODELLING\n",
      "\n",
      "*** Pattern = 'sequence model\\w*|rnn' ***\n",
      "\n",
      "[46] ion of Supply Chains\n",
      "Experience in Deep Learning (RNN), particularly Reinforcement Learning\n",
      "Experience \n",
      "\n",
      "[78] n environments (AWS)\n",
      "Experience in Deep Learning (RNN)\n",
      "Benefits\n",
      "\n",
      "All Gousto employees are offered a ben\n",
      "\n",
      "COMPUTER_VISION\n",
      "\n",
      "*** Pattern = 'computer vision|machine vision|image classif\\w*' ***\n",
      "\n",
      "[64] lgorithms for real business problems.\n",
      "NLU/NLP and computer vision-based predictions and inference for B2B use cases\n",
      "\n",
      "[70] re. We use the most advanced machine learning and computer vision techniques, delivering actionable insights on cro\n",
      "\n",
      "NLP\n",
      "\n",
      "*** Pattern = 'natural language processing|NLP' ***\n",
      "\n",
      "[3] owing techniques: machine learning, data linking, natural language processing) –NLP is not essential\n",
      "Experience of analysing la\n",
      "\n",
      "[4] adient Descent, Learning Rate Decay, LTSM etc.)\n",
      "· NLP/NLG Capabilities (Content Categorisation, Topic D\n",
      "\n",
      "[6] \n",
      "\n",
      "[10] ed on deep learning\n",
      "delivering solutions based on NLP\n",
      "deploying machine learning to Cloud platforms (e.\n",
      "\n",
      "[29] ted mobile services utilising video analytics and NLP speech recognition to analyse and categorise meet\n",
      "\n",
      "[30]  deep learning solutions relating to time series, NLP, video, and images.\n",
      "Expert knowledge in visualizi\n",
      "\n",
      "[35]  applied across a number of areas; segmentations, NLP, predictive modelling, recommendation systems,… .\n",
      "\n",
      "[38] re to statistical modelling, machine learning and natural language processing\n",
      "A keen interest in financial markets, quantitativ\n",
      "\n",
      "[45] heat mapping, digital automation and attribution, NLP, machine learning, AI and building recommendation\n",
      "\n",
      "[47] roficient in Python, SQL\n",
      "Experience in developing NLP, classification and deep learning models\n",
      "Strong s\n",
      "\n",
      "[54] logy to create solutions which are centred around Natural language processing (NLP), Machine learning (ML), Deep learning (DL) \n",
      "\n",
      "[60] Modelling, Optimisation, Unsupervised Learning or NLP and have experience building and deploying advanc\n",
      "\n",
      "[66] logy to create solutions which are centred around Natural language processing (NLP).\n",
      "You will be hands on with the development \n",
      "\n",
      "[82]  Cloud context group has deep roots in the use of natural language processing, and information retrieval technology.\n",
      "\n",
      "As a Data\n",
      "\n",
      "[83] \n",
      "\n",
      "[91] gnificant product demonstrating successful use of NLP and chatbot user interaction.\n",
      "Your experience wil\n",
      "\n",
      "AI\n",
      "\n",
      "*** Pattern = 'artificial intelligence|\\bai\\b' ***\n",
      "\n",
      "[2] the end-user.\n",
      "\n",
      "LogicPlum is and always will be an artificial intelligence company. We hire people with a broad set of techn\n",
      "\n",
      "[5] and enhance analysis through machine learning and artificial intelligence. Through this augmented analysis we can protect g\n",
      "\n",
      "[6] ate Data Scientist you will focus on Big Data and AI technologies to solve problems in a variety of in\n",
      "\n",
      "[9] has brought one of the most exciting, disruptive, AI platforms to the UK market!\n",
      "\n",
      "THE ROLE\n",
      "\n",
      "The succes\n",
      "\n",
      "[16] oneering technologies, such as cloud engineering, artificial intelligence, the Internet of Things for Industry 4.0, and blo\n",
      "\n",
      "[22] cal use of data\n",
      "A bit about the team:\n",
      "\n",
      "The Data & AI Team, shortlisted for the ‘Best Analytics Team’ D\n",
      "\n",
      "[25] on with leading Professor of Machine Learning and AI\n",
      "Candidate must have the right to work in the UK, \n",
      "\n",
      "[28] s)\n",
      "Worked with clients to successfully apply your AI know-how to their opportunities and challenges\n",
      "An\n",
      "\n",
      "[31] ring global solutions\n",
      "Use of Machine Learning and Artificial Intelligence in the generation of hypotheses within Real World\n",
      "\n",
      "[33] g and processing data.\n",
      "Capabilities in a range of AI techniques (eg supervised and unsupervised machin\n",
      "\n",
      "[35]  it’s churning gigabytes of ecommerce data, using AI to recommend the latest trends, or understanding \n",
      "\n",
      "[37] to field polygons that were developed by applying AI algorithms to earth observation (EO)/satellite da\n",
      "\n",
      "[39] \n",
      "Have a passion for deploying robust and scalable AI solutions\n",
      "Have an interest in working closely wit\n",
      "\n",
      "[40] rip, through Personalization, Customer Experience AI and Relevance algorithms. We offer the chance to \n",
      "\n",
      "[41] ime. Yuno also has plans for Machine Learning and AI capabilities to improve efficiency internally, fo\n",
      "\n",
      "[43] althcare and life sciences through their powerful AI engine. Working alongside some of the best data s\n",
      "\n",
      "[45] \n",
      "\n",
      "[47] \n",
      "\n",
      "[53] wledge Transfer Partnership (KTP) Associate. Humn.ai Ltd is an Insurtech company backed by Venture Cap\n",
      "\n",
      "[56]  acting as Data Scientist, having been working on AI/Machine Learning projects\n",
      "Strong understanding of\n",
      "\n",
      "HYPOTHESIS_TESTING\n",
      "\n",
      "*** Pattern = '\\ba\\/b\\b|hypothesis testing' ***\n",
      "\n",
      "[27] project management experience\n",
      "Funnel analysis and A/B tests\n",
      "Excellent communication skills; written and\n",
      "\n",
      "[32] tist, Data Analyst, Python, R, Backend, Bayesian, Hypothesis Testing, Isometric Testing, Data Analysis, Statistics, Bi\n",
      "\n",
      "[43] owledge of statistics (statistical distributions, hypothesis testing, and confidence intervals).?\n",
      "Do you have experien\n",
      "\n",
      "[60] hon\n",
      "You have experience in conducting large scale A/B experiments\n",
      "Nice to haves:\n",
      "You have multiple year\n",
      "\n",
      "[62] odel performance and uncertainty, you can perform hypothesis testing, you can evaluate the pros and cons of the algori\n",
      "\n",
      "[77]  measure things that matter; initiate or help run A/B experiments to keep improving everything we do\n",
      "Dr\n",
      "\n",
      "[87] ical background with knowledge of regressions and hypothesis testing\n",
      "Full proficiency using SQL, coding from scratch, \n",
      "\n",
      "[96] ision making across marketing attribution and ROI\n",
      "A/B testing strategies for adverts, tools, design and\n",
      "\n",
      "CLOUD_COMPUTING\n",
      "\n",
      "*** Pattern = 'cloud|cloud computing' ***\n",
      "\n",
      "[1] s (version control, CI/CD, containers, etc.) in a cloud platform (GCP, AWS)\n",
      "High commercial awareness to \n",
      "\n",
      "[3] nsorFlow)\n",
      "Knowledge of TensorFlow\n",
      "Experience with cloud infrastructure (such as GCP or AWS)\n",
      "Sound knowled\n",
      "\n",
      "[9] data science tools, data visualization tools, and cloud environments e.g., Azure, Power BI, SQL server, S\n",
      "\n",
      "[13] ders & AI specialists who are developing a unique cloud-based integrated security platform that will save\n",
      "\n",
      "[18] ges such as Hadoop, Spark, R, Python, and ideally cloud computing infrastructure (e.g. Azure, AWS).\n",
      "Takes\n",
      "\n",
      "[19] ud to be the developer of the industry acclaimed; cloud based “Drive-Sync” connected car platform. From i\n",
      "\n",
      "[25] cientific or engineering discipline\n",
      "Experience in cloud data services, Google Cloud Platform (especially \n",
      "\n",
      "[28] utions based on NLP\n",
      "Deploying machine learning to Cloud platforms (e.g. AWS, Azure)\n",
      "Adversarial learning\n",
      "\n",
      "\n",
      "[32] nal work experience setting up and managing Azure cloud services in a corporate environment\n",
      "Work effectiv\n",
      "\n",
      "[46] ’s biggest fashion site data and can leverage our cloud based systems.\n",
      "\n",
      "What will you be working on?\n",
      "Buil\n",
      "\n",
      "[48] ermanent\n",
      "December 13, 2020\n",
      "Machine Learning Lead (Cloud, NLP, Ops)\n",
      "London, England\n",
      "£75000 - £90000 per an\n",
      "\n",
      "[52] s all aspects of pioneering technologies, such as cloud engineering, artificial intelligence, the Interne\n",
      "\n",
      "[57] ence\n",
      "Work with the data architect teams on Google Cloud Platform / Amazon AWS / Azure\n",
      "Manage Analysts, pr\n",
      "\n",
      "[63] f clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50\n",
      "\n",
      "[67] . All our data infrastructure lives on the Google Cloud Platform, so you don't need to spend your time co\n",
      "\n",
      "[68] ner (including Deep Learning)\n",
      "Experience with AWS cloud services or other Cloud platforms\n",
      "Experienced sof\n",
      "\n",
      "[69] ial)\n",
      "Any experience doing data engineering in the cloud would be ideal such as Azure, AWS or GCP for exam\n",
      "\n",
      "[71] t with Go, C/C++, other languages\n",
      "Proficient with cloud computing environments, Kubernetes, etc.\n",
      "Software\n",
      "\n",
      "[74] tate of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of b\n",
      "\n",
      "[78] icated user community.\n",
      "We are heavily invested in cloud technologies, especially (but not exclusively) Am\n",
      "\n",
      "SOFTWARE_DEVELOPMENT\n",
      "\n",
      "*** Pattern = 'software development|software engineering' ***\n",
      "\n",
      "[1] ning and predictive analytics to join our growing software engineering team. Our scale-up enterprise learning software c\n",
      "\n",
      "[3] will therefore be vital.\n",
      "Nice to haves\n",
      "Understand software engineering best practices (version control, unit tests, code\n",
      "\n",
      "[8] g, computer vision and so on, combined with great software engineering skills…no point creating great models if we can’t\n",
      "\n",
      "[21]  languages: Python, Java, R, SPARK, SQL, etc) and software development skills\n",
      "Expert in mining large and complex data se\n",
      "\n",
      "[22] d frameworks (eg Tensorflow, MXNet, scikit-learn)\n",
      "Software engineering – Good Software engineering practices (unit testi\n",
      "\n",
      "[24]  audiences\n",
      "Data visualisation\n",
      "Working in an agile software development environment\n",
      "\n",
      "Desirable\n",
      "\n",
      "Natural language processi\n",
      "\n",
      "[28] ween the different components/features within the software development life cycle and identify bottlenecks\n",
      "Forecasting c\n",
      "\n",
      "[30] lable IT solutions, GFT increases productivity in software development. This provides clients with faster access to new \n",
      "\n",
      "[35] he right person will have a good appreciation for software engineering and how to build production-quality systems using\n",
      "\n",
      "[42] ndering\n",
      "Essential skills\n",
      "\n",
      "Analytics, modelling or software development experience including coding/software development \n",
      "\n",
      "[46] nce with developing solutions following a defined Software Development Life Cycle\n",
      "Why GSK?\n",
      "Our values and expectations a\n",
      "\n",
      "[48] ages (e.g. Python, Java, R, SPARK, SQL, etc.) and software development skills.\n",
      "Possess considerable experience working a\n",
      "\n",
      "[49] tions and Skills\n",
      "Deep and passionate knowledge of software engineering principles, practices\n",
      "Proven knowledge of object-\n",
      "\n",
      "[51] ualifications include:\n",
      "Experience of modern Agile software development methodologies and DevOps practices;Exposure to da\n",
      "\n",
      "[53] Specific Skills:\n",
      "Knowledge and experience of good software engineering practices\n",
      "Keen interest and desire to stay abreas\n",
      "\n",
      "[55] siness partner.\n",
      "Desirable Criteria:\n",
      "Experience in software engineering, data engineering, consulting, or academic resear\n",
      "\n",
      "[60] \n",
      "This is an opportunity to join a high performing software development team, in a data scientist role, working for a glo\n",
      "\n",
      "[67] ential\n",
      "Bachelors/Masters/PhD in Computer Science, Software Engineering, Mathematics or equivalent.\n",
      "Excellent Python and \n",
      "\n",
      "[74] d Machine Learning models from scratch\n",
      "Scientific software development experience with Python\n",
      "Ideally, a knowledge of bi\n",
      "\n",
      "[77] g with and alongside our customers, we use modern software engineering methods (Scaled Agile Development, DevSec Ops, Si\n",
      "\n",
      "AGILE_WORKING\n",
      "\n",
      "*** Pattern = 'agile working|agile develop|agile method|scrum' ***\n",
      "\n",
      "[2] e use modern software engineering methods (Scaled Agile Development, DevSec Ops, Site Reliability Engineering, mi\n",
      "\n",
      "[65] time / basis.\n",
      "“Our team members work a variety of agile working patterns. Tell us what arrangement works for you \n",
      "\n",
      "[75] terprise systems.\n",
      "You will be supporting on-going agile development projects. The development will build upon a b\n",
      "\n",
      "[90] of modern software engineering practices, such as SCRUM/Agile, micro-services and containerisation (inclu\n",
      "\n",
      "[97] data analytics team in UK\n",
      "Participate in an Agile/Scrum methodology\n",
      "\n",
      "Required Competencies:\n",
      "Preference an\n",
      "\n",
      "[99] tegrated in our Science team working according to Agile methodologies (Scrum) in close collaboration with other \n",
      "\n",
      "PIPELINES\n",
      "\n",
      "*** Pattern = 'pipeline' ***\n",
      "\n",
      "[7]  data warehouse\n",
      "design, build and launch new data pipelines in production\n",
      "You should apply if\n",
      "you have stron\n",
      "\n",
      "[9] to Ripjar's software products and data processing pipelines.\n",
      "You will have a strong technical and theoretica\n",
      "\n",
      "[20] cker, Kubernetes or any other job scheduling/data pipeline tools;\n",
      "Have some experience with running Elastics\n",
      "\n",
      "[22] .\n",
      "Experience building large scale data processing pipelines. e. g. Hadoop/Spark and SQL.\n",
      "Experience provisio\n",
      "\n",
      "[38] ensorflow, Keras\n",
      "\n",
      "= Knowledgeof standard ETL data pipeline tools/techniques.\n",
      "\n",
      "= The abilityto lead a team or\n",
      "\n",
      "[45] eering, especially with advanced SQL and big data pipeline skills\n",
      "Over 3 years of experience in machine lear\n",
      "\n",
      "[47] a Analytics estate which has large number of data pipelines moving, messaging and transforming data between \n",
      "\n",
      "[51] ational needs and health needs with your delivery pipeline.\n",
      "You’re purpose driven. You care about the value \n",
      "\n",
      "[55] the movement of populations.\n",
      "Developing efficient pipelines to transform vast datasets into usable informati\n",
      "\n",
      "[63] arning techniques and distributed/serverless data pipelines to process a wide variety of data, including bat\n",
      "\n",
      "[67] to Ripjar's software products and data processing pipelines.\n",
      "You will have a strong technical and theoretica\n",
      "\n",
      "[70] ve opportunities to create/optimise computational pipelines and develop new statistical methods for the anal\n",
      "\n",
      "[75] king or similarity algorithms\n",
      "Experience with ETL pipelines\n",
      "Have a detail oriented mindset and actively demo\n",
      "\n",
      "[81] y, sometimes mysql, oracle, and vertica\n",
      "Authoring pipelines via SQL and python based ETL framework\n",
      "Building \n",
      "\n",
      "[87] ost sales\n",
      "Ability to develop a customer and sales pipeline to achieve practice level sales targets\n",
      "Ability t\n",
      "\n",
      "[88]  data warehouse\n",
      "design, build and launch new data pipelines in production\n",
      "You should apply if\n",
      "you have stron\n",
      "\n",
      "[95] vity\n",
      "Developing and enhancing data structures and pipelines, and supporting BI with data migrations to ensur\n",
      "\n",
      "DEVOPS\n",
      "\n",
      "*** Pattern = '\\bci\\b|\\bcd\\b|devops' ***\n",
      "\n",
      "[46] nagement systems, CRM, etc. We use GitHub, travis-ci, code-pipeline and cloudformation and a devops ap\n",
      "\n",
      "[54] h etc.) and SQL\n",
      "Working knowledge of Git, Docker, CI/CD, REST API\n",
      "Ability to work under pressure and m\n",
      "\n",
      "[67] itbucket, NoSQL/MongoDB, Linux.\n",
      "Optional: Docker, CI/CD processes knowledge.\n",
      "Experience\n",
      "3-5 years of p\n",
      "\n",
      "[75] \n",
      "Process: Agile, Scrum\n",
      "Demonstrable experience of DevOps tools: CI – Visual Studio/Jupyter, SCM –Github/Gi\n",
      "\n",
      "DEPLOYMENT\n",
      "\n",
      "*** Pattern = 'deploy\\w*' ***\n",
      "\n",
      "[2] ning projects: from R&D to large-scale production deployment; from forecasting and decision trees to the lates\n",
      "\n",
      "[11]  framing, data preparation, model building, model deployment, model management, and output consumption\n",
      "In some\n",
      "\n",
      "[14]  platform and work with the team to prototype and deploy analytics models to predict certain failures and \n",
      "\n",
      "[19] olutions.\n",
      "Experience developing, implementing and deploying predictive models, machine learning algorithms or\n",
      "\n",
      "[22] rk on a variety of data tasks including building, deploying and monitoring models, creating visualisations, a\n",
      "\n",
      "[26]  game-changing projects and technologies that get deployed on devices and the cloud. As a Sr. ML Data Scient\n",
      "\n",
      "[30] ta scientist with excellent analytical skills and deployment experience.\n",
      "You will be part of a growing data sc\n",
      "\n",
      "[32] he fashion industry.\n",
      "\n",
      "The Role:\n",
      "Design, train and deploy machine learning solutions focusing on customer b\n",
      "\n",
      "[34]  insights that will ultimately lead to production deployment\n",
      "Identifying new methods, tools, techniques and op\n",
      "\n",
      "[35] ry capability. As part of a growing team you will deploy our technology to help our customers solve their \n",
      "\n",
      "[38]  AWS technologies such as Lambda and SageMaker to deploy our models.\n",
      "\n",
      "The Data Science team is currently f\n",
      "\n",
      "[49] ronment.\n",
      "Experience of containerisation and cloud deployment.\n",
      "Experience of Deep Learning Architectures (e.g. \n",
      "\n",
      "[51] xperience of working within a team to develop and deploy a technical product, including experience with mo\n",
      "\n",
      "[64] allenges in extreme environments by designing and deploying ground-breaking technology that interprets data c\n",
      "\n",
      "[71] P per day\n",
      "Detailed JD:\n",
      "Proficient in Python\n",
      "Model deployment on AWS Sagemaker when the model is trained outsid\n",
      "\n",
      "[80] ave a large data science function that builds and deploys machine learning models for all business areas.\n",
      "W\n",
      "\n",
      "[84]  Venture Capital and Private Investment firms who deploy and manage large data platforms in real time. The\n",
      "\n",
      "[88]  Science, Statistics\n",
      "Experience in developing and deploying machine learning algorithms using Python or R.\n",
      "Pr\n",
      "\n",
      "[90] king a project from an initial concept through to deployment in a production system\n",
      "Experience of championing \n",
      "\n",
      "[96] ts.\n",
      "Model development and performance evaluation.\n",
      "Deploying models in production environments.\n",
      "Continuous eva\n",
      "\n",
      "CONTAINERIZATION\n",
      "\n",
      "*** Pattern = 'container\\w*' ***\n",
      "\n",
      "[49] anguage like Python (preferred) or R\n",
      "Knowledge of container platforms, e.g. dockers\n",
      "Business-oriented present\n",
      "\n",
      "[88] ces in a variety of environments.\n",
      "Experience with containers and microservice architectures e.g. Kubernetes, D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use check_re to test the regex dictionary that will be used to search for skills\n",
    "for key, val in dict_skills.items():\n",
    "    print(f\"{key.upper()}\\n\")\n",
    "    check_re(jobsdf=dsjobs, regex=val[\"re\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda function below throws a SettingWithCopyWarning but I have checked that\n",
    "# I am not making a change to a copy so this warning will be suppressed\n",
    "from warnings import simplefilter\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each skill in the dict_skills, create a column in the dataframe with the 'label',\n",
    "# with a lambda function, search for the skill in each job's description text using \n",
    "# the regular expression ('re'), entering the boolean result in the column, 'label'\n",
    "for key, val in dict_skills.items():\n",
    "    dsjobs[key] = dsjobs[\"job_description\"].apply(\n",
    "        lambda x: bool(re.search(val['re'], x, re.IGNORECASE)))\n",
    "    # # if you want to see the results for debugging, uncomment below\n",
    "    # print(f\"{val['label']} : {round(np.mean(dsjobs[key])*100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools: search for mentions of data science tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job descriptions will almost always name programming languages and other data science tools that the company uses or the employer expects candidates to know/have experience with. I want to know which tools are most popular among employers/companies, so I will create and test a dictionary of regular expressions to search for a wide range of tools within the description text of each job, and add the results to `dsjobs`. The data science tools I have decided to look for are based on my own knowledge of the data scientist role, scanning many of the job descriptions in the data set, and additional web searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expression that will be used to search for \n",
    "# data science tools in each job description; the labels will later be used for plots\n",
    "dict_tools = {\n",
    "    \"python\": {\n",
    "        # programming language\n",
    "        're': r\"\\bpython\\b\",\n",
    "        'label': \"Python\"\n",
    "    },\n",
    "    \"r\": {\n",
    "        # programming language\n",
    "        're': r\"\\br(?!&)\\b|\\brstudio\\b\",\n",
    "        'label': \"R\"\n",
    "    },\n",
    "    \"scala\": {\n",
    "        # programming language\n",
    "        're': r\"\\bscala\\b\",\n",
    "        'label': \"Scala\"\n",
    "    },\n",
    "    \"matlab\": {\n",
    "        # desktop environment tuned for iterative analysis and design processes with a \n",
    "        # programming language that expresses matrix and array mathematics directly\n",
    "        're': r\"\\bmatlab\\b\",\n",
    "        'label': \"MATLAB\"\n",
    "    },\n",
    "    \"sas\": {\n",
    "        # statistical software suite\n",
    "        're': r\"\\bsas\\b\",\n",
    "        'label': \"SAS\"\n",
    "    },\n",
    "    \"spss\": {\n",
    "        # software package used for interactive, or batched, statistical analysis\n",
    "        're': r\"\\bspss\\b\",\n",
    "        'label': \"SPSS\"\n",
    "    },\n",
    "    \"stata\": {\n",
    "        # statistical software package\n",
    "        're': r\"\\bstata\\b\",\n",
    "        'label': \"Stata\"\n",
    "    },\n",
    "    \"perl\": {\n",
    "        # programming language\n",
    "        're': r\"\\bperl\\b\",\n",
    "        'label': \"Perl\"\n",
    "    },\n",
    "    \"unix\": {\n",
    "        # Operating system\n",
    "        're': r\"\\bunix\\b\",\n",
    "        'label': \"Unix\"\n",
    "    },\n",
    "    \"linux\": {\n",
    "        # Unix-like operating system\n",
    "        're': r\"\\blinux\\b\",\n",
    "        'label': \"Linux\"\n",
    "    },\n",
    "    \"git_github\": {\n",
    "        # Git is a version control system that lets you manage and keep track of your source code history;\n",
    "        # GitHub is a cloud-based hosting service that lets you manage Git repositories.\n",
    "        're': r\"\\bgit|github\\b\",\n",
    "        'label': \"Git/GitHub\"\n",
    "    },\n",
    "    \"anaconda\": {\n",
    "        # Anaconda is a distribution of the Python and R programming languages for scientific computing\n",
    "        # (data science, machine learning applications, large-scale data processing, predictive analytics, etc.),\n",
    "        # that aims to simplify package management and deployment.\n",
    "        're': r\"\\banaconda\\b\",\n",
    "        'label': \"Anaconda\"\n",
    "    },\n",
    "    \"d3js\": {\n",
    "        # a JavaScript library for visualizing data with HTML, SVG, and CSS\n",
    "        're': r\"\\bd3\\.?js\\b\",\n",
    "        'label': \"D3.js\"\n",
    "    },\n",
    "    \"jira\": {\n",
    "        # software used for bug tracking, issue tracking, and project management\n",
    "        're': r\"\\bjira\\b\",\n",
    "        'label': \"Jira\"\n",
    "    },\n",
    "    \"java\": {\n",
    "        # programming language\n",
    "        're': r\"\\bjava\\b\",\n",
    "        'label': \"Java\"\n",
    "    },\n",
    "    \"javascript\": {\n",
    "        # programming language\n",
    "        're': r\"\\bjavascript\\b\",\n",
    "        'label': \"JavaScript\"\n",
    "    },\n",
    "    \"nodejs\": {\n",
    "        # cross-platform, back-end JavaScript runtime environment that executes JavaScript code outside a web browser.\n",
    "        're': r\"\\bnode\\.js\\b\",\n",
    "        'label': \"Node.js\"\n",
    "    },\n",
    "    \"c++_c#\": {\n",
    "        # programming languages\n",
    "        're': r\"\\bc\\b|\\bc\\+{2}\\b|\\bc\\#\\b\",\n",
    "        'label': \"C++/C#\"\n",
    "    },\n",
    "    \"docker\": {\n",
    "        # Docker is a set of products that use OS-level virtualization to deliver software in packages called containers,\n",
    "        # removing the issue of dependencies\n",
    "        're': r\"\\bdocker\\w*?\\b\",\n",
    "        'label': \"Docker\"\n",
    "    },\n",
    "    \"kubernetes\": {\n",
    "        # Container-orchestration system for automating computer application deployment, scaling, and management\n",
    "        're': r\"\\bkubernetes\\b\",\n",
    "        'label': \"Kubernetes\"\n",
    "    },\n",
    "    \"google_cloud\": {\n",
    "        # a suite of cloud computing services\n",
    "        're': r\"\\bgoogle cloud\\b|\\bgcp\\b\",\n",
    "        'label': \"Google Cloud Platform (GCP)\"\n",
    "    },\n",
    "    \"aws\": {\n",
    "        # a suite of cloud computing services\n",
    "        're': r\"\\baws\\b\",\n",
    "        'label': \"Amazon Web Services (AWS)\"\n",
    "    },\n",
    "    \"azure\": {\n",
    "        # a suite of cloud computing services\n",
    "        're': r\"\\bazure\\b\",\n",
    "        'label': \"Microsoft Azure\"\n",
    "    },\n",
    "    \"kafka\": {\n",
    "        # a stream-processing software platform for handling real-time data feeds, which can connect to external systems (for data import/export)\n",
    "        're': r\"\\bkafka\\b\",\n",
    "        'label': \"Kafka\"\n",
    "    },\n",
    "    \"kinesis\": {\n",
    "        # a cloud-based service that allows real-time processing of data streaming large amount of data\n",
    "        're': r\"\\bkinesis\\b\",\n",
    "        'label': \"Kinesis\"\n",
    "    },\n",
    "    \"spark\": {\n",
    "        # general-purpose cluster-computing framework\n",
    "        're': r\"\\bspark\\b\",\n",
    "        'label': \"Spark\"\n",
    "    },\n",
    "    \"elasticsearch\": {\n",
    "        # Elasticsearch takes unstructured data from different locations, stores and indexes it according to user-specified mapping\n",
    "        # (or automatically from data) and makes it searchable.\n",
    "        're': r\"\\belasticsearch\\b\",\n",
    "        'label': \"Elasticsearch\"\n",
    "    },\n",
    "    \"sql\": {\n",
    "        # a domain-specific language used in programming and designed for managing data held in a relational database management system\n",
    "        're': r\"\\bsql\\b\",\n",
    "        'label': \"Structured Query Language (SQL)\"\n",
    "    },\n",
    "    \"redshift\": {\n",
    "        #  a cloud-based, big data warehouse product; can be used for real-time analytics\n",
    "        're': r\"\\bredshift\\b\",\n",
    "        'label': \"Redshift\"\n",
    "    },\n",
    "    \"looker\": {\n",
    "        # a browser-based data analytics platform for collection, visualization and analysis\n",
    "        're': r\"\\blooker\\b\",\n",
    "        'label': \"Looker\"\n",
    "    },\n",
    "    \"bigquery\": {\n",
    "        # A serverless cloud storage platform for large data sets,\n",
    "        # which allows you to run complex analytical SQL-based queries under large sets of data\n",
    "        're': r\"\\bbigquery\\b\",\n",
    "        'label': \"BigQuery\"\n",
    "    },\n",
    "    \"hive\": {\n",
    "        # A data warehouse software that allows users to read, write, and manage petabytes of data using SQL.\n",
    "        # Hive is built on top of Hadoop\n",
    "        're': r\"\\bhive\\b\",\n",
    "        'label': \"Apache Hive\"\n",
    "    },\n",
    "    \"excel\": {\n",
    "        # A program that allows users to organize, format and calculate data with formulas using a spreadsheet system\n",
    "        're': r\"\\bexcel\\b\",\n",
    "        'label': \"Excel\"\n",
    "    },\n",
    "    \"power_bi\": {\n",
    "        # Power BI is a business analytics service by Microsoft for interactive visualizations and business intelligence\n",
    "        # capabilities with an interface simple enough for end users to create their own reports and dashboards.\n",
    "        're': r\"\\bpower bi\\b\",\n",
    "        'label': \"Power BI\"\n",
    "    },\n",
    "    \"snowflake\": {\n",
    "        # Snowflake is a full SQL data warehouse built for the cloud (on top of the AWS or Azure)\n",
    "        're': r\"\\bsnowflake\\b\",\n",
    "        'label': \"Snowflake\"\n",
    "    },\n",
    "    \"tableau\": {\n",
    "        # an interactive data visualization software\n",
    "        're': r\"\\btableau\\b\",\n",
    "        'label': \"Tableau\"\n",
    "    },\n",
    "    \"vertica\": {\n",
    "        # a data analytics platform\n",
    "        're': r\"\\bvertica\\b\",\n",
    "        'label': \"Vertica\"\n",
    "    },\n",
    "    \"grafana\": {\n",
    "        # a multi-platform open source analytics and interactive visualization web application.\n",
    "        're': r\"\\bgrafana\\b\",\n",
    "        'label': \"Grafana\"\n",
    "    },\n",
    "    \"lubridate\": {\n",
    "        # R library used for data wrangling, good for date-time data\n",
    "        're': r\"\\blubridate\\b\",\n",
    "        'label': \"Lubridate\"\n",
    "    },\n",
    "    \"tidyverse\": {\n",
    "        # R data science packages\n",
    "        're': r\"\\btidyverse\\b\",\n",
    "        'label': \"Tidyverse\"\n",
    "    },\n",
    "    \"dplyr\": {\n",
    "        # R package to manipulate, clean and summarize unstructured data\n",
    "        're': r\"\\bdplyr\\b\",\n",
    "        'label': \"dplyr\"\n",
    "    },\n",
    "    \"ggplot2\": {\n",
    "        # library for data visualization in R\n",
    "        're': r\"\\bggplot2\\b\",\n",
    "        'label': \"ggplot2\"\n",
    "    },\n",
    "    \"esquisse\": {\n",
    "        # R ggplot2 addin that allows you to interactively explore your data by visualizing it with the ggplot2 package,\n",
    "        # then export the graph or retrieve the code generating the graph\n",
    "        're': r\"\\besquisse\\b\",\n",
    "        'label': \"esquisse\"\n",
    "    },\n",
    "    \"shiny\": {\n",
    "        # R package  to build interactive web apps\n",
    "        're': r\"\\bshiny\\b\",\n",
    "        'label': \"Shiny\"\n",
    "    },\n",
    "    \"bioconductor\": {\n",
    "        # software for bioinformatics\n",
    "        're': r\"\\bbioconductor\\b\",\n",
    "        'label': \"Bioconductor\"\n",
    "    },\n",
    "    \"knitr\": {\n",
    "        # R package for dynamic report generation\n",
    "        're': r\"\\bknitr\\b\",\n",
    "        'label': \"knitr\"\n",
    "    },\n",
    "    \"rmarkdown\": {\n",
    "        # R package for dynamic report generation\n",
    "        're': r\"\\brmarkdown\\b\",\n",
    "        'label': \"RMarkdown\"\n",
    "    },\n",
    "    \"quanteda\": {\n",
    "        # R package for managing and analyzing text\n",
    "        're': r\"\\bquanteda\\b\",\n",
    "        'label': \"quanteda\"\n",
    "    },\n",
    "    \"rcrawler\": {\n",
    "        # R package for domain-based web crawling and content scraping\n",
    "        're': r\"\\brcrawler\\b\",\n",
    "        'label': \"RCrawler\"\n",
    "    },\n",
    "    \"caret\": {\n",
    "        # R package for model building and evaluation, e.g. data splitting, pre-processing, feature selection, variable importance estimation etc.\n",
    "        're': r\"\\bcaret\\b\",\n",
    "        'label': \"Caret\"\n",
    "    },\n",
    "    \"mlr\": {\n",
    "        # R package and framework for ML\n",
    "        're': r\"\\bmlr\\b\",\n",
    "        'label': \"mlr\"\n",
    "    },\n",
    "    \"oracle\": {\n",
    "        # cloud computing infrastructure\n",
    "        're': r\"\\boracle\\b\",\n",
    "        'label': \"Oracle\"\n",
    "    },\n",
    "    \"numpy\": {\n",
    "        # python library adding support for large, multi-dimensional arrays and matrices,\n",
    "        # along with a large collection of high-level mathematical functions to operate on them\n",
    "        're': r\"\\bnumpy\\b\",\n",
    "        'label': \"NumPy\"\n",
    "    },\n",
    "    \"scipy\": {\n",
    "        # python library used for scientific computing and technical computing, with modules for optimization,\n",
    "        # linear algebra, integration, interpolation, special functions, FFT, signal and image processing,\n",
    "        # ODE solvers and other tasks common in science and engineering.\n",
    "        're': r\"\\bscipy\\b\",\n",
    "        'label': \"SciPy\"\n",
    "    },\n",
    "    \"pandas\": {\n",
    "        # python library for data manipulation and analysis in python, offering data structures and operations\n",
    "        # for manipulating numerical tables and time series.\n",
    "        're': r\"\\bpandas\\b\",\n",
    "        'label': \"pandas\"\n",
    "    },\n",
    "    \"matplotlib\": {\n",
    "        # python ibrary for creating static, animated, and interactive visualizations in Python, based on NumPy\n",
    "        're': r\"\\bmatplotlib\\b\",\n",
    "        'label': \"matplotlib\"\n",
    "    },\n",
    "    \"bokeh\": {\n",
    "        # python library used to make interactive plots, dashboards, and data applications for modern web browsers/notebooks\n",
    "        're': r\"\\bbokeh\\b\",\n",
    "        'label': \"Bokeh\"\n",
    "    },\n",
    "    \"sklearn\": {\n",
    "        # python ML library, used for classification, regression clustering, SVM, random forests,\n",
    "        # gradient boosting, k-means and DBSCAN; designed to work with NumPy and SciPy.\n",
    "        're': r\"\\bscikit\\-learn\\b|\\bsklearn\\b\",\n",
    "        'label': \"scikit-learn\"\n",
    "    },\n",
    "    \"pytorch\": {\n",
    "        # python ML library based on the Torch library, uses include computer vision and NLP\n",
    "        're': r\"\\bpytorch\\b\",\n",
    "        'label': \"PyTorch\"\n",
    "    },\n",
    "    \"pyspark\": {\n",
    "        # python API written to support Apache Spark\n",
    "        're': r\"\\bpyspark\\b\",\n",
    "        'label': \"PySpark\"\n",
    "    },\n",
    "    \"sparkml\": {\n",
    "        # Spark MLlib is a distributed ML framework on top of Spark Core\n",
    "        're': r\"\\bspark[\\.\\s]?ml\",\n",
    "        'label': \"Spark ML\"\n",
    "    },\n",
    "    \"tensorflow\": {\n",
    "        # library for ML with a particular focus on training and interference of deep neural networks\n",
    "        're': r\"\\btensorflow\\b\",\n",
    "        'label': \"TensorFlow\"\n",
    "    },\n",
    "    \"spacy\": {\n",
    "        # Library for advanced NLP\n",
    "        're': r\"\\bspacy\\b\",\n",
    "        'label': \"spaCy\"\n",
    "    },\n",
    "    \"keras\": {\n",
    "        # Library providing Python interface for artificial neural networks.\n",
    "        're': r\"\\bkeras\\b\",\n",
    "        'label': \"Keras\"\n",
    "    },\n",
    "    \"databricks\": {\n",
    "        # Data analytics/ data lake platform optimized for Azure\n",
    "        're': r\"\\bdatabricks\\b\",\n",
    "        'label': \"Databricks\"\n",
    "    },\n",
    "    \"mongodb\": {\n",
    "        # Cross-platform document-oriented NoSQL database program.\n",
    "        're': r\"\\bmongodb\\b\",\n",
    "        'label': \"MongoDB\"\n",
    "    },\n",
    "    \"hadoop\": {\n",
    "        # A software framework for distributed storage and processing of big data\n",
    "        're': r\"\\bhadoop\\b\",\n",
    "        'label': \"Hadoop\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON\n",
      "\n",
      "*** Pattern = '\\bpython\\b' ***\n",
      "\n",
      "[1] nsultant with solid experience in programming (R, Python) and machine learning/AI methodologies.\n",
      "Job Overv\n",
      "\n",
      "[2] \n",
      "\n",
      "[4] \n",
      "advanced programming expertise in two or more of Python, Java and SQL\n",
      "experience conducting analysis on l\n",
      "\n",
      "[5] Data Scientist\n",
      "Proficiency in SQL experience with Python or R\n",
      "Experience with Big Data systems such as; Hi\n",
      "\n",
      "[6] er reporting suites, advance knowledge in R, SQL, Python and excel, Intermediate to advance level in Stati\n",
      "\n",
      "[7] d experience with programming languages like SQL, Python, Scala or similar\n",
      "Your understanding and your exp\n",
      "\n",
      "[8] d quantitative skills.\n",
      "Strong programming skills (Python, SQL, Matlab, Java, C++, and R)\n",
      "Knowledge of: too\n",
      "\n",
      "[9] ng model development\n",
      "• Strong proficiency in both Python & SQL\n",
      "• Outcome/impact focussed\n",
      "• Naturally curio\n",
      "\n",
      "[10] th a minimum of 2+ years’ experience working with Python, R , SQL and common data science tool kits is req\n",
      "\n",
      "[13] xperiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools\n",
      "Manage \n",
      "\n",
      "[16] \n",
      "Requirements\n",
      "You feel comfortable programming in Python, and you've worked on a codebase of more than a t\n",
      "\n",
      "[17] Physics, Engineering, etc.)\n",
      "Advanced knowledge of Python, in particular packages such as Pandas, Numpy, Sc\n",
      "\n",
      "[19] e with the above and are well adept to the use of Python and SQL, submit your application for review and f\n",
      "\n",
      "[20] achine learning, and statistical tools\n",
      "Manipulate Python and R to improve mathematical analysis\n",
      "Report res\n",
      "\n",
      "[21] g environment\n",
      "Strong coding skills, preferably in Python\n",
      "\n",
      "[22]  on high volumes of data\n",
      "Use Hive, Scala, Java or Python to utilize Hadoop/Spark to process large-scale da\n",
      "\n",
      "[23]  Senior Data Scientist you will be:\n",
      "Using SQL and Python to extract a wide range of data to understand cus\n",
      "\n",
      "[25] s’ key business questions. Products are typically Python notebooks or scripts, potentially deployed in Dat\n",
      "\n",
      "[26] g (Deep Learning would be advantageous)\n",
      "Expert in Python\n",
      "Genomics transcription data, building predictive \n",
      "\n",
      "[28] ntervals).?\n",
      "Do you have experience in programming Python/R and SQL?\n",
      "Do you have the technical understandin\n",
      "\n",
      "R\n",
      "\n",
      "*** Pattern = '\\br(?!&)\\b|\\brstudio\\b' ***\n",
      "\n",
      "[2] assessment.\n",
      "+ Ability to use SQL is essential and R/Python an advantage.\n",
      "+ Experience in tools such a\n",
      "\n",
      "[3] cell and other ‘omics technologies\n",
      "Writing Python/R code to a professional standard\n",
      "Experience workin\n",
      "\n",
      "[4] ence with typical Data Science languages (Python, R) with project experience manipulating large datas\n",
      "\n",
      "[5] ne learning and predictive modeling (e.g. Python, R, C/C++), and competent working in multiple comput\n",
      "\n",
      "[7] develop pricing strategies using either Python or R\n",
      "Presenting key insights to stakeholders\n",
      "Relations\n",
      "\n",
      "[9] chine learning solutions\n",
      "Experienced in Python or R\n",
      "Leadership Qualities - How to manage people withi\n",
      "\n",
      "[10] al skills in analytical languages such as Python, R, SQL, SAS. Specific knowledge of Spark and/or gra\n",
      "\n",
      "[14] guage processing (NLP) - strong experience\n",
      "Python\n",
      "R\n",
      "SQL\n",
      "Enjoys the idea of remaining hands on but als\n",
      "\n",
      "[16] imilar field\n",
      "Programming skills (Python, Pyspark, R, SQL)\n",
      "Logical thinking and approach to problem so\n",
      "\n",
      "[21] ogramming skills in statistical languages such as R and SAS\n",
      "Wider programming skills, for example in \n",
      "\n",
      "[23]  business insights. Experience/Certification with R, Python or other analytic tools is essential, as \n",
      "\n",
      "[24] th analytical programming languages (e.g. Python, R, SQL) or other machine learning, statistical or m\n",
      "\n",
      "[28] rience with common data science toolkits (such as R, Python, NumPy, MatLab, Tensorflow, keras, etc.)\n",
      "\n",
      "\n",
      "[30] Experience using data and modelling tools such as R, Python, SAS, and SQL\n",
      "Excellent communication ski\n",
      "\n",
      "[32]  learn more\n",
      "Expertise in technologies like Python/R, SQL, Big Query, and the drive to learn more\n",
      "A MS\n",
      "\n",
      "[35] you on the journey\n",
      "Comprehensive proficiency with R/Python toolkits, preferably working with data pip\n",
      "\n",
      "[36]  consultant with solid experience in programming (R, Python) and machine learning/AI methodologies.\n",
      "J\n",
      "\n",
      "[37] , e.g. Mixpanel, Amplitude\n",
      "Excellent knowledge of R, Python and SQL.\n",
      "Excellent analytical and project\n",
      "\n",
      "[38] und with data science and statistical analysis in R or Python.\n",
      "Strong data management skills includin\n",
      "\n",
      "[39] \n",
      "Using statistical computer languages (python and R) to manipulate data and draw insights from large \n",
      "\n",
      "SCALA\n",
      "\n",
      "*** Pattern = '\\bscala\\b' ***\n",
      "\n",
      "[1] s\n",
      "Demonstrated experience using Spark, Python, R, Scala, or similar tools for data analysis, structuring,\n",
      "\n",
      "[19] dable code (we use Python and Java at present but Scala, R and others are by no means excluded);\n",
      "Are comf\n",
      "\n",
      "[28] nguages such as PySpark/Databricks, Python, R, or Scala, cloud, Jupyter, or git.\n",
      "Are you a Senior Data Sc\n",
      "\n",
      "[54]  purpose programming language (preferably Python, Scala or C).\n",
      "Experience in using programming languages \n",
      "\n",
      "[57]  Matplotlib (or equivalent). Knowledge of PySpark/Scala is a bonus\n",
      "Practical understanding of SQL and NoS\n",
      "\n",
      "[58] oduction grade python code\n",
      "Experience with spark (scala or python) for ETLs and model development\n",
      "Experie\n",
      "\n",
      "[64] , time series).\n",
      "Experience of Python (essential), Scala/Java (desirable)\n",
      "Experience working with big data\n",
      "\n",
      "[90] ce\n",
      "Great programming skills in Python, R, Java or Scala\n",
      "Very good communicative skills\n",
      "Ability to work we\n",
      "\n",
      "[98]  Matplotlib (or equivalent). Knowledge of PySpark/Scala is a bonus\n",
      "Practical understanding of SQL and NoS\n",
      "\n",
      "MATLAB\n",
      "\n",
      "*** Pattern = '\\bmatlab\\b' ***\n",
      "\n",
      "[67] thon.Experience in other languages e.g. R, Scala, Matlab will also be considered.\n",
      "\n",
      "= Knowledgeof common li\n",
      "\n",
      "[72] application using statistical languages such as R/Matlab/SAS/SQL/Hadoop/Python\n",
      "Experience in advanced visu\n",
      "\n",
      "SAS\n",
      "\n",
      "*** Pattern = '\\bsas\\b' ***\n",
      "\n",
      "[3] c.) or statistical/mathematical software (e.g. R, SAS, or Matlab)\n",
      "· Master's degree in Computer Science\n",
      "\n",
      "[18] tion using statistical languages such as R/Matlab/SAS/SQL/Hadoop/Python\n",
      "Experience in advanced visualis\n",
      "\n",
      "[25] using data and modelling tools such as R, Python, SAS, and SQL\n",
      "Excellent communication skills for both \n",
      "\n",
      "[29] analysis and modelling using standard tools (e.g. SAS, R, Matlab, Scala);\n",
      "Data analysis and modelling u\n",
      "\n",
      "[66] nsorFlow\n",
      "Strong coding skills in R, Python and/or SAS\n",
      "Experience with Spark, Hive or Impala\n",
      "Passion for\n",
      "\n",
      "[70] tools such as R or Python during your studies (or SAS, SPSS, MATLAB), they are more interested in recru\n",
      "\n",
      "[77] ing skills in statistical languages such as R and SAS\n",
      "Wider programming skills, for example in Python, \n",
      "\n",
      "SPSS\n",
      "\n",
      "*** Pattern = '\\bspss\\b' ***\n",
      "\n",
      "STATA\n",
      "\n",
      "*** Pattern = '\\bstata\\b' ***\n",
      "\n",
      "[47] parkR, R, Python, Scala, Hive, SQL, SPSS, Hadoop, Stata, Google Analytics, Azure\n",
      "Why you want to work her\n",
      "\n",
      "PERL\n",
      "\n",
      "*** Pattern = '\\bperl\\b' ***\n",
      "\n",
      "[40] e, efficient code\n",
      "Experience of C or C++ or Java, Perl, Matlab, R is also beneficial\n",
      "Experience of devel\n",
      "\n",
      "UNIX\n",
      "\n",
      "*** Pattern = '\\bunix\\b' ***\n",
      "\n",
      "[10] s are by no means excluded);\n",
      "Are comfortable in a Unix environment (Mac and Linux, basically); and\n",
      "Are d\n",
      "\n",
      "[13] d Kibana\n",
      "Agile Methodology\n",
      "Git, Jira, Confluence, UNIX\n",
      "PhD or MSc in Mathematics, Computer Science, Engi\n",
      "\n",
      "LINUX\n",
      "\n",
      "*** Pattern = '\\blinux\\b' ***\n",
      "\n",
      "[18] sion Control such as git\n",
      "Comfortable working in a Linux/Mac development environment\n",
      "Training & Career dev\n",
      "\n",
      "[79] s: Python / PySpark / SQL\n",
      "Working experience with Linux OS ( Redhat / Ubuntu ).\n",
      "Excellent English (speaki\n",
      "\n",
      "[80] taining a substantial numerical component.\n",
      "Use of Linux/Unix environment and associated development toolc\n",
      "\n",
      "[84] e Cloud Services, or equivalent).\n",
      "Experience with Linux operating systems for developing data science app\n",
      "\n",
      "[87] );\n",
      "Are comfortable in a Unix environment (Mac and Linux, basically); and\n",
      "Are degree qualified in a subjec\n",
      "\n",
      "GIT_GITHUB\n",
      "\n",
      "*** Pattern = '\\bgit|github\\b' ***\n",
      "\n",
      "[12] skills in DataViz/Data Analytics\n",
      "Experience using GitHub\n",
      "Understanding of Cloud Computing Environments \n",
      "\n",
      "[18] itywith Linux and common software tools including Git, Jupyter, and Docker.\n",
      "\n",
      "= Experienceof working wit\n",
      "\n",
      "[30] l services industry experience\n",
      "DevOps experience (Git, CI etc)\n",
      "Cloud fundamental or architect accredita\n",
      "\n",
      "[41] ield service management systems, CRM, etc. We use GitHub, travis-ci, code-pipeline and cloudformation a\n",
      "\n",
      "[85] mand-line environment\n",
      "Demonstratable knowledge of Git version control\n",
      "Experience working with container\n",
      "\n",
      "[88] ftware development and data science tools such as Github, Jira, Anaconda, D3JS, Grafana.\n",
      "You should be\n",
      "\n",
      "\n",
      "ANACONDA\n",
      "\n",
      "*** Pattern = '\\banaconda\\b' ***\n",
      "\n",
      "[73] ment and data science tools such as Github, Jira, Anaconda, D3JS, Grafana.\n",
      "You should be\n",
      "A person who likes \n",
      "\n",
      "D3JS\n",
      "\n",
      "*** Pattern = '\\bd3\\.?js\\b' ***\n",
      "\n",
      "[60] ata science tools such as Github, Jira, Anaconda, D3JS, Grafana.\n",
      "You should be\n",
      "A person who likes to wor\n",
      "\n",
      "JIRA\n",
      "\n",
      "*** Pattern = '\\bjira\\b' ***\n",
      "\n",
      "[29] \n",
      "Experience working with the Atlassian toolchain (Jira, Bitbucket, Confluence)\n",
      "Experience working in an \n",
      "\n",
      "[30] ment and related tools such as Microsoft Project, JIRA, DevOps etc.;\n",
      "Relational databases, e.g. SQL Serv\n",
      "\n",
      "[66] evelopment and data science tools such as Github, Jira, Anaconda, D3JS, Grafana.\n",
      "You should be\n",
      "A person \n",
      "\n",
      "[90] earch, LogStash and Kibana\n",
      "Agile Methodology\n",
      "Git, Jira, Confluence, UNIX\n",
      "PhD or MSc in Mathematics, Comp\n",
      "\n",
      "JAVA\n",
      "\n",
      "*** Pattern = '\\bjava\\b' ***\n",
      "\n",
      "[1] ale well on high volumes of data\n",
      "Use Hive, Scala, Java or Python to utilize Hadoop/Spark to process larg\n",
      "\n",
      "[12] nce projects.\n",
      "Programming languages (e.g. Python, Java, R, SPARK, SQL, etc.) and software development sk\n",
      "\n",
      "[16] and have some experience in implementation (Scala/Java).\n",
      "Having a working knowledge of Big Data technolo\n",
      "\n",
      "[17] eadable, efficient code\n",
      "Experience of C or C++ or Java, Perl, Matlab, R is also beneficial\n",
      "Experience of\n",
      "\n",
      "[23] her regulatory areas.\n",
      "Programming experience in C/Java/Scala.\n",
      "Experience with reinforcement and/or deep \n",
      "\n",
      "[37] ility including fluency in two or more of Python, Java (or equivalent), and SQL.\n",
      "Experience conducting a\n",
      "\n",
      "[46] rred\n",
      "Essential:\n",
      "Fluency in two or more of Python, Java (or equivalent), and SQL.\n",
      "Experience conducting a\n",
      "\n",
      "[57] ility including fluency in two or more of Python, Java (or equivalent), and SQL.\n",
      "Experience conducting a\n",
      "\n",
      "[89] ounding in one of our core languages is required: Java, Python, C, C#, C++, R, Matlab.\n",
      "Excellent interpe\n",
      "\n",
      "[95] hnologies is always up for discussion. Python and Java are heavily used all throughout the platform, but\n",
      "\n",
      "[100]  programming experience in Python, R, potentially Java, C++\n",
      "Experience using relational databases in SQL\n",
      "\n",
      "JAVASCRIPT\n",
      "\n",
      "*** Pattern = '\\bjavascript\\b' ***\n",
      "\n",
      "[48] across other programming languages such as R, C#, JavaScript\n",
      "Experience in design and implementation of end-to\n",
      "\n",
      "[57]  Web development with using ReactJS, D3, or other JavaScript frameworks\n",
      "Experience with using ESRI tools to vi\n",
      "\n",
      "NODEJS\n",
      "\n",
      "*** Pattern = '\\bnode\\.js\\b' ***\n",
      "\n",
      "[55] e with R programming language, C++, Python, Java, Node.JS\n",
      "\n",
      "Additional Information\n",
      "Highly analytical with a \n",
      "\n",
      "C++_C#\n",
      "\n",
      "*** Pattern = '\\bc\\b|\\bc\\+{2}\\b|\\bc\\#\\b' ***\n",
      "\n",
      "[12] company.\n",
      "2 days per week Working From Home (Given C-19, once appropriate)\n",
      "Great teams need to co-loca\n",
      "\n",
      "[19] vant field\n",
      "Experiece with R programming language, C++, Python, Java, Node.JS\n",
      "\n",
      "Additional Information\n",
      "\n",
      "\n",
      "[43] revious role) of coding in languages like Python, C# or Java – you will fit right in.\n",
      "What you will g\n",
      "\n",
      "[48] \n",
      "\n",
      "[53] \n",
      "Wider programming skills, for example in Python, C, C ++, Java\n",
      "Advanced SQL and data manipulation sk\n",
      "\n",
      "[59] st models ideally in Fintech with a Consumer B to C business\n",
      "Strong skills in Excel\n",
      "Strong skills in \n",
      "\n",
      "[63] ience would be beneficial)\n",
      "Hands-on experience in C#/Java/Groovy, Python, Anaconda, PyCharm, Spark, F\n",
      "\n",
      "[64] irable programming languages: Powershell, Python, C#\n",
      "Data serialisation language: JSON, YAML\n",
      "Containe\n",
      "\n",
      "[65] undaries, etc.\n",
      "Programming\n",
      "Python, and one of the C family languages such as Java, C++, C#, etc.\n",
      "OOP \n",
      "\n",
      "[96] h other team leads, academic research partners or C-Suite stakeholders.\n",
      "\n",
      "My client for this Lead Data\n",
      "\n",
      "[99] programming language (preferably Python, Scala or C).\n",
      "Experience in using programming languages to ma\n",
      "\n",
      "DOCKER\n",
      "\n",
      "*** Pattern = '\\bdocker\\w*?\\b' ***\n",
      "\n",
      "[14] ata experience (e.g. Spark, Hadoop, Kafka, Flink, Docker, Kubernetes, NoSQL DB)\n",
      "Experience with deep learn\n",
      "\n",
      "[21] ibuted processing technologies e.g. Apache Spark, Docker, Hadoop, Flink\n",
      "The position is initially a 12 mon\n",
      "\n",
      "[24] e, micro-services and containerisation (including Docker and Kubernetes) etc.\n",
      "Also, we’d love it if you ha\n",
      "\n",
      "[31] , PyTorch etc.) and SQL\n",
      "Working knowledge of Git, Docker, CI/CD, REST API\n",
      "Ability to work under pressure a\n",
      "\n",
      "[38] ther team members\n",
      "\n",
      "Nice to haves:\n",
      "\n",
      "· Knowledge of Docker and/or SpaCy\n",
      "\n",
      "We value intelligence, creativity a\n",
      "\n",
      "[45] rol\n",
      "Experience working with containerisation e.g. Docker\n",
      "In addition to the above, the following skills/ex\n",
      "\n",
      "[52] common software tools including Git, Jupyter, and Docker.\n",
      "\n",
      "= Experienceof working with data in a regulated\n",
      "\n",
      "[55] anguage: JSON, YAML\n",
      "Containerisation: Kubernetes, Docker\n",
      "Security : Azure Active Directory and integration\n",
      "\n",
      "[61]  Python is a must\n",
      "Knowledge of Spark, Kafka, AWS, Docker, Kubernetes is desirable\n",
      "A strong knowledge of st\n",
      "\n",
      "[86] s.\n",
      "Ideally, you would have worked with VMs and/or Docker.\n",
      "Experience with Agile technologies (JIRA) and ve\n",
      "\n",
      "KUBERNETES\n",
      "\n",
      "*** Pattern = '\\bkubernetes\\b' ***\n",
      "\n",
      "[6] rvices and containerisation (including Docker and Kubernetes) etc.\n",
      "For the Lead Data Scientist role, an MSc or\n",
      "\n",
      "[19] data to work with\n",
      "Work with Python, PySpark, AWS, Kubernetes\n",
      "Have a passion for deploying robust and scalable \n",
      "\n",
      "[32] nding of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is esse\n",
      "\n",
      "[91] ialisation language: JSON, YAML\n",
      "Containerisation: Kubernetes, Docker\n",
      "Security : Azure Active Directory and int\n",
      "\n",
      "GOOGLE_CLOUD\n",
      "\n",
      "*** Pattern = '\\bgoogle cloud\\b|\\bgcp\\b' ***\n",
      "\n",
      "[7] ext analytics\n",
      "– Big data\n",
      "– Cloud Technologies AWS/GCP\n",
      "– Structured query language (SQL)\n",
      "Join REED – Imp\n",
      "\n",
      "[17] perience of working in cloud environments (Azure, GCP, AWS etc)\n",
      "Experience with data visualisation tool\n",
      "\n",
      "[19] olumes\n",
      "Knowledge of cloud technology stacks (AWS, GCP, Azure) and data visualization tools and applicat\n",
      "\n",
      "[26] in the cloud would be ideal such as Azure, AWS or GCP for example although not essential\n",
      "They are activ\n",
      "\n",
      "[32] g on the cloud infrastructure, a familiarity with GCP.\n",
      "Understanding of Machine Learning models and con\n",
      "\n",
      "[34] applicants to have prior experience of all them):\n",
      "Google Cloud Platform for all of our analytics infrastructure\n",
      "\n",
      "\n",
      "[50] nd data engineers excited to use state of the art Google Cloud technology and the most advanced Machine Learning\n",
      "\n",
      "[51] ructure. All our data infrastructure lives on the Google Cloud Platform, so you don't need to spend your time co\n",
      "\n",
      "[64] ve:\n",
      "Experience with cloud infrastructure (such as GCP or AWS)\n",
      "Knowledge of TensorFlow\n",
      "Skills and attrib\n",
      "\n",
      "[68]  and services.\n",
      "Knowledge of cloud platforms (AWS, GCP, AZURE)\n",
      "It is important that you are passionate a\n",
      "\n",
      "[92] in the cloud would be ideal such as Azure, AWS or GCP for example, along with experience on Machine Lea\n",
      "\n",
      "[94] truly mind-blowing. Ideally, you will have AWS or GCP experience but if you are strong in other areas a\n",
      "\n",
      "AWS\n",
      "\n",
      "*** Pattern = '\\baws\\b' ***\n",
      "\n",
      "[1] nce of working in cloud environments (Azure, GCP, AWS etc)\n",
      "Experience with data visualisation tools (Ta\n",
      "\n",
      "[5] lic cloud environments (e.g. Google GCP or Amazon AWS)\n",
      "Education: Masters or PhD level qualification in\n",
      "\n",
      "[7] \n",
      "\n",
      "Cloud: Delivering within cloud services (Azure, AWS or Google Cloud) – we use Azure.\n",
      "\n",
      "[1] https://www\n",
      "\n",
      "[12] and understanding of the Cloud Environments (GCP, AWS, Azure)\n",
      "Ability to program in Python and SQL\n",
      "Plea\n",
      "\n",
      "[16] erience with cloud infrastructure (such as GCP or AWS)\n",
      "Sound knowledge of statistics\n",
      "\n",
      "If you feel you h\n",
      "\n",
      "[20] for data science\n",
      "Go to write our application code\n",
      "AWS for most of our backend infrastructure\n",
      "The role\n",
      "W\n",
      "\n",
      "[25] eering in the cloud would be ideal such as Azure, AWS or GCP for example, along with experience on Mach\n",
      "\n",
      "[26] This data is stored, analysed and labelled on the AWS cloud. Various integrations push the analysis res\n",
      "\n",
      "[30] ces, Google Cloud Platform (especially BigQuery), AWS, etc\n",
      "Experience or keen interest in learning Pyth\n",
      "\n",
      "[32]  of working withcloud technologies such as GCP or AWS, as well as versioning tools such as Gitand Docke\n",
      "\n",
      "[35] ce.\n",
      "\n",
      "= Experiencewith modern cloud services, e.g. AWS services EC2, RDS, Redshift, S3, Glue,SageMaker, \n",
      "\n",
      "[39] ploying machine learning to Cloud platforms (e.g. AWS, Azure)\n",
      "adversarial learning\n",
      "data engineering\n",
      "sup\n",
      "\n",
      "[44] hnologies (Hadoop / Spark / NoSQL DBs) and Cloud (AWS and Azure) is a bonus.\n",
      "Exceptional attention to d\n",
      "\n",
      "[48] w insights from large data sets.\n",
      "Experience using AWS (S3, Redshift, CloudWatch, DynamoDB)\n",
      "Experience w\n",
      "\n",
      "[63] ience with big data technologies such as Spark or AWS; are able to write efficient SQL; and are profici\n",
      "\n",
      "[75] for data science\n",
      "Go to write our application code\n",
      "AWS for most of our backend infrastructure\n",
      "The role\n",
      "W\n",
      "\n",
      "[76] n ecommerce, consulting or similar\n",
      "strong Python, AWS and SQL experience, including manipulating large \n",
      "\n",
      "[80] ploying machine learning to Cloud platforms (e.g. AWS, Azure)\n",
      "taking a project from an initial concept \n",
      "\n",
      "[81] .\n",
      "Familiarity with cloud based computing systems (AWS, PythonAnywhere, Google Cloud Services, or equiva\n",
      "\n",
      "[85] orking with Big Data platforms, including Hadoop, AWS, Azure, or DataBricks\n",
      "Experience with data cleani\n",
      "\n",
      "AZURE\n",
      "\n",
      "*** Pattern = '\\bazure\\b' ***\n",
      "\n",
      "[5] visualization tools, and cloud environments e.g., Azure, Power BI, SQL server, SAS visual analytics, Spot\n",
      "\n",
      "[18] nderstanding of the Cloud Environments (GCP, AWS, Azure)\n",
      "Ability to program in Python and SQL\n",
      "Please appl\n",
      "\n",
      "[20] Experience deploying machine learning models into Azure or another cloud environment.\n",
      "Experience in conti\n",
      "\n",
      "[25] nus:\n",
      "Experience working in the financial industry\n",
      "Azure\n",
      "Engine development\n",
      "Data design/modelling\n",
      "Data ins\n",
      "\n",
      "[66] experience of working with cloud services such as Azure, web technologies and local IT infrastructure and\n",
      "\n",
      "[68] e building and deploying solutions to Cloud (AWS, Azure, Google Cloud) including Cloud provisioning tools\n",
      "\n",
      "[86] onstrated experience delivering data products via Azure (e.g. databricks, data lake, etc)\n",
      "Experience in d\n",
      "\n",
      "KAFKA\n",
      "\n",
      "*** Pattern = '\\bkafka\\b' ***\n",
      "\n",
      "[43] h Data Messages Queueing technologies, preferably Kafka\n",
      "Automated and Performance testing of ETL / ELT an\n",
      "\n",
      "[64] ch, S3, SQS, Kinesis) or Spark / Storm / Hadoop / Kafka or Neo4. Comfortable with analytic platforms, e.g\n",
      "\n",
      "KINESIS\n",
      "\n",
      "*** Pattern = '\\bkinesis\\b' ***\n",
      "\n",
      "SPARK\n",
      "\n",
      "*** Pattern = '\\bspark\\b' ***\n",
      "\n",
      "[13] gramming and scripting languages (e.g. Python, R, SPARK, SQL, etc) and software development skills.\n",
      "Exper\n",
      "\n",
      "[19] eering best practices exp, big data technologies (spark, pig, hive) and data pipeline / reproducible ML s\n",
      "\n",
      "[21]  working knowledge of Big Data technologies (e.g. Spark or Redshift) is a plus.\n",
      "You're fluent in English \n",
      "\n",
      "[29] ncy in SQL and programing languages like Python/R/Spark etc.\n",
      "A proven track record of using analysis to i\n",
      "\n",
      "[35]  data to classify UK vegetation and massive scale Spark for image processing at an O&G client.\n",
      "Why You?\n",
      "W\n",
      "\n",
      "[36] ls such as Cassandra, Hadoop (Pig, Hive, Impala), Spark, MongoDB\n",
      "Qualifications\n",
      "University degree in comp\n",
      "\n",
      "[45] c.\n",
      "Experience using Python is a must\n",
      "Knowledge of Spark, Kafka, AWS, Docker, Kubernetes is desirable\n",
      "A st\n",
      "\n",
      "[65]  new documents per day;\n",
      "Have some experience with Spark, Docker, Kubernetes or any other job scheduling/d\n",
      "\n",
      "[69]  ensure end-to-end project delivery.\n",
      "Use a Hadoop/Spark big data ecosystem and program within Pyspark / P\n",
      "\n",
      "[78] NoSQL data bases\n",
      "Prior experience of using Apache Spark to develop and deploy data science projects\n",
      "Compr\n",
      "\n",
      "[85] (scikit-learn, pandas, numpy, scipy, Matplotlib), Spark MLlib, etc.;\n",
      "Real world experience with Internet \n",
      "\n",
      "[92] ormation, etc).\n",
      "Data Engineering proficiency with Spark\n",
      "ECommerce background\n",
      "Previous experience with lif\n",
      "\n",
      "[94] working with Big Data technologies; Hive, Hadoop, spark Understanding of Capital Markets, for example tra\n",
      "\n",
      "[95] er of data manipulation tools and languages (e.g. Spark, Python, R, SAS, Impala, Hive, Pig, SQL etc.);\n",
      "St\n",
      "\n",
      "[97] rite production grade python code\n",
      "Experience with spark (scala or python) for ETLs and model development\n",
      "\n",
      "\n",
      "ELASTICSEARCH\n",
      "\n",
      "*** Pattern = '\\belasticsearch\\b' ***\n",
      "\n",
      "[5] echnical Skills/Experience\n",
      "Experience with any of Elasticsearch, Kafka, MongoDB and Node.js.\n",
      "Proficiency in multi\n",
      "\n",
      "[10] udes many of your usual suspects including Kafka, Elasticsearch and Kubernetes but the introduction of new techno\n",
      "\n",
      "[20] (Scikit-learn, Spark ML, TensorFlow)\n",
      "Apache Spark\n",
      "ElasticSearch, LogStash and Kibana\n",
      "Agile Methodology\n",
      "Git, Jira,\n",
      "\n",
      "[34] Amazon Datastores) and tools (including dynamoDB, elasticsearch, S3, SQS, Kinesis) or Spark / Storm / Hadoop / Ka\n",
      "\n",
      "SQL\n",
      "\n",
      "*** Pattern = '\\bsql\\b' ***\n",
      "\n",
      "[1] ultiple languages is a strong positive.\n",
      "NoSQL and SQL knowledge; the ability to create queries in tools\n",
      "\n",
      "[3] tic tools is essential, as is the need for strong SQL skills. Experience with Tableau or other data vis\n",
      "\n",
      "[7]  partners and technology vendors.\n",
      "Data modelling (SQL, Access) and/or visualisation experience (PowerBi\n",
      "\n",
      "[9] business problems at hand.\n",
      "Details:\n",
      "Proficient in SQL and have experience with R or Python.\n",
      "Have first-\n",
      "\n",
      "[10] stomer engagement. In the role, you will be using SQL, Python and R, as well as cloud technologies, to \n",
      "\n",
      "[11] cs and programming for models through Python\n",
      "Good SQL/data manipulation skills required including clean\n",
      "\n",
      "[13] uch as R, or python) and database languages (e.g. SQL)\n",
      "Experience working with amazon technologies, spe\n",
      "\n",
      "[14] on data pipelines in hybrid environments – RDBMS [SQL] and Big Data environments [Hadoop, SPARK, HIVE, \n",
      "\n",
      "[16] thon, but also in associated languages such as R, SQL and Hadoop/Hive, working with both structured and\n",
      "\n",
      "[18]  two or more of Python, Java (or equivalent), and SQL.\n",
      "Experience conducting analysis on large data set\n",
      "\n",
      "[22]  two or more of Python, Java (or equivalent), and SQL.\n",
      "Experience conducting analysis on large data set\n",
      "\n",
      "[24] posure on AWS ML and AI services\n",
      "Comfortable with SQL\n",
      "Confidence with JIRA\n",
      "Knowledge of Scikit-learn an\n",
      "\n",
      "[26] from systems and relational databases (e.g., CRM, SQL, Adobe Analytics) using tools such as Excel, Alte\n",
      "\n",
      "[28] nd the right person will be very comfortable with SQL and Excel, capable with data querying and manipul\n",
      "\n",
      "[29] ets\n",
      "Strong programming knowledge (ideally Python, SQL and Apache Spark)\n",
      "Track record of producing robus\n",
      "\n",
      "[30] and experience\n",
      "Data querying with Python or R and SQL\n",
      "Proficient in R or Python\n",
      "Supervised and unsuperv\n",
      "\n",
      "[32] -cycle experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical to\n",
      "\n",
      "[33] Languages: Spark, SparkR, R, Python, Scala, Hive, SQL, SPSS, Hadoop, Stata, Google Analytics, Azure\n",
      "Why\n",
      "\n",
      "[34] ectively through reports and presentations\n",
      "Strong SQL and excel skills\n",
      "A strong candidate will have\n",
      "Exp\n",
      "\n",
      "[35] ith a wide variety of technologies (e.g. Tableau, SQL, Python or R…), data sets, and techniques to driv\n",
      "\n",
      "REDSHIFT\n",
      "\n",
      "*** Pattern = '\\bredshift\\b' ***\n",
      "\n",
      "[15]  with big data technologies (Spark, Hadoop, Hive, Redshift, SQL or similar)\n",
      "Experience with Data science too\n",
      "\n",
      "[38] nd workflow management tools, AWS cloud services (Redshift)\n",
      "Knowledge of data mining and segmentation techni\n",
      "\n",
      "[77] knowledge of Big Data technologies (e.g. Spark or Redshift) is a plus.\n",
      "You're fluent in English and eager to\n",
      "\n",
      "LOOKER\n",
      "\n",
      "*** Pattern = '\\blooker\\b' ***\n",
      "\n",
      "[1] y\n",
      "Develop models, reporting, and dashboards using Looker\n",
      "Design and implement advanced statistical testing\n",
      "\n",
      "[26]  using 3rd party analytics tools such as Tableau, Looker, SAP, etc\n",
      "A great work ethic and a thirst for kno\n",
      "\n",
      "[37] sions are covered by self-serve analytics through Looker which gives data scientists the head space to foc\n",
      "\n",
      "BIGQUERY\n",
      "\n",
      "*** Pattern = '\\bbigquery\\b' ***\n",
      "\n",
      "[3] ocumentation.\n",
      "\n",
      "Technical requirement:\n",
      "SQL\n",
      "GIT\n",
      "DBT\n",
      "BigQuery\n",
      "Looker\n",
      "Python - Airflow, Scikit Learn.\n",
      "\n",
      "If you’re\n",
      "\n",
      "[39] perience\n",
      "Comfortable with big data stores (Google BigQuery, Amazon Datastores) and tools (including dynamoDB\n",
      "\n",
      "[69] sations downstream of backend services (mostly in BigQuery SQL) that support internal management information\n",
      "\n",
      "[92] h Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent).\n",
      "Experie\n",
      "\n",
      "HIVE\n",
      "\n",
      "*** Pattern = '\\bhive\\b' ***\n",
      "\n",
      "[18] S [SQL] and Big Data environments [Hadoop, SPARK, HIVE, PIG, KAFKA], Cloud GCP Data components\n",
      "·Ability \n",
      "\n",
      "[30] Tools/Languages: Spark, SparkR, R, Python, Scala, Hive, SQL, SPSS, Hadoop, Stata, Google Analytics, Azur\n",
      "\n",
      "[38]  areas:\n",
      "Data Infrastructure\n",
      "Working in hadoop and hive primarily, sometimes mysql, oracle, and vertica\n",
      "A\n",
      "\n",
      "[63] in associated languages such as R, SQL and Hadoop/Hive, working with both structured and unstructured da\n",
      "\n",
      "[85] more data science toolkits such as Spark, Hadoop, Hive, scikit-learn and pandas\n",
      "Ability to travel 30% in\n",
      "\n",
      "[87]  distributed computing tools (Map/Reduce, Hadoop, Hive, Spark, Gurobi, Arena, etc.)\n",
      "Experience in softwa\n",
      "\n",
      "[92] nd languages (e.g. Spark, Python, R, SAS, Impala, Hive, Pig, SQL etc.);\n",
      "Strong presentation and communic\n",
      "\n",
      "EXCEL\n",
      "\n",
      "*** Pattern = '\\bexcel\\b' ***\n",
      "\n",
      "[45]  State, QGIS, SQL\n",
      "Highly proficient in the use of Excel, SQL and R\n",
      "Hybrid leadership skills is paramount\n",
      "\n",
      "\n",
      "[50]  once, to operate with a high degree of ambiguity\n",
      "Excel and PowerPoint experience\n",
      "Experience on Tableau, \n",
      "\n",
      "[82] \n",
      "If you feel you have the knowledge and skills to excel in this role, we would love to hear from you. To \n",
      "\n",
      "[88] multi-tasking and prioritization skills. Needs to excel in fast paced environment with frequently changin\n",
      "\n",
      "[95] g suites, advance knowledge in R, SQL, Python and excel, Intermediate to advance level in Statistics/Math\n",
      "\n",
      "[99] ery comfortable working with data – a wizard with Excel and other tools;\n",
      "- Knowledge of any BI tool;\n",
      "- Kn\n",
      "\n",
      "POWER_BI\n",
      "\n",
      "*** Pattern = '\\bpower bi\\b' ***\n",
      "\n",
      "[7]  Microsoft Azure SQL Server & Data Factory, R and Power BI, all team members are provided with high spec lap\n",
      "\n",
      "[12] ata visualisation libraries/ platforms such as MS Power BI\n",
      "Experience of Data Engineering on the cloud infra\n",
      "\n",
      "[16] Point experience\n",
      "Experience on Tableau, QlikView, Power BI or similar is an advantage\n",
      "Experience with SQL pr\n",
      "\n",
      "[18] nts\n",
      "·Ability to use visualisation tools [Tableau, Power BI etc] to storyboard and communicate insights\n",
      "· Mus\n",
      "\n",
      "[49] ualization tools (eg Spotfire, Tableau, Microsoft Power BI, etc)\n",
      "Preferred Qualifications:\n",
      "If you have the f\n",
      "\n",
      "[65] d STEM related University degree\n",
      "Experience using Power BI or similar data management system/software is vit\n",
      "\n",
      "SNOWFLAKE\n",
      "\n",
      "*** Pattern = '\\bsnowflake\\b' ***\n",
      "\n",
      "[87] \n",
      "\n",
      "Our data is stored in a data warehouse built on Snowflake and we use AWS technologies such as Lambda and Sa\n",
      "\n",
      "[94] ing.\n",
      "tSQLt.\n",
      "Team City.\n",
      "Experience in Erwin DG and Snowflake desireable.\n",
      "It has been and will continue to be t\n",
      "\n",
      "[99] b, Potgresql, Mysql, Oracle, SqlServer, Bigquery, Snowflake, Redshift\n",
      "Documentation and Process: Jira, Conflu\n",
      "\n",
      "TABLEAU\n",
      "\n",
      "*** Pattern = '\\btableau\\b' ***\n",
      "\n",
      "[1] ing complex data visualizations in BI tools (i.e. Tableau, Qlikview or PowerBI)\n",
      "- Agile and organized with \n",
      "\n",
      "[4] s the need for strong SQL skills. Experience with Tableau or other data visualization tools is highly desir\n",
      "\n",
      "[18] Experience in data visualization, preferably with Tableau and/or Shiny\n",
      "· Advantage: experience with working\n",
      "\n",
      "[25] learning algorithms.\n",
      "\n",
      "Visualization tools such as Tableau and R shiny.\n",
      "\n",
      "[26] d business intelligence tools (Microsoft Power BI/Tableau).\n",
      "\n",
      "= Experienceof delivering dashboards and visua\n",
      "\n",
      "[28] with data visualization and analytics tools (e.g. Tableau, D3.js, R)\n",
      "Able to take accountability with a pro\n",
      "\n",
      "[30] ta visualization tools – experience of PowerBi or Tableau beneficial\n",
      "Clear communicator - able to concisely\n",
      "\n",
      "[44] a components\n",
      "·Ability to use visualisation tools [Tableau, Power BI etc] to storyboard and communicate insi\n",
      "\n",
      "[45] nd business intelligence platforms (e.g. Alteryx, Tableau, Power BI, QlikView/Sense)\n",
      "You are a self-starter\n",
      "\n",
      "[46] y, Athena, Mongo) and visualisation tools such as Tableau\n",
      "A high degree of self-sufficiency, with proven tr\n",
      "\n",
      "[50] s the need for strong SQL skills. Experience with Tableau or other data visualization tools is highly desir\n",
      "\n",
      "[62] xperience with data visualisation tools Qlikview, Tableau, matplotlib\n",
      "Experience with Agile technologies (J\n",
      "\n",
      "[65] usiness intelligence visualisation tools (such as Tableau) or data frameworks (such as Hadoop) would be adv\n",
      "\n",
      "[73] alisation tools or libraries (Javascript, Python, Tableau)\n",
      "Cloud platforms – Experience building and deploy\n",
      "\n",
      "[74] WS etc)\n",
      "Experience with data visualisation tools (Tableau, QlikView etc)\n",
      "Deploying machine learning models \n",
      "\n",
      "[94] L and Python/R\n",
      "Proficient in the use of Excel and Tableau/PowerBI or a similar visualisation tool\n",
      "Experienc\n",
      "\n",
      "[96] ning and algorithms\n",
      "Data visualization tools like Tableau\n",
      "Be able to apply statistics with an emphasis on d\n",
      "\n",
      "VERTICA\n",
      "\n",
      "*** Pattern = '\\bvertica\\b' ***\n",
      "\n",
      "GRAFANA\n",
      "\n",
      "*** Pattern = '\\bgrafana\\b' ***\n",
      "\n",
      "[69] ience tools such as Github, Jira, Anaconda, D3JS, Grafana.\n",
      "You should be\n",
      "A person who likes to work in a st\n",
      "\n",
      "LUBRIDATE\n",
      "\n",
      "*** Pattern = '\\blubridate\\b' ***\n",
      "\n",
      "TIDYVERSE\n",
      "\n",
      "*** Pattern = '\\btidyverse\\b' ***\n",
      "\n",
      "[49] L, NoSQL, Shiny, Graph database, Knowledge Graph, Tidyverse, Machine Learning, AI, Artificial Intelligence, C\n",
      "\n",
      "[85]  R packages/ python modules e.g. Bioconductor and tidyverse or pandas\n",
      "Experience working with the Atlassian t\n",
      "\n",
      "DPLYR\n",
      "\n",
      "*** Pattern = '\\bdplyr\\b' ***\n",
      "\n",
      "GGPLOT2\n",
      "\n",
      "*** Pattern = '\\bggplot2\\b' ***\n",
      "\n",
      "ESQUISSE\n",
      "\n",
      "*** Pattern = '\\besquisse\\b' ***\n",
      "\n",
      "SHINY\n",
      "\n",
      "*** Pattern = '\\bshiny\\b' ***\n",
      "\n",
      "[51] ronment; using data visualisation tools such as R Shiny or Tableau\n",
      "Post-graduate science or medical degre\n",
      "\n",
      "[75] data visualization tools such as Pydash, Bokeh, R Shiny and Tableau would be desired.\n",
      "Domain-expertise in\n",
      "\n",
      "BIOCONDUCTOR\n",
      "\n",
      "*** Pattern = '\\bbioconductor\\b' ***\n",
      "\n",
      "KNITR\n",
      "\n",
      "*** Pattern = '\\bknitr\\b' ***\n",
      "\n",
      "RMARKDOWN\n",
      "\n",
      "*** Pattern = '\\brmarkdown\\b' ***\n",
      "\n",
      "QUANTEDA\n",
      "\n",
      "*** Pattern = '\\bquanteda\\b' ***\n",
      "\n",
      "RCRAWLER\n",
      "\n",
      "*** Pattern = '\\brcrawler\\b' ***\n",
      "\n",
      "CARET\n",
      "\n",
      "*** Pattern = '\\bcaret\\b' ***\n",
      "\n",
      "MLR\n",
      "\n",
      "*** Pattern = '\\bmlr\\b' ***\n",
      "\n",
      "ORACLE\n",
      "\n",
      "*** Pattern = '\\boracle\\b' ***\n",
      "\n",
      "[45]  Knowledge of/and experience in databases such as Oracle and other relational database systems such as MS \n",
      "\n",
      "[47] ng in hadoop and hive primarily, sometimes mysql, oracle, and vertica\n",
      "Authoring pipelines via SQL and pyth\n",
      "\n",
      "[94] s (including all stages of software development).\n",
      "Oracle SQL Developer and Microsoft SQL Server Management\n",
      "\n",
      "[99]  tools like: DynamoDb, Mongodb, Potgresql, Mysql, Oracle, SqlServer, Bigquery, Snowflake, Redshift\n",
      "Documen\n",
      "\n",
      "NUMPY\n",
      "\n",
      "*** Pattern = '\\bnumpy\\b' ***\n",
      "\n",
      "[8]  such as scikit-learn, tensorflow, keras, pandas, numpy\n",
      "Strong statistical modelling background\n",
      "Python we\n",
      "\n",
      "[12] n for data analysis and machine learning (pandas, numpy, scikit-learn, tensorflow, keras, etc.).\n",
      "Demonstr\n",
      "\n",
      "[18] wledge of and experience with core libraries like Numpy, Pandas, Scikit-learn, SciPy etc. Bonus points fo\n",
      "\n",
      "[30]  deploying ML models using the Python data stack (numpy, pandas, sklearn).\n",
      "Strong analytical skills.\n",
      "Bein\n",
      "\n",
      "[32] various ML models, technical engineering (python, numpy, tensorflow, scikit-learn), work with massive, co\n",
      "\n",
      "[36] data science toolkits for Python, such as Pandas, Numpy, Dask, visualisation.\n",
      "Sound understanding and pre\n",
      "\n",
      "[42] \n",
      "\n",
      "[43] ries such as Pandas, Matplotlib, Scikit-learn and Numpy\n",
      "Experience using SQL\n",
      "Knowledge of the following a\n",
      "\n",
      "[57]  Degree in STEM subject\n",
      "Fluent in Python (Pandas, Numpy, Sci-Kit) and/or other relevant languages\n",
      "Our cor\n",
      "\n",
      "[60] and development in Python using libraries such as numpy, pandas, scikit-learn, tensorflow or pytorch.\n",
      "Hig\n",
      "\n",
      "[64] raries such as Tensorflow, PyTorch, scikit-learn, numpy and scipy.\n",
      "Strong understanding of statistics and\n",
      "\n",
      "[79]  tooling and approaches, great Python experience (NumPy, Pandas, SciKit-Learn and Matplotlib). Experience\n",
      "\n",
      "[93] on based data science libraries, such as: pandas, numpy, matplotlib, plotly & dash, sqlalchemy, sklearn, \n",
      "\n",
      "SCIPY\n",
      "\n",
      "*** Pattern = '\\bscipy\\b' ***\n",
      "\n",
      "[20] anced in Python for data science/analysis (Pandas/SciPy/sk-learn/Keras) or, alternatively, R programming \n",
      "\n",
      "[84] ency using general data science libraries (numpy, scipy, pandas)\n",
      "You have proficiency in either PyTorch o\n",
      "\n",
      "[88]  common libraries and frameworks including Numpy, Scipy, Pandas, Matplotlib,Tensorflow, Keras\n",
      "\n",
      "= Knowledg\n",
      "\n",
      "PANDAS\n",
      "\n",
      "*** Pattern = '\\bpandas\\b' ***\n",
      "\n",
      "[1] of python for data analysis and machine learning (pandas, numpy, scikit-learn, statsmodels, Spacy, Tensorf\n",
      "\n",
      "[3] knowledge of Python libraries such as matplotlib, pandas and numpy would be advantageous\n",
      "Experience with d\n",
      "\n",
      "[18] of and experience with core libraries like Numpy, Pandas, Scikit-learn, SciPy etc. Bonus points for skills\n",
      "\n",
      "[23]  you can use would be Python, with libraries like Pandas, and use of Jupyter notebooks.\n",
      "Experience with da\n",
      "\n",
      "[24] nce background\n",
      "Experience with Python (especially Pandas) is essential\n",
      "Taking it to the next level\n",
      "Basic u\n",
      "\n",
      "[33] ta/statistical packages (eg. SQL/Hive, R, Python (Pandas + Statsmodels + Scikit-learn), Pig, Julia, D3.js)\n",
      "\n",
      "[38]  libraries and frameworks including Numpy, Scipy, Pandas, Matplotlib,Tensorflow, Keras\n",
      "\n",
      "= Knowledgeof stan\n",
      "\n",
      "[41]  plus)\n",
      "Backend and data processing, Django/Flask, Pandas, Jupyter notebooks based research\n",
      "Team\n",
      "We’re a sm\n",
      "\n",
      "[62] \n",
      "\n",
      "[75] g our services.\n",
      "We work mostly in Python3.\n",
      "We use Pandas & Numpy quite heavily, as well as TensorFlow, whe\n",
      "\n",
      "[77] ition\n",
      "Proficient knowledge of Python\n",
      "Knowledge of Pandas for python analytics\n",
      "Proficient with common libra\n",
      "\n",
      "[80] owledge of Python, in particular packages such as Pandas, Numpy, SciPy, Matplotlib (or equivalent). Knowle\n",
      "\n",
      "[100] owledge of Python, in particular packages such as Pandas, Numpy, SciPy, Matplotlib (or equivalent). Knowle\n",
      "\n",
      "MATPLOTLIB\n",
      "\n",
      "*** Pattern = '\\bmatplotlib\\b' ***\n",
      "\n",
      "[24] e stack (tensorflow/pytorch/mxnet, numpy, pandas, matplotlib, scikit-learn, etc)\n",
      "· Ability to convey rigorous \n",
      "\n",
      "[45] particular packages such as Pandas, Numpy, SciPy, Matplotlib (or equivalent). Knowledge of PySpark/Scala is a \n",
      "\n",
      "[65] tools and libraries such as OpenCV, scikit-image, matplotlib, etc.\n",
      "Educational or work exposure to agriculture\n",
      "\n",
      "[69] earning Python for data analysis ( Pandas, Numpy, Matplotlib )\n",
      "An understanding of basic programming principle\n",
      "\n",
      "[87] ndas, SQL)\n",
      "Data visualization libraries (Seaborn, matplotlib)\n",
      "Demonstrated initiative, judgment and discretion\n",
      "\n",
      "BOKEH\n",
      "\n",
      "*** Pattern = '\\bbokeh\\b' ***\n",
      "\n",
      "SKLEARN\n",
      "\n",
      "*** Pattern = '\\bscikit\\-learn\\b|\\bsklearn\\b' ***\n",
      "\n",
      "[8] ssential)\n",
      "High familiarity with libraries such as scikit-learn, tensorflow, keras, pandas, numpy\n",
      "Strong statisti\n",
      "\n",
      "[12] ata analysis and machine learning (pandas, numpy, scikit-learn, tensorflow, keras, etc.).\n",
      "Demonstrable machine l\n",
      "\n",
      "[18] xperience with core libraries like Numpy, Pandas, Scikit-learn, SciPy etc. Bonus points for skills with deep lea\n",
      "\n",
      "[19] n; experience with Keras, PyTorch, TensorFlow and Scikit-learn\n",
      "Commercial experience on production systems\n",
      "Good \n",
      "\n",
      "[30] odels using the Python data stack (numpy, pandas, sklearn).\n",
      "Strong analytical skills.\n",
      "Being a strong collab\n",
      "\n",
      "[32] technical engineering (python, numpy, tensorflow, scikit-learn), work with massive, complex datasets and a high \n",
      "\n",
      "[43] with common libraries such as Pandas, Matplotlib, Scikit-learn and Numpy\n",
      "Experience using SQL\n",
      "Knowledge of the f\n",
      "\n",
      "[48] h Data science toolkits for ML and deep learning (scikit-learn, SparkML, Tensorflow, Keras)\n",
      "Experience in Agile \n",
      "\n",
      "[52] Flow / PyTorch / Keras, Jupyter, Pandas / SciPy / scikit-learn\n",
      "Strong expertise in remote sensing and image proc\n",
      "\n",
      "[53] le hands-on experience with ML libraries (such as scikit-learn and/or TensorFlow)\n",
      "Fluent communicator in both wr\n",
      "\n",
      "[60]  in Python using libraries such as numpy, pandas, scikit-learn, tensorflow or pytorch.\n",
      "Highly proficient in SQL \n",
      "\n",
      "[63] cs).\n",
      "Knowledge of common analytics tools (Python, Sklearn, Pandas, SQL)\n",
      "Data visualization libraries (Seabo\n",
      "\n",
      "[64] ta science libraries such as Tensorflow, PyTorch, scikit-learn, numpy and scipy.\n",
      "Strong understanding of statist\n",
      "\n",
      "[71] rtable with SQL\n",
      "Confidence with JIRA\n",
      "Knowledge of Scikit-learn and/or Pandas\n",
      "Exposure to functional programming \n",
      "\n",
      "[75] t\n",
      "Machine learning algorithms and frameworks e.g. Scikit-Learn, TensorFlow\n",
      "Distributed processing technologies e\n",
      "\n",
      "[79] proaches, great Python experience (NumPy, Pandas, SciKit-Learn and Matplotlib). Experience with Jupyter Notebook\n",
      "\n",
      "[80] ence in machine learning with frameworks (such as Scikit-Learn, Keras, TensorFlow, PyTorch, Mllib)\n",
      "Excellent kno\n",
      "\n",
      "[93] as, numpy, matplotlib, plotly & dash, sqlalchemy, sklearn, jupyter-notebooks etc.\n",
      "Familiarity with cloud ba\n",
      "\n",
      "[99] engineering etc.\n",
      "Coding experience – SQL, Python (sklearn), R, SAS etc.\n",
      "Experience working with large and s\n",
      "\n",
      "PYTORCH\n",
      "\n",
      "*** Pattern = '\\bpytorch\\b' ***\n",
      "\n",
      "[32] rvival Analysis, Enrichment Analysis, Tensorflow, Pytorch, PhD, MSc, masters, BSc, bachelors, games, gaming\n",
      "\n",
      "[44] uch as numpy, pandas, scikit-learn, tensorflow or pytorch.\n",
      "Highly proficient in SQL using databases such as\n",
      "\n",
      "[72] ng and data science libraries such as Tensorflow, PyTorch, scikit-learn, numpy and scipy.\n",
      "Strong understand\n",
      "\n",
      "[89] ith machine learning packages such as TensorFlow, PyTorch, Keras, Python (scikit-learn, pandas, numpy, scip\n",
      "\n",
      "[93] with deep learning frameworks like Tensorflow and PyTorch.\n",
      "Natural Language Processing - Knowledge includin\n",
      "\n",
      "[97] rning tools/frameworks such as Tensorflow, Keras, PyTorch scikit-learn, DeepLearning4j, etc. Version contro\n",
      "\n",
      "[98] g algorithms to create novel plant genetics using PyTorch and/or Tensorflow with Python as our main codebas\n",
      "\n",
      "PYSPARK\n",
      "\n",
      "*** Pattern = '\\bpyspark\\b' ***\n",
      "\n",
      "[11] , SciPy, Matplotlib (or equivalent). Knowledge of PySpark/Scala is a bonus\n",
      "Practical understanding of SQL a\n",
      "\n",
      "[36] ften leverage the following technologies: Python, PySpark, TensorFlow, PyTorch, SQL, Airflow, Databricks, o\n",
      "\n",
      "[53] haviour. You will be hands-on modelling in Python/PySpark and present insights back to clients across the r\n",
      "\n",
      "[59]  of very rich data to work with\n",
      "Work with Python, PySpark, AWS, Kubernetes\n",
      "Have a passion for deploying rob\n",
      "\n",
      "[98] stical modelling experience with Python including PySpark\n",
      "Ability to communicate technical findings to non \n",
      "\n",
      "SPARKML\n",
      "\n",
      "*** Pattern = '\\bspark[\\.\\s]?ml' ***\n",
      "\n",
      "TENSORFLOW\n",
      "\n",
      "*** Pattern = '\\btensorflow\\b' ***\n",
      "\n",
      "[18]  familiarity with libraries such as scikit-learn, tensorflow, keras, pandas, numpy\n",
      "Strong statistical modellin\n",
      "\n",
      "[24] ning algorithms and frameworks e.g. Scikit-Learn, TensorFlow\n",
      "Distributed processing technologies e.g. Apache S\n",
      "\n",
      "[26]  models with deep learning frameworks like MXNet, Tensorflow, Caffe, Torch, Theano or similar\n",
      "Fluency with oth\n",
      "\n",
      "[27] ine Learning and Deep Learning frameworks such as TensorFlow, PyTorch, MxNet Caffe, and Keras.\n",
      "· Experience bu\n",
      "\n",
      "[32] ent\n",
      "Experience with deep learning frameworks like tensorflow, keras or mxnet\n",
      "Ability to research machine learn\n",
      "\n",
      "[36] pment of machine learning models using Python and TensorFlow/PyTorch\n",
      "Experience with time-series modelling and\n",
      "\n",
      "[48] hine learning and data handling libraries such as Tensorflow/Keras, Scikit-learn, Pandas and Numpy.\n",
      "An expert \n",
      "\n",
      "[52] PoCs with Python; experience with Keras, PyTorch, TensorFlow and Scikit-learn\n",
      "Commercial experience on product\n",
      "\n",
      "[57] atistics/machine learning packages such as Keras, Tensorflow or Spark MLlib. Experience with programming in Py\n",
      "\n",
      "[65] earning methodologies and frameworks (e.g. MXNet, TensorFlow);Experience with a number of data manipulation to\n",
      "\n",
      "[79] g or neural nets\n",
      "Exposure to technologies such as tensorflow, decision trees, spark\n",
      "Masters or PHD in relevant\n",
      "\n",
      "[82] essing and modelling libraries such as pandas and TensorFlow. R is a nice-to-have but not a requirement.\n",
      "Worki\n",
      "\n",
      "[94] e in Data science solution development in Python/ Tensorflow/R and GCP components\n",
      "Contract length: 6 months\n",
      "Jo\n",
      "\n",
      "[96] nd machine learning (pandas, numpy, scikit-learn, tensorflow, keras, etc.).\n",
      "Demonstrable machine learning expe\n",
      "\n",
      "[99] \n",
      "A practice of Big Data platforms (Spark, Hadoop, TensorFlow, etc.)\n",
      "Would be a plus:\n",
      "Knowledge of Agile method\n",
      "\n",
      "SPACY\n",
      "\n",
      "*** Pattern = '\\bspacy\\b' ***\n",
      "\n",
      "[59]  libraries are Scipy, Scikit-learn, NLTK, Gensim, Spacy, CoreNLP.\n",
      "Required: knowledge of machine learning\n",
      "\n",
      "[85] A or BS degree\n",
      "\n",
      "Nice If You Have:\n",
      "Experience with SpaCy or other Natural Language Processing Libraries\n",
      "Ex\n",
      "\n",
      "KERAS\n",
      "\n",
      "*** Pattern = '\\bkeras\\b' ***\n",
      "\n",
      "[2] ce with deep learning frameworks like tensorflow, keras or mxnet\n",
      "Ability to research machine learning tec\n",
      "\n",
      "[8] ability and Bayesian statistics.\n",
      "Have worked with Keras, PyTorch, Tensorflow and Scikit-learn etc. - Idea\n",
      "\n",
      "[79] earning (pandas, numpy, scikit-learn, tensorflow, keras, etc.).\n",
      "Demonstrable machine learning experience \n",
      "\n",
      "[88] rience deploying ML at scale via APIs (eg. Flask, Keras) advantageous\n",
      "Startup experience and working with\n",
      "\n",
      "DATABRICKS\n",
      "\n",
      "*** Pattern = '\\bdatabricks\\b' ***\n",
      "\n",
      "[37] perience delivering data products via Azure (e.g. databricks, data lake, etc)\n",
      "Experience in dashboard tools (T\n",
      "\n",
      "[65] atest AI webservices and data science tools, from DataBricks to citizen data science tools like Dataiku, C3.AI\n",
      "\n",
      "[87] tiple databases.\n",
      "Desirable:\n",
      "Experience with Spark/Databricks is desirable\n",
      "Experience deploying ML at scale via\n",
      "\n",
      "MONGODB\n",
      "\n",
      "*** Pattern = '\\bmongodb\\b' ***\n",
      "\n",
      "[8] analysis\n",
      "Experience with NoSQL databases, such as MongoDB\n",
      "Experience with common data science toolkits\n",
      "Work\n",
      "\n",
      "[21] quired: competence required with Bitbucket, NoSQL/MongoDB, Linux.\n",
      "Optional: Docker, CI/CD processes knowled\n",
      "\n",
      "[50] ence\n",
      "Experience with any of Elasticsearch, Kafka, MongoDB and Node.js .\n",
      "Proficiency in multiple programming\n",
      "\n",
      "[62] Experience working with our tech stack, including MongoDB, AWS, Django, ElasticSearch, Redis and Flask.\n",
      "Kno\n",
      "\n",
      "HADOOP\n",
      "\n",
      "*** Pattern = '\\bhadoop\\b' ***\n",
      "\n",
      "[4] f data\n",
      "Use Hive, Scala, Java or Python to utilize Hadoop/Spark to process large-scale datasets\n",
      "Able to ide\n",
      "\n",
      "[30] ng statistical languages such as R/Matlab/SAS/SQL/Hadoop/Python\n",
      "Experience in advanced visualisation and v\n",
      "\n",
      "[40] Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs) and Cloud (AWS and Azure) is\n",
      "\n",
      "[44] s-on experience of Python, AI, ML, Kafka, Oracle, Hadoop, Flink, Jupyter Notebook, or other data science p\n",
      "\n",
      "[46] MODELS!!)\n",
      "Fluent in Python &/or R\n",
      "Experience with Hadoop and related Big Data Technologies\n",
      "Exceptional com\n",
      "\n",
      "[47] tion and distributed computing tools (Map/Reduce, Hadoop, Hive, Spark, Gurobi, Arena, etc.)\n",
      "Experience in \n",
      "\n",
      "[55] ding large scale data processing pipelines. e. g. Hadoop/Spark and SQL.\n",
      "Experience provisioning computatio\n",
      "\n",
      "[56] \n",
      "Experience with distributed data frameworks like Hadoop and Spark a plus\n",
      "A good understanding of, and exp\n",
      "\n",
      "[74]  knowledge of big data architectures, i.e. NoSQL, Hadoop etc.\n",
      "Benefits:\n",
      "\n",
      "Our employees enjoy free breakfas\n",
      "\n",
      "[79] achine learning models on very large data sets in Hadoop environments using tools such as Python, Spark an\n",
      "\n",
      "[82] nowledge\n",
      "A practice of Big Data platforms (Spark, Hadoop, TensorFlow, etc.)\n",
      "Would be a plus:\n",
      "Knowledge of \n",
      "\n",
      "[97] o DS, unit testing, version control, code review)\n",
      "Hadoop (especially the Cloudera and Hortonworks distribu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use check_re to test the regular expressions that will be used to search for tools\n",
    "for key, val in dict_tools.items():\n",
    "    print(f\"{key.upper()}\\n\")\n",
    "    check_re(jobsdf=dsjobs, regex=val[\"re\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression looking for mentions of the C, C++ or C# programming languages matches mentions of \"C\" with respect to grades, e.g. GCSE grades or NHS/other salary bands, so I will check for this and correct the results where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (and correct, if needed) the results of the regex used to identify mentions of \n",
    "# C, C++ or C# programming languages\n",
    "for index, row in dsjobs.iterrows():\n",
    "    # return an iterator over all matches with the regular expression\n",
    "    result = re.finditer(\n",
    "        dict_tools[\"c++_c#\"]['re'], row[\"job_description\"], re.IGNORECASE)\n",
    "    if result:  # if there are any matches:\n",
    "        for v in result:\n",
    "            start = v.span()[0]\n",
    "            stop = v.span()[1]\n",
    "            # isolate the text surrounding the match result (string)\n",
    "            string = row['job_description'][start-50:stop+50]\n",
    "            counter = 0\n",
    "            # search this string for reference to grades, GCSEs and Bands (e.g. NHS salary bands)\n",
    "            if re.search(r\"\\bgcse\\b|\\bband\\b|\\bgrade\\b\", string, re.IGNORECASE):\n",
    "                # correct these \"false positives\"\n",
    "                print(string+\"\\n\")\n",
    "                dsjobs.loc[index, \"c++_c#\"] = False\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search each job description for each skill using the regular expressions in dict_tools,\n",
    "# entering the boolean result in a new column for each tool\n",
    "for key, val in dict_tools.items():\n",
    "    dsjobs[key] = dsjobs[\"job_description\"].apply(\n",
    "        lambda x: bool(re.search(val['re'], x, re.IGNORECASE)))\n",
    "    # print(f\"{val['label']}: {(np.mean(dsjobs[key])*100).round(2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education: search for mentions of academic qualifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A quick scan of a few data science roles will tell you that employers believe a very strong educational background is required to develop the depth of knowledge necessary to be a data scientist.\n",
    " \n",
    " To find out what proportion of data science jobs require a degree, and which qualifications and subjects are most often mentioned by employers in job descriptions, I will create dictionaries of regular expressions to search for these within the job descriptions, and add the results (boolean masks) to `dsjobs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expressions and labels for degree qualifications,\n",
    "# which will be used to search for these in the job descriptions\n",
    "# the labels will later be used for plots\n",
    "dict_qualifications = {\n",
    "    \"bachelors\": {\n",
    "        're': r\"\\bbachelor\\'?|\\bhonours\\b|\\bbsc\\b|\\bbs\\b|\\bba\\b\",\n",
    "        'label': \"Bachelor's\"\n",
    "    },\n",
    "    \"masters\": {\n",
    "        're': r\"\\bmaster\\'?s\\b|\\bmsc\\b|\\bma\\b\",\n",
    "        'label': \"Master's\"\n",
    "    },\n",
    "    \"phd\": {\n",
    "        're': r\"\\bphd\\b|\\bdphil\\b|\\bdoctorate\\b\",\n",
    "        'label': \"PhD\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACHELORS\n",
      "\n",
      "*** Pattern = '\\bbachelor\\'?|\\bhonours\\b|\\bbsc\\b|\\bbs\\b|\\bba\\b' ***\n",
      "\n",
      "[9] sex.\n",
      "KEY REQUIREMENTS\n",
      "\n",
      "The post holder must have:\n",
      "BSc in Computer Science, Physics, Economics, Statisti\n",
      "\n",
      "[12] Appropriate statistical/computer science degree – BSc/MSc/PhD.\n",
      "\n",
      "Strong programming experience (python, \n",
      "\n",
      "[15] ls required.\n",
      "Great communication skills required.\n",
      "Bachelor's degree in data related field required.\n",
      "Experienc\n",
      "\n",
      "[21] ls required.\n",
      "Great communication skills required.\n",
      "Bachelor's degree in data related field required.\n",
      "Experienc\n",
      "\n",
      "[33] ta-driven decision making\n",
      "Minimum qualifications:\n",
      "BS in Computer Science, Electrical Engineering, Math\n",
      "\n",
      "[37] ex.\n",
      "Key Requirements:\n",
      "The postholder must have:\n",
      "* BSc in Network Science, Data Science, Statistics, Com\n",
      "\n",
      "[44] nation of education and experience (3+ preferred)\n",
      "Bachelor’s degree in Computer Science, Artificial Intellig\n",
      "\n",
      "[45] h more).\n",
      "Education, Skills & Experience\n",
      "Essential\n",
      "Bachelors/Masters/PhD in Computer Science, Software Engine\n",
      "\n",
      "[46]  tools used by analysts\n",
      "Requirements\n",
      "Minimum of a Bachelors degree, preferably in Finance, Business Analytic\n",
      "\n",
      "[54]  a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ year\n",
      "\n",
      "[55]  and big data\n",
      "\n",
      "Skills and experience\n",
      "\n",
      "Educated to bachelor’s degree (or higher) in a numerate discipline, su\n",
      "\n",
      "[57] tion as expert in claims data science\n",
      "Key Skills:\n",
      "Bachelor, MS/PhD(preferable) in computer science, mathemat\n",
      "\n",
      "[64] cs, mathematics or engineering. Candidates with a BSc in AI or Machine Learning will be considered\n",
      "Prog\n",
      "\n",
      "[65] c.)\n",
      "Outstanding academic qualifications such as a Bachelor's Degree in Mathematics, Statistics or other Quant\n",
      "\n",
      "[86]  possess the following:\n",
      "· Desired qualifications; BSc / MSc in Analytical Chemistry or related subject.\n",
      "\n",
      "[87] ronment across multinational teams\n",
      "You must have…\n",
      "Bachelor’s or Master’s Degree in a quantitative field\n",
      "Expe\n",
      "\n",
      "[91]  the following skills and experience:\n",
      "Educated to BSc/ MSc/ PhD in a STEM degree\n",
      "Proficiency in Python/\n",
      "\n",
      "[92] ndonTechnology\n",
      "15 Oct, 2020\n",
      "Business Analyst/Tech BA (London)\n",
      "Helen Dawit\n",
      "\n",
      "[93]  with these required skills to achieve our goals:\n",
      "Bachelor's degree from an accredited institution in Data Sc\n",
      "\n",
      "[99] l skills.\n",
      "Strong communication skills.\n",
      "Desirable:\n",
      "BS in Mathematics, Statistics, Operation Research or\n",
      "\n",
      "MASTERS\n",
      "\n",
      "*** Pattern = '\\bmaster\\'?s\\b|\\bmsc\\b|\\bma\\b' ***\n",
      "\n",
      "[1] ademia. Holding at least an BSc, and preferably a MSc/ PhD in a science such as Physics, Statistics, Co\n",
      "\n",
      "[4] on.\n",
      "\n",
      "\n",
      "What are we looking for?\n",
      "\n",
      "Essential:\n",
      "BSc or MSc qualification in data science, or recognised equi\n",
      "\n",
      "[7] or data science projects\n",
      "What we're looking for:\n",
      "\n",
      "Masters or PhD degree in a quantitative field (e.g. mathe\n",
      "\n",
      "[8] uired including cleaning and managing data\n",
      "PhD or MSc in a technical discipline\n",
      "The Benefits:\n",
      "Remote wo\n",
      "\n",
      "[11] ience or similar); or\n",
      "\n",
      "• A higher degree, e.g. an MSc or PhD, in a subject containing formal statistica\n",
      "\n",
      "[16]  looking for an ambitious and enthusiastic recent masters or PhD graduate in a numerical discipline to join\n",
      "\n",
      "[19] similar roles in a data science team\n",
      "Bachelors or Masters in Economy, Computer Science, Mathematics, Physic\n",
      "\n",
      "[20] iculture.\n",
      "\n",
      "Requirements\n",
      "\n",
      "Requirements - must have\n",
      "MsC or PhD in Computer Science, Machine Learning, Rem\n",
      "\n",
      "[25] ou'll probably need to be successful on this one:\n",
      "Masters or PhD in Computer Science, Statistics, Applied S\n",
      "\n",
      "[27] opriate statistical/computer science degree – BSc/MSc/PhD.\n",
      "\n",
      "Strong programming experience (python, R) a\n",
      "\n",
      "[29] ESSENTIAL SKILLS AND EXPERIENCE REQUIRED\n",
      "· PhD or MSc in data science or other advanced degree in life \n",
      "\n",
      "[38] g solutions for new areas of predictive leverage.\n",
      "MSc, PhD in mathematics, statistics, quantitative fin\n",
      "\n",
      "[40] iences using products such as Power BI\n",
      "A relevant Masters or PhD degree in Computer Science, Engineering, a\n",
      "\n",
      "[41] eam.\n",
      "This role would equally suit a recent PhD or Masters graduate looking to take their first steps out of\n",
      "\n",
      "[44] efore you join us you should have:\n",
      "BSc (min 2.1), MSc or PhD in science, mathematics or engineering. We\n",
      "\n",
      "[46] iculture.\n",
      "\n",
      "Requirements\n",
      "\n",
      "Requirements - must have\n",
      "MsC or PhD in Computer Science, Machine Learning, Rem\n",
      "\n",
      "[71] mmercial experience of from a relevant STEM-based MSc degree\n",
      "Ability to operate with Linux on a day-to-\n",
      "\n",
      "[79]  have but not essential), GIS analysis experience\n",
      "MsC in a relevant subject (Stats, Physics, Maths)\n",
      "\n",
      "[80] ducation/Qualifications:\n",
      "Scientific Degree - BSc, MSc/PhD or equivalent\n",
      "Experience:\n",
      "Must have experienc\n",
      "\n",
      "[81] s involving data.\n",
      "\n",
      "Essential Skills & Experience\n",
      "\n",
      "Masters in Maths, Statistics, Data Science, Machine Learn\n",
      "\n",
      "PHD\n",
      "\n",
      "*** Pattern = '\\bphd\\b|\\bdphil\\b|\\bdoctorate\\b' ***\n",
      "\n",
      "[13] lls required including cleaning and managing data\n",
      "PhD or MSc in a technical discipline\n",
      "The Benefits:\n",
      "Re\n",
      "\n",
      "[14] tical procedures.\n",
      "\n",
      "Essential Skills\n",
      "Experience at PhD/postdoctoral level with processing proteomics dat\n",
      "\n",
      "[17] nd equal manner.\n",
      "\n",
      "Go Gousto!\n",
      "\n",
      "Requirements\n",
      "MSc or PhD in STEM subjects would be great! But there are lo\n",
      "\n",
      "[19] olve complex problems.\n",
      "\n",
      "Desiredrequirements:\n",
      "\n",
      "= A PhD ormasters level degree in a related discipline wi\n",
      "\n",
      "[22] entation for the engineering team\n",
      "Qualifications:\n",
      "PhD in statistics, economics, econometrics, or a rele\n",
      "\n",
      "[23] ate statistical/computer science degree – BSc/MSc/PhD.\n",
      "\n",
      "Strong programming experience (python, R) and m\n",
      "\n",
      "[29] d as a new market innovation.\n",
      "\n",
      "Master's degree or Phd in Statistics, Data Science, Mathematics, Compute\n",
      "\n",
      "[30] rable qualifications and experience:\n",
      "Quantitative PhD degree in engineering, computer science, physics,\n",
      "\n",
      "[32] alysis, Enrichment Analysis, Tensorflow, Pytorch, PhD, MSc, masters, BSc, bachelors, games, gaming\n",
      "Expi\n",
      "\n",
      "[35] sia.\n",
      "\n",
      "Requirements\n",
      "\n",
      "Minimum qualifications\n",
      "MSc or Phd in an applied scientific subject (e.g. Statistics\n",
      "\n",
      "[36] at affect their performance\n",
      "- Bachelor’s/Master’s/PhD in STEM (preferably Computer Science or Mathemati\n",
      "\n",
      "[38] ou join us you should have:\n",
      "BSc (min 2.1), MSc or PhD in science, mathematics or engineering. We recrui\n",
      "\n",
      "[39] alytical concepts to people from other fields\n",
      "MSc/PhD Degree in STEM subject\n",
      "Fluent in Python (Pandas, \n",
      "\n",
      "[50]  be great if you have:\n",
      "A top degree (and possibly PhD) from a university in engineering, computer scien\n",
      "\n",
      "[51]  develop our product\n",
      "\n",
      "Minimum Requirements:\n",
      "MS or PhD in quantitative field\n",
      "5+ years hands on experienc\n",
      "\n",
      "[52] products such as Power BI\n",
      "· A relevant Masters or PhD degree in Computer Science, Engineering, and/or r\n",
      "\n",
      "[57] lytics projects for diverse industries\n",
      "Masters or PhD in a quantitative discipline\n",
      "Please note you must\n",
      "\n",
      "[58] r an ambitious and enthusiastic recent masters or PhD graduate in a numerical discipline to join our In\n",
      "\n",
      "[59]  relevant academic background (ideally masters or PhD) in Computer Science, Maths, Physics or similar a\n",
      "\n",
      "[66] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use check_re to test the regular expressions that will be used for searching qualifications\n",
    "for key, val in dict_qualifications.items():\n",
    "    print(f\"{key.upper()}\\n\")\n",
    "    check_re(jobsdf=dsjobs, regex=val[\"re\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bachelor's: 0.19\n",
      "Master's: 0.24\n",
      "PhD: 0.28\n"
     ]
    }
   ],
   "source": [
    "# search each job description for each qualification using the regular expressions in \n",
    "# dict_qualifications, entering the boolean result in a new column for each one\n",
    "for key, val in dict_qualifications.items():\n",
    "    dsjobs[key] = dsjobs[\"job_description\"].apply(\n",
    "        lambda x: bool(re.search(val['re'], x, re.IGNORECASE)))\n",
    "    # for debugging: if any job mentions a qualification, column mean should be non-zero\n",
    "    print(f\"{val['label']}: {(np.mean(dsjobs[key])).round(2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find mentions of degree subjects in the job descriptions, searching for just the name of the subject in the job description will not do, since words like \"statistics\" and \"engineering\" are also mentioned in other contexts, e.g. in the company overview, or in the description of responsibilities, so I'll look for instances where the subject name and reference to a degree are in the same sentence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the job description text into sentences using new lines\n",
    "dsjobs['job_description_sent'] = dsjobs[\"job_description\"].apply(\n",
    "    lambda x: x.split(\"\\n\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of regular expressions for degree subjects, which will\n",
    "# be used to search for the subjects in the text surrounding the mention of \n",
    "# a qualification; the labels will be used for analysis plots later\n",
    "dict_degsubjects = {\n",
    "    \"degree_statistics\": {\n",
    "        're': r\"\\bstatistics\\b\",\n",
    "        'label': \"Statistics\"\n",
    "    },\n",
    "    \"degree_compsci\": {\n",
    "        're': r\"\\bcomputer science\\b\",\n",
    "        'label': \"Computer Science\"\n",
    "    },\n",
    "    \"degree_software_engineering\": {\n",
    "        're': r\"\\bsoftware engineering\\b\",\n",
    "        'label': \"Software Engineering\"\n",
    "    },\n",
    "    \"degree_economics\": {\n",
    "        're': r\"\\beconomics\\b\",\n",
    "        'label': \"Economics\"\n",
    "    },\n",
    "    \"degree_maths\": {\n",
    "        're': r\"\\bmaths\\b|\\bmathematics\\b\",\n",
    "        'label': \"Maths\"\n",
    "    },\n",
    "    \"degree_physics\": {\n",
    "        're': r\"\\bphysics\\b\",\n",
    "        'label': \"Physics\"\n",
    "    },\n",
    "    \"degree_engineering\": {\n",
    "        're': r\"\\bengineering\\b\",\n",
    "        'label': \"Engineering\"\n",
    "    },\n",
    "    \"degree_biology\": {\n",
    "        're': r\"\\bbiolog\\b|\\bbioinformatics\\b\",\n",
    "        'label': \"Biology\"\n",
    "    },\n",
    "    \"degree_chemistry\": {\n",
    "        're': r\"\\bchemistry\\b\",\n",
    "        'label': \"Chemistry\"\n",
    "    },\n",
    "    \"degree_datasci\": {\n",
    "        're': r\"\\bdata science\\b\",\n",
    "        'label': \"Data Science\"\n",
    "    },\n",
    "    \"degree_ml_ai\": {\n",
    "        're': r\"machine learning|\\bml\\b|artificial intelligence|\\bai\\b\",\n",
    "        'label': \"ML or AI\"\n",
    "    },\n",
    "    \"degree_stem_quantfield\": {\n",
    "        're': r\"\\bstem\\b|\\bquantitative field\\b\",\n",
    "        'label': \"'STEM' or 'Quantitative Field'\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics: 0.26\n",
      "Computer Science: 0.29\n",
      "Software Engineering: 0.01\n",
      "Economics: 0.06\n",
      "Maths: 0.29\n",
      "Physics: 0.12\n",
      "Engineering: 0.17\n",
      "Biology: 0.02\n",
      "Chemistry: 0.02\n",
      "Data Science: 0.13\n",
      "ML or AI: 0.1\n",
      "'STEM' or 'Quantitative Field': 0.11\n"
     ]
    }
   ],
   "source": [
    "# line by line, check each job description for the subject + mention of a 'degree'/qualification\n",
    "for key, val in dict_degsubjects.items():\n",
    "    # create a column for the degree subject in ds with default values set to False\n",
    "    dsjobs[key] = False\n",
    "    for index, row in dsjobs.iterrows():\n",
    "        for sentence in row['job_description_sent']:\n",
    "            # if the subject is in the sentence\n",
    "            if (re.search(val['re'], sentence, re.IGNORECASE)):\n",
    "                # if \"degree\" is in the same sentence, positive result\n",
    "                if (re.search(r\"degree\", sentence, re.IGNORECASE)):\n",
    "                    dsjobs.loc[index, key] = True\n",
    "                    break   # no need to look for a specific degree type\n",
    "                # else look for a specific qualification, e.g. \"PhD\"\n",
    "                else:\n",
    "                    for k, v in dict_qualifications.items():\n",
    "                        # if the qualification is in the same sentence\n",
    "                        if (re.search(v['re'], sentence, re.IGNORECASE)):  \n",
    "                            dsjobs.loc[index, key] = True\n",
    "                            break   # no need to keep looking for a qualification\n",
    "    # for debugging: if any mentions of a degree in the subject, column mean should be non-zero\n",
    "    print(f\"{val['label']}: {round((dsjobs[key].mean()),2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boolean mask to mark jobs that mention any type of degree\n",
    "degree_any = dsjobs.loc[:,\"degree_statistics\":\"degree_stem_quantfield\"].any(axis='columns')\n",
    "dsjobs[\"degree_any\"] = degree_any\n",
    "\n",
    "# add mention of \"any degree\" to the qualifcations dictionary for analysis and visualisation\n",
    "dict_qualifications[\"degree_any\"] = {'label': \"Any Degree\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of the dictionaries so we can use them later\n",
    "dsjobs_dicts = {\n",
    "    'dict_skills' : dict_skills,\n",
    "    'dict_tools' : dict_tools,\n",
    "    'dict_degsubjects' : dict_degsubjects,\n",
    "    'dict_qualifications' : dict_qualifications,\n",
    "}\n",
    "\n",
    "# save the list of dictionaries as a .pkl file\n",
    "with open('dsjobs_dicts.pkl', 'wb') as f:\n",
    "    pickle.dump(dsjobs_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fully wrangled dsjobs dataframe \n",
    "# as a .csv file\n",
    "dsjobs.to_csv(\n",
    "    os.path.join(path, f'dsjobs_df_{scrapedate}_wrangled.csv'), \n",
    "    encoding='utf-8'\n",
    ")\n",
    "# as a .pkl file which preserves data types (better for processing steps)\n",
    "dsjobs.to_pickle(os.path.join(path, f'dsjobs_df_{scrapedate}_wrangled.pkl'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf77a1a389081cd4a2e68fe826e74ff3c59ede00e7da793e7feb1b74b90842f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('eda-proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
